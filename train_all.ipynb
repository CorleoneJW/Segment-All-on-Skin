{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import HAMALL_datasets,HAM_datasets\n",
    "from models.meta import Meta\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from models.basenet import *\n",
    "from utils import *\n",
    "from configs.config_setting import setting_config\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics as metrics\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.init as init\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = setting_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    support_images = batch['support_images'].squeeze(0)\n",
    "    support_masks = batch['support_masks'].squeeze(0)\n",
    "    query_images = batch['query_images'].squeeze(0)\n",
    "    query_masks = batch['query_masks'].squeeze(0)\n",
    "    return support_images, support_masks, query_images, query_masks\n",
    "\n",
    "# the function of copying the images\n",
    "def copy_file_to_folder(source_file, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    dest_path = os.path.join(dest_folder, os.path.basename(source_file))\n",
    "    shutil.copy(source_file, dest_path)\n",
    "\n",
    "def evaluation_api(predicted_list,groudtruth_list):\n",
    "    pre = np.array([item for sublist in predicted_list for item in sublist]).reshape(-1)\n",
    "    gts = np.array([item for sublist in groudtruth_list for item in sublist]).reshape(-1)\n",
    "    # confusion_matrix = metrics.confusion_matrix(gts,pre)\n",
    "    # TN, FP, FN, TP = confusion[0,0], confusion[0,1], confusion[1,0], confusion[1,1] \n",
    "    dice = metrics.f1_score(gts,pre)\n",
    "    return dice\n",
    "\n",
    "def evaluation_epoch(predicted_list,groundtruth_list):\n",
    "    TP = [0]*config.num_classes\n",
    "    FP = [0]*config.num_classes\n",
    "    FN = [0]*config.num_classes\n",
    "    dice = [0.0]*config.num_classes\n",
    "    \n",
    "    for i in range(len(predicted_list)):\n",
    "        preds = np.array(predicted_list[i]).reshape(-1)\n",
    "        gts = np.array(groundtruth_list[i]).reshape(-1)\n",
    "        for j in range(len(preds)):\n",
    "            if preds[j] == gts[j]:\n",
    "                TP[gts[j]] += 1\n",
    "            else:\n",
    "                FP[preds[j]] += 1\n",
    "                FN[gts[j]] += 1        \n",
    "    \n",
    "    for i in range(config.num_classes):\n",
    "        dice[i] = (2 * TP[i])/(FP[i]+FN[i]+2*TP[i]+1)\n",
    "\n",
    "    mdice = (2*np.sum(TP))/(np.sum(FP)+np.sum(FN)+2*np.sum(TP)+1)    \n",
    "    return dice,mdice\n",
    "\n",
    "def evaluation_basenet(base_net,query_images,query_masks,criterion):\n",
    "    predicted = base_net(query_images)\n",
    "    loss = criterion(predicted,query_masks)\n",
    "    predicted = torch.argmax(predicted,dim=1).long()\n",
    "    predict_numpy = predicted.detach().cpu().numpy().reshape(-1)\n",
    "    masks_numpy = query_masks.long().detach().cpu().numpy().reshape(-1)\n",
    "    accuracy = metrics.accuracy_score(masks_numpy,predict_numpy)\n",
    "    f1_score = metrics.f1_score(masks_numpy,predict_numpy,average=None)\n",
    "    return accuracy,f1_score,loss\n",
    "\n",
    "def initialize_weights_he(model):\n",
    "    for param in model.parameters():\n",
    "        init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "def initialize_weights_xavier(model):\n",
    "    for param in model.parameters():\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "def initialize_weights_normal(model):\n",
    "    for param in model.parameters():\n",
    "        init.normal_(param, mean=0, std=1)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Creating logger----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Creating logger----------#')\n",
    "sys.path.append(config.work_dir + '/')\n",
    "log_dir = os.path.join(config.work_dir, 'log')\n",
    "checkpoint_dir = os.path.join(config.work_dir, 'checkpoints')\n",
    "resume_model = os.path.join(checkpoint_dir, 'latest.pth')\n",
    "outputs = os.path.join(config.work_dir, 'outputs')\n",
    "csv_save = os.path.join(config.work_dir, 'csv')\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "if not os.path.exists(csv_save):\n",
    "    os.makedirs(csv_save)\n",
    "\n",
    "global logger\n",
    "logger = get_logger('test', log_dir)\n",
    "global writer\n",
    "writer = SummaryWriter(config.work_dir + 'summary')\n",
    "\n",
    "log_config_info(config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Generating data----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Generating data----------#')\n",
    "images_resources_path = \"./data/HAM10000/origin/images/\"         # the resource folder of images\n",
    "masks_resources_path = \"./data/HAM10000/origin/masks/\"           # the resource folder of masks\n",
    "ratio = 0.8     # the dataset and testset ratio\n",
    "categories = config.categories\n",
    "categories_dictionary = {}\n",
    "category_id = 1\n",
    "# prepare the csv for groundtruth\n",
    "origin_groundtruth_csv = \"./data/HAM10000/origin/groundtruth/HAM10000_groundtruth.csv\"   # read the csv file\n",
    "origin_groundtruth = pd.read_csv(origin_groundtruth_csv)    # read the csv file of groundtruth\n",
    "\n",
    "# generating the folders for each category in train folder and test folder\n",
    "# create folders for each categories\n",
    "trainset_images_path = \"./data/HAM10000/train/images/\"     # the images path for train dataset\n",
    "trainset_masks_path = \"./data/HAM10000/train/masks/\"     # the masks path for train dataset\n",
    "testset_images_path = \"./data/HAM10000/test/images/\"     # the images path for test dataset\n",
    "testset_masks_path = \"./data/HAM10000/test/masks/\"      # the masks path for test dataset\n",
    "\n",
    "for category in categories:\n",
    "    # prepare the address for folders\n",
    "    category_images_train_path = os.path.join(trainset_images_path,category)\n",
    "    category_masks_train_path = os.path.join(trainset_masks_path,category)\n",
    "    category_images_test_path = os.path.join(testset_images_path,category)\n",
    "    category_masks_test_path = os.path.join(testset_masks_path,category)\n",
    "    #delete the previously exsited folders\n",
    "    shutil.rmtree(category_images_train_path)\n",
    "    shutil.rmtree(category_masks_train_path)\n",
    "    shutil.rmtree(category_images_test_path)\n",
    "    shutil.rmtree(category_masks_test_path)\n",
    "    # create corresponding folder for each categories\n",
    "    os.makedirs(category_images_train_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_train_path, exist_ok=True)\n",
    "    os.makedirs(category_images_test_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_test_path, exist_ok=True)\n",
    "\n",
    "    # generate the data in trainset and testset for each categories\n",
    "    dest_folder_images = \"./data/HAM10000/train/images/\"+category    # the destination train set folder of copying the images\n",
    "    dest_folder_masks = \"./data/HAM10000/train/masks/\"+category    # the destination trian set folder of copying the masks\n",
    "    dest_folder_images_change = \"./data/HAM10000/test/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change = \"./data/HAM10000/test/masks/\"+category      # the destination folder of test set masks\n",
    "    data_categories = origin_groundtruth[origin_groundtruth['dx'] == category]      # extract each categories \n",
    "    data_categories = data_categories.sample(frac=1,random_state=config.seed)       # random sample the datagenerating\n",
    "    length_categories = len(data_categories)\n",
    "    change_folder_point = math.floor(length_categories * ratio)     # get the point to change directory name \n",
    "    elements_count = 0\n",
    "    for image_name in data_categories['image_id']:      # each image_id in each categories\n",
    "        if elements_count == change_folder_point:\n",
    "            dest_folder_images = dest_folder_images_change\n",
    "            dest_folder_masks = dest_folder_masks_change\n",
    "        images_file = image_name+\".jpg\"\n",
    "        masks_file = image_name+\"_segmentation.png\"\n",
    "        source_image = images_resources_path+images_file    # the full path of source of image : path + image file name\n",
    "        source_mask = masks_resources_path+masks_file       # the full path of source of mask : path + mask file name\n",
    "        copy_file_to_folder(source_image,dest_folder_images)\n",
    "        # masks should be preprocess to the form of output for network (Width*Height*Category)\n",
    "        image = Image.open(source_mask)\n",
    "        image_array = np.array(image)\n",
    "        image_array[image_array == 255] = 1\n",
    "        image = Image.fromarray(image_array)\n",
    "        image.save(os.path.join(dest_folder_masks, masks_file))\n",
    "        elements_count +=1\n",
    "    categories_dictionary[category] = category_id       # add the category id in the categories_dictionary\n",
    "    category_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------GPU init----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------GPU init----------#')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu_id\n",
    "set_seed(config.seed)\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Datasets----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Datasets----------#')\n",
    "# create the dataset and dataloader\n",
    "batch_size = 20\n",
    "train_dataset = HAMALL_datasets(config, train=True)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "test_dataset = HAMALL_datasets(config, train=False)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Model----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Model----------#')\n",
    "in_channels = config.in_channels\n",
    "out_channels = config.out_channels\n",
    "# base_net = smp.Unet(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.num_classes, activation=None, aux_params=None)\n",
    "base_net = smp.UnetPlusPlus(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.num_classes, activation=None, aux_params=None)\n",
    "# initialize_weights_he(base_net)\n",
    "base_net = base_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing loss, opt, sch and amp----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing loss, opt, sch and amp----------#')\n",
    "criterion = config.criterion\n",
    "meta_optimizer = get_optimizer(config, base_net)\n",
    "meta_scheduler = get_scheduler(config, meta_optimizer)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Set other params----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Set other params----------#')\n",
    "min_loss = 999\n",
    "start_epoch = 1\n",
    "min_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Start training----------#\n",
      "128-resizeh, 128-resizew, 0.000100-outer_lr\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m     groundtruth_list\u001b[39m.\u001b[39mappend(mask\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     36\u001b[0m \u001b[39m# train_dice,train_mdice = evaluation_epoch(predicted_list,groundtruth_list)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m train_dice \u001b[39m=\u001b[39m evaluation_api(predicted_list,groundtruth_list)\n\u001b[1;32m     38\u001b[0m train_mloss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(loss_list)\n\u001b[1;32m     39\u001b[0m log_train \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mepoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_mloss\u001b[39m}\u001b[39;00m\u001b[39m, dice: \u001b[39m\u001b[39m{\u001b[39;00mtrain_dice\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m, in \u001b[0;36mevaluation_api\u001b[0;34m(predicted_list, groudtruth_list)\u001b[0m\n\u001b[1;32m     18\u001b[0m gts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([item \u001b[39mfor\u001b[39;00m sublist \u001b[39min\u001b[39;00m groudtruth_list \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sublist])\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[39m# confusion_matrix = metrics.confusion_matrix(gts,pre)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# TN, FP, FN, TP = confusion[0,0], confusion[0,1], confusion[1,0], confusion[1,1] \u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m dice \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39;49mf1_score(gts,pre)\n\u001b[1;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m dice\n",
      "File \u001b[0;32m~/anaconda3/envs/dataEngineering/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/dataEngineering/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1238\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m   1071\u001b[0m     {\n\u001b[1;32m   1072\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1096\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1097\u001b[0m ):\n\u001b[1;32m   1098\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \n\u001b[1;32m   1100\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[39m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1237\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1238\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[1;32m   1239\u001b[0m         y_true,\n\u001b[1;32m   1240\u001b[0m         y_pred,\n\u001b[1;32m   1241\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1242\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1243\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1244\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1245\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1246\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1247\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/dataEngineering/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dataEngineering/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1411\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m   1251\u001b[0m     {\n\u001b[1;32m   1252\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1279\u001b[0m ):\n\u001b[1;32m   1280\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \n\u001b[1;32m   1282\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[39m    0.38...\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1411\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1412\u001b[0m         y_true,\n\u001b[1;32m   1413\u001b[0m         y_pred,\n\u001b[1;32m   1414\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[1;32m   1415\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1416\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1417\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1418\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1419\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1420\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1421\u001b[0m     )\n\u001b[1;32m   1422\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/anaconda3/envs/dataEngineering/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dataEngineering/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1721\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m \n\u001b[1;32m   1565\u001b[0m \u001b[39mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[39m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m zero_division_value \u001b[39m=\u001b[39m _check_zero_division(zero_division)\n\u001b[0;32m-> 1721\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1723\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/dataEngineering/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1516\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1515\u001b[0m             average_options\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1516\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1517\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTarget is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m but average=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1518\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mchoose another average setting, one of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (y_type, average_options)\n\u001b[1;32m   1519\u001b[0m         )\n\u001b[1;32m   1520\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m):\n\u001b[1;32m   1521\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1522\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pos_label (set to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) is ignored when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1523\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maverage != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m). You may use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1526\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m   1527\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "print('#----------Start training----------#')\n",
    "torch.cuda.empty_cache()\n",
    "info = \"%d-resizeh, %d-resizew, %f-outer_lr\"%(config.resize_h,config.resize_w,config.outer_lr)\n",
    "print(info)\n",
    "logger.info(info)\n",
    "best_dice = 0.0\n",
    "train_csv = os.path.join(csv_save,\"train.csv\")\n",
    "test_csv = os.path.join(csv_save,\"test.csv\")\n",
    "train_columns = ['Epoch','Loss',\"Mdice\"]\n",
    "train_df = pd.DataFrame(columns=train_columns)\n",
    "test_columns = ['Epoch','Mdice']\n",
    "test_df = pd.DataFrame(columns=test_columns)\n",
    "for epoch in range(start_epoch, config.epoch_num+1):\n",
    "    # train part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    loss_list = []    \n",
    "    base_net.train()\n",
    "    for image,mask in train_loader:\n",
    "        # claer the meta_optimizer, setting zero\n",
    "        meta_optimizer.zero_grad()\n",
    "        image = image.to(device)\n",
    "        mask = mask.to(device)\n",
    "        image = torch.squeeze(image,dim=1)      # torch.Size([20, 3, 512, 512])\n",
    "        mask = torch.squeeze(mask,dim=1)     # torch.Size([20, 1, 512, 512])\n",
    "        mask = torch.squeeze(mask,dim=1).long()     # torch.Size([20, 512, 512])\n",
    "        predicted = base_net(image)\n",
    "        loss = criterion(predicted,mask)\n",
    "        loss.backward()\n",
    "        meta_optimizer.step()\n",
    "        loss_list.append(loss.cpu().detach().numpy())\n",
    "        temp_predicted = torch.argmax(predicted,dim=1).long().cpu().detach().numpy()\n",
    "        predicted_list.append(temp_predicted)\n",
    "        groundtruth_list.append(mask.cpu().detach().numpy())\n",
    "    # train_dice,train_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "    train_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "    train_mloss = np.mean(loss_list)\n",
    "    log_train = f'epoch: {epoch}, loss: {train_mloss}, dice: {train_dice}'\n",
    "    print(\"#Train# \",log_train)\n",
    "    temp_result = pd.Series([epoch,train_mloss,train_dice],index=train_columns)\n",
    "    train_df = train_df.append(temp_result, ignore_index=True)\n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    \n",
    "    # test part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in test_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([20, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([20, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).long()     # torch.Size([20, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = torch.argmax(predicted,dim=1).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.cpu().detach().numpy())\n",
    "        # test_dice,test_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        test_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_test = f'epoch: {epoch}, dice: {test_dice}'\n",
    "        print(\"#Test# \",log_test)\n",
    "        temp_result = pd.Series([epoch,test_dice],index=test_columns)\n",
    "        test_df = test_df.append(temp_result, ignore_index=True)\n",
    "        test_df.to_csv(test_csv, index=False)\n",
    "        logger.info(log_test)\n",
    "\n",
    "    if test_dice > best_dice:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best.pth'))\n",
    "        best_dice = test_dice\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
