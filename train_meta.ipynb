{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import *\n",
    "from models.meta import Meta\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from models.basenet import *\n",
    "from utils import *\n",
    "from configs.config_setting import setting_config\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics as metrics\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.init as init\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = setting_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    support_images = batch['support_images'].squeeze(0)\n",
    "    support_masks = batch['support_masks'].squeeze(0)\n",
    "    query_images = batch['query_images'].squeeze(0)\n",
    "    query_masks = batch['query_masks'].squeeze(0)\n",
    "    return support_images, support_masks, query_images, query_masks\n",
    "\n",
    "# the function of copying the images\n",
    "def copy_file_to_folder(source_file, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    dest_path = os.path.join(dest_folder, os.path.basename(source_file))\n",
    "    shutil.copy(source_file, dest_path)\n",
    "\n",
    "def evaluation_api(predicted_list,groudtruth_list):\n",
    "    pre = np.array([item for sublist in predicted_list for item in sublist]).reshape(-1)\n",
    "    gts = np.array([item for sublist in groudtruth_list for item in sublist]).reshape(-1)\n",
    "    # confusion_matrix = metrics.confusion_matrix(gts,pre)\n",
    "    # TN, FP, FN, TP = confusion[0,0], confusion[0,1], confusion[1,0], confusion[1,1] \n",
    "    dice = metrics.f1_score(gts,pre)\n",
    "\n",
    "    return dice\n",
    "\n",
    "def evaluation_epoch(predicted_list,groundtruth_list):\n",
    "    TP = [0]*config.num_classes\n",
    "    FP = [0]*config.num_classes\n",
    "    FN = [0]*config.num_classes\n",
    "    dice = [0.0]*config.num_classes\n",
    "    \n",
    "    for i in range(len(predicted_list)):\n",
    "        preds = np.array(predicted_list[i]).reshape(-1)\n",
    "        gts = np.array(groundtruth_list[i]).reshape(-1)\n",
    "        for j in range(len(preds)):\n",
    "            if preds[j] == gts[j]:\n",
    "                TP[gts[j]] += 1\n",
    "            else:\n",
    "                FP[preds[j]] += 1\n",
    "                FN[gts[j]] += 1        \n",
    "    \n",
    "    for i in range(config.num_classes):\n",
    "        dice[i] = (2 * TP[i])/(FP[i]+FN[i]+2*TP[i]+1)\n",
    "\n",
    "    mdice = (2*np.sum(TP))/(np.sum(FP)+np.sum(FN)+2*np.sum(TP)+1)    \n",
    "    return dice,mdice\n",
    "\n",
    "def evaluation_basenet(base_net,query_images,query_masks,criterion):\n",
    "    predicted = base_net(query_images)\n",
    "    loss = criterion(predicted,query_masks)\n",
    "    predicted = torch.argmax(predicted,dim=1).long()\n",
    "    predict_numpy = predicted.detach().cpu().numpy().reshape(-1)\n",
    "    masks_numpy = query_masks.long().detach().cpu().numpy().reshape(-1)\n",
    "    accuracy = metrics.accuracy_score(masks_numpy,predict_numpy)\n",
    "    f1_score = metrics.f1_score(masks_numpy,predict_numpy,average=None)\n",
    "    return accuracy,f1_score,loss\n",
    "\n",
    "def initialize_weights_he(model):\n",
    "    for param in model.parameters():\n",
    "        init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "def initialize_weights_xavier(model):\n",
    "    for param in model.parameters():\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "def initialize_weights_normal(model):\n",
    "    for param in model.parameters():\n",
    "        init.normal_(param, mean=0, std=1)\n",
    "\n",
    "def remove_exsits_folder(folderpath):\n",
    "    if os.path.exists(folderpath):\n",
    "        shutil.rmtree(folderpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Creating logger----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Creating logger----------#')\n",
    "sys.path.append(config.work_dir + '/')\n",
    "log_dir = os.path.join(config.work_dir, 'log')\n",
    "checkpoint_dir = os.path.join(config.work_dir, 'checkpoints')\n",
    "resume_model = os.path.join(checkpoint_dir, 'latest.pth')\n",
    "outputs = os.path.join(config.work_dir, 'outputs')\n",
    "csv_save = os.path.join(config.work_dir, 'csv')\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "if not os.path.exists(csv_save):\n",
    "    os.makedirs(csv_save)\n",
    "\n",
    "global logger\n",
    "logger = get_logger('test', log_dir)\n",
    "global writer\n",
    "writer = SummaryWriter(config.work_dir + 'summary')\n",
    "\n",
    "log_config_info(config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Generating data----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Generating data----------#')\n",
    "images_resources_path = \"./data/HAM10000/origin/images/\"         # the resource folder of images\n",
    "masks_resources_path = \"./data/HAM10000/origin/masks/\"           # the resource folder of masks\n",
    "ratio = [0.6,0.2]     # the ratio point of train dataset and validation set and testset\n",
    "categories = config.categories\n",
    "categories_dictionary = {}\n",
    "category_id = 1\n",
    "# prepare the csv for groundtruth\n",
    "origin_groundtruth_csv = \"./data/HAM10000/origin/groundtruth/HAM10000_groundtruth.csv\"   # read the csv file\n",
    "origin_groundtruth = pd.read_csv(origin_groundtruth_csv)    # read the csv file of groundtruth\n",
    "\n",
    "# generating the folders for each category in train folder and test folder\n",
    "# create folders for each categories\n",
    "trainset_images_path = \"./data/HAM10000/train/images/\"     # the images path for train dataset\n",
    "trainset_masks_path = \"./data/HAM10000/train/masks/\"     # the masks path for train dataset\n",
    "valset_images_path = \"./data/HAM10000/val/images/\"     # the images path for validation dataset\n",
    "valset_masks_path = \"./data/HAM10000/val/masks/\"      # the masks path for validation dataset\n",
    "testset_images_path = \"./data/HAM10000/test/images/\"     # the images path for test dataset\n",
    "testset_masks_path = \"./data/HAM10000/test/masks/\"      # the masks path for test dataset\n",
    "\n",
    "for category in categories:\n",
    "    # prepare the address for folders\n",
    "    category_images_train_path = os.path.join(trainset_images_path,category)\n",
    "    category_masks_train_path = os.path.join(trainset_masks_path,category)\n",
    "    category_images_val_path = os.path.join(valset_images_path,category)\n",
    "    category_masks_val_path = os.path.join(valset_masks_path,category)\n",
    "    category_images_test_path = os.path.join(testset_images_path,category)\n",
    "    category_masks_test_path = os.path.join(testset_masks_path,category)\n",
    "    #delete the previously exsited folders\n",
    "    remove_exsits_folder(category_images_train_path)\n",
    "    remove_exsits_folder(category_masks_train_path)\n",
    "    remove_exsits_folder(category_images_val_path)\n",
    "    remove_exsits_folder(category_masks_val_path)\n",
    "    remove_exsits_folder(category_images_test_path)\n",
    "    remove_exsits_folder(category_masks_test_path)\n",
    "    # create corresponding folder for each categories\n",
    "    os.makedirs(category_images_train_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_train_path, exist_ok=True)\n",
    "    os.makedirs(category_images_val_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_val_path, exist_ok=True)\n",
    "    os.makedirs(category_images_test_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_test_path, exist_ok=True)\n",
    "\n",
    "    # generate the data in trainset and testset for each categories\n",
    "    dest_folder_images = \"./data/HAM10000/train/images/\"+category    # the destination train set folder of copying the images\n",
    "    dest_folder_masks = \"./data/HAM10000/train/masks/\"+category    # the destination trian set folder of copying the masks\n",
    "    dest_folder_images_change_val = \"./data/HAM10000/val/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_val = \"./data/HAM10000/val/masks/\"+category      # the destination folder of test set masks\n",
    "    dest_folder_images_change_test = \"./data/HAM10000/test/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_test = \"./data/HAM10000/test/masks/\"+category      # the destination folder of test set masks\n",
    "    data_categories = origin_groundtruth[origin_groundtruth['dx'] == category]      # extract each categories \n",
    "    data_categories = data_categories.sample(frac=1,random_state=config.seed)       # random sample the datagenerating\n",
    "    length_categories = len(data_categories)\n",
    "    change_folder_point_valset = math.floor(length_categories * ratio[0])     # get the point to change directory name\n",
    "    change_folder_point_testset = math.floor(length_categories * (ratio[0]+ratio[1]))     # get the point to change directory name \n",
    "    elements_count = 0\n",
    "    for image_name in data_categories['image_id']:      # each image_id in each categories\n",
    "        if elements_count == change_folder_point_valset:\n",
    "            dest_folder_images = dest_folder_images_change_val\n",
    "            dest_folder_masks = dest_folder_masks_change_val\n",
    "        elif elements_count == change_folder_point_testset:\n",
    "            dest_folder_images = dest_folder_images_change_test\n",
    "            dest_folder_masks = dest_folder_masks_change_test\n",
    "        images_file = image_name+\".jpg\"\n",
    "        masks_file = image_name+\"_segmentation.png\"\n",
    "        source_image = images_resources_path+images_file    # the full path of source of image : path + image file name\n",
    "        source_mask = masks_resources_path+masks_file       # the full path of source of mask : path + mask file name\n",
    "        copy_file_to_folder(source_image,dest_folder_images)\n",
    "        # masks should be preprocess to the form of output for network (Width*Height*Category)\n",
    "        image = Image.open(source_mask)\n",
    "        image_array = np.array(image)\n",
    "        image_array[image_array == 255] = 1\n",
    "        image = Image.fromarray(image_array)\n",
    "        image.save(os.path.join(dest_folder_masks, masks_file))\n",
    "        elements_count +=1\n",
    "    categories_dictionary[category] = category_id       # add the category id in the categories_dictionary\n",
    "    category_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------GPU init----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------GPU init----------#')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu_id\n",
    "set_seed(config.seed)\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Datasets----------#\n",
      "trian_dataset_list length: 3\n",
      "trian_dataset(mel) length: 667\n",
      "trian_dataset(bkl) length: 659\n",
      "trian_dataset(bcc) length: 308\n",
      "val_dataset length: 546\n",
      "test_dataset length: 546\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Datasets----------#')\n",
    "# create the dataset and dataloader\n",
    "batch_size = config.batch_size\n",
    "categories = config.categories\n",
    "num_categories = len(categories)\n",
    "train_dataset_list = []\n",
    "train_loader_list = []\n",
    "for i in range(num_categories):\n",
    "    train_dataset = HAMALL_datasets(config, train=True,categories = [categories[i]])\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "    train_dataset_list.append(train_dataset)\n",
    "    train_loader_list.append(train_loader)\n",
    "val_dataset = HAMALL_datasets(config, train=False,val=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "test_dataset = HAMALL_datasets(config, train=False)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "print(\"trian_dataset_list length:\",len(train_loader_list))\n",
    "for i in range(num_categories):\n",
    "    print(\"trian_dataset(\"+categories[i]+\") length:\",len(train_dataset_list[i]))\n",
    "print(\"val_dataset length:\",len(val_dataset))\n",
    "print(\"test_dataset length:\",len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Model----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Model----------#')\n",
    "in_channels = config.in_channels\n",
    "out_channels = config.out_channels\n",
    "base_net = smp.Unet(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# base_net = smp.UnetPlusPlus(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# initialize_weights_he(base_net)\n",
    "base_net = base_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing loss, opt, sch and amp----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing loss, opt, sch and amp----------#')\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "meta_optimizer = get_optimizer(config, base_net)\n",
    "meta_scheduler = get_scheduler(config, meta_optimizer)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Set other params----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Set other params----------#')\n",
    "min_loss = 999\n",
    "start_epoch = 1\n",
    "min_epoch = 1\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Start training----------#\n",
      "128-resizeh, 128-resizew, 0.000100-outer_lr\n",
      "#Train#  epoch: 1, loss: 0.3034991919994354, dice: 0.40686081720597306\n",
      "#Val#  epoch: 1, dice: 0.2814770276406152\n",
      "#Test#  epoch: 1, dice: 0.2675629540715056\n",
      "#Train#  epoch: 2, loss: 0.26854491233825684, dice: 0.529375892364986\n",
      "#Val#  epoch: 2, dice: 0.5819813892063513\n",
      "#Test#  epoch: 2, dice: 0.5680878550952079\n",
      "#Train#  epoch: 3, loss: 0.24931800365447998, dice: 0.6004283201100188\n",
      "#Val#  epoch: 3, dice: 0.6348999982416236\n",
      "#Test#  epoch: 3, dice: 0.6328770686139973\n",
      "#Train#  epoch: 4, loss: 0.23692063987255096, dice: 0.6427478376659617\n",
      "#Val#  epoch: 4, dice: 0.6598292839826501\n",
      "#Test#  epoch: 4, dice: 0.6587129919215603\n",
      "#Train#  epoch: 5, loss: 0.22812716662883759, dice: 0.669849607183213\n",
      "#Val#  epoch: 5, dice: 0.6782613367409781\n",
      "#Test#  epoch: 5, dice: 0.6772101317933141\n",
      "#Train#  epoch: 6, loss: 0.22091035544872284, dice: 0.6872732207056385\n",
      "#Val#  epoch: 6, dice: 0.691122738617464\n",
      "#Test#  epoch: 6, dice: 0.6897043473735722\n",
      "#Train#  epoch: 7, loss: 0.21485589444637299, dice: 0.6985170363593377\n",
      "#Val#  epoch: 7, dice: 0.700381870569059\n",
      "#Test#  epoch: 7, dice: 0.6985421440168436\n",
      "#Train#  epoch: 8, loss: 0.20963150262832642, dice: 0.7073728517752481\n",
      "#Val#  epoch: 8, dice: 0.7083144273156677\n",
      "#Test#  epoch: 8, dice: 0.7065537001577402\n",
      "#Train#  epoch: 9, loss: 0.20508740842342377, dice: 0.7148143928817037\n",
      "#Val#  epoch: 9, dice: 0.7153889935322818\n",
      "#Test#  epoch: 9, dice: 0.7137251918153661\n",
      "#Train#  epoch: 10, loss: 0.20102326571941376, dice: 0.72135791351414\n",
      "#Val#  epoch: 10, dice: 0.7222447780933172\n",
      "#Test#  epoch: 10, dice: 0.7200630598706224\n",
      "#Train#  epoch: 11, loss: 0.19732777774333954, dice: 0.7273405618652372\n",
      "#Val#  epoch: 11, dice: 0.7286196032556869\n",
      "#Test#  epoch: 11, dice: 0.7257689536734522\n",
      "#Train#  epoch: 12, loss: 0.1938987821340561, dice: 0.7328908759248105\n",
      "#Val#  epoch: 12, dice: 0.7344253373365716\n",
      "#Test#  epoch: 12, dice: 0.7312728425581042\n",
      "#Train#  epoch: 13, loss: 0.19068008661270142, dice: 0.7381049046614832\n",
      "#Val#  epoch: 13, dice: 0.7403417365008049\n",
      "#Test#  epoch: 13, dice: 0.7364797598405105\n",
      "#Train#  epoch: 14, loss: 0.18768537044525146, dice: 0.7434286573498138\n",
      "#Val#  epoch: 14, dice: 0.7464614882968006\n",
      "#Test#  epoch: 14, dice: 0.7414675513019674\n",
      "#Train#  epoch: 15, loss: 0.18489313125610352, dice: 0.7491672139539911\n",
      "#Val#  epoch: 15, dice: 0.7525049582893214\n",
      "#Test#  epoch: 15, dice: 0.746290172136013\n",
      "#Train#  epoch: 16, loss: 0.18234136700630188, dice: 0.7555846771623431\n",
      "#Val#  epoch: 16, dice: 0.7577380699333974\n",
      "#Test#  epoch: 16, dice: 0.7505755423721624\n",
      "#Train#  epoch: 17, loss: 0.18007269501686096, dice: 0.7624380703253024\n",
      "#Val#  epoch: 17, dice: 0.7616650273132299\n",
      "#Test#  epoch: 17, dice: 0.7537402747116144\n",
      "#Train#  epoch: 18, loss: 0.1780533790588379, dice: 0.7696936963367343\n",
      "#Val#  epoch: 18, dice: 0.7639895825726392\n",
      "#Test#  epoch: 18, dice: 0.7554971144458411\n",
      "#Train#  epoch: 19, loss: 0.17614907026290894, dice: 0.777114850934637\n",
      "#Val#  epoch: 19, dice: 0.7659061653947011\n",
      "#Test#  epoch: 19, dice: 0.7572443297825259\n",
      "#Train#  epoch: 20, loss: 0.17402905225753784, dice: 0.7847425498293302\n",
      "#Val#  epoch: 20, dice: 0.7684177370797546\n",
      "#Test#  epoch: 20, dice: 0.760099732141912\n",
      "#Train#  epoch: 21, loss: 0.17123976349830627, dice: 0.7922312289101879\n",
      "#Val#  epoch: 21, dice: 0.7715988760996051\n",
      "#Test#  epoch: 21, dice: 0.763111285067848\n",
      "#Train#  epoch: 22, loss: 0.16760730743408203, dice: 0.7991278705986417\n",
      "#Val#  epoch: 22, dice: 0.7725989240460827\n",
      "#Test#  epoch: 22, dice: 0.7638691217484499\n",
      "#Train#  epoch: 23, loss: 0.16376931965351105, dice: 0.8060417118693073\n",
      "#Val#  epoch: 23, dice: 0.7725685592368656\n",
      "#Test#  epoch: 23, dice: 0.7634749648286148\n",
      "#Train#  epoch: 24, loss: 0.1602679342031479, dice: 0.8129468235727085\n",
      "#Val#  epoch: 24, dice: 0.7758603447953009\n",
      "#Test#  epoch: 24, dice: 0.7670030718336903\n",
      "#Train#  epoch: 25, loss: 0.15696893632411957, dice: 0.8195167951378503\n",
      "#Val#  epoch: 25, dice: 0.7801421193262754\n",
      "#Test#  epoch: 25, dice: 0.7712608706711623\n",
      "#Train#  epoch: 26, loss: 0.15394848585128784, dice: 0.8255561798402005\n",
      "#Val#  epoch: 26, dice: 0.7770948667699289\n",
      "#Test#  epoch: 26, dice: 0.7658004186237004\n",
      "#Train#  epoch: 27, loss: 0.15151700377464294, dice: 0.8323306883465021\n",
      "#Val#  epoch: 27, dice: 0.7727894698021175\n",
      "#Test#  epoch: 27, dice: 0.7597582062604645\n",
      "#Train#  epoch: 28, loss: 0.1492789387702942, dice: 0.8395381764605487\n",
      "#Val#  epoch: 28, dice: 0.7804910278923379\n",
      "#Test#  epoch: 28, dice: 0.7680573410441245\n",
      "#Train#  epoch: 29, loss: 0.1469622701406479, dice: 0.8452565805741157\n",
      "#Val#  epoch: 29, dice: 0.7772147215369316\n",
      "#Test#  epoch: 29, dice: 0.7637477612627106\n",
      "#Train#  epoch: 30, loss: 0.14482365548610687, dice: 0.8508890101961422\n",
      "#Val#  epoch: 30, dice: 0.783521092120519\n",
      "#Test#  epoch: 30, dice: 0.7714691307253656\n",
      "#Train#  epoch: 31, loss: 0.14272311329841614, dice: 0.8555184879546069\n",
      "#Val#  epoch: 31, dice: 0.7823658624075103\n",
      "#Test#  epoch: 31, dice: 0.769535051824219\n",
      "#Train#  epoch: 32, loss: 0.14071311056613922, dice: 0.8602143724290634\n",
      "#Val#  epoch: 32, dice: 0.7777761038146679\n",
      "#Test#  epoch: 32, dice: 0.7638555546711627\n",
      "#Train#  epoch: 33, loss: 0.1387452334165573, dice: 0.86530477271406\n",
      "#Val#  epoch: 33, dice: 0.7835351590026794\n",
      "#Test#  epoch: 33, dice: 0.7704516052417084\n",
      "#Train#  epoch: 34, loss: 0.13668057322502136, dice: 0.8698560765571751\n",
      "#Val#  epoch: 34, dice: 0.7658307723028615\n",
      "#Test#  epoch: 34, dice: 0.7499511593051666\n",
      "#Train#  epoch: 35, loss: 0.13487640023231506, dice: 0.8748527422138784\n",
      "#Val#  epoch: 35, dice: 0.7875495545345376\n",
      "#Test#  epoch: 35, dice: 0.7737056390776816\n",
      "#Train#  epoch: 36, loss: 0.13277758657932281, dice: 0.8779827896563068\n",
      "#Val#  epoch: 36, dice: 0.7358872543723974\n",
      "#Test#  epoch: 36, dice: 0.7158569193992244\n",
      "#Train#  epoch: 37, loss: 0.1310739517211914, dice: 0.8823147311580319\n",
      "#Val#  epoch: 37, dice: 0.7904013017319935\n",
      "#Test#  epoch: 37, dice: 0.77719006908994\n",
      "#Train#  epoch: 38, loss: 0.12895295023918152, dice: 0.8865420101971911\n",
      "#Val#  epoch: 38, dice: 0.7565824738012218\n",
      "#Test#  epoch: 38, dice: 0.7363311384174565\n",
      "#Train#  epoch: 39, loss: 0.1267157644033432, dice: 0.8926199253130966\n",
      "#Val#  epoch: 39, dice: 0.7700170421888296\n",
      "#Test#  epoch: 39, dice: 0.7503763204468598\n",
      "#Train#  epoch: 40, loss: 0.12469005584716797, dice: 0.8964335409749467\n",
      "#Val#  epoch: 40, dice: 0.7871049277218392\n",
      "#Test#  epoch: 40, dice: 0.7694321652300559\n",
      "#Train#  epoch: 41, loss: 0.12300249934196472, dice: 0.8987415888358911\n",
      "#Val#  epoch: 41, dice: 0.7473438164045899\n",
      "#Test#  epoch: 41, dice: 0.7274349053389318\n",
      "#Train#  epoch: 42, loss: 0.12091359496116638, dice: 0.9026517208461502\n",
      "#Val#  epoch: 42, dice: 0.7850072738452242\n",
      "#Test#  epoch: 42, dice: 0.7672194752689919\n",
      "#Train#  epoch: 43, loss: 0.11912953853607178, dice: 0.9060422880207591\n",
      "#Val#  epoch: 43, dice: 0.7779441529797387\n",
      "#Test#  epoch: 43, dice: 0.7612639641858568\n",
      "#Train#  epoch: 44, loss: 0.11779788136482239, dice: 0.9067511615955977\n",
      "#Val#  epoch: 44, dice: 0.7725255734051005\n",
      "#Test#  epoch: 44, dice: 0.7533531576252986\n",
      "#Train#  epoch: 45, loss: 0.11617478728294373, dice: 0.9079325881896426\n",
      "#Val#  epoch: 45, dice: 0.7877146969115862\n",
      "#Test#  epoch: 45, dice: 0.7736839560384458\n",
      "#Train#  epoch: 46, loss: 0.11439167708158493, dice: 0.9130708187749229\n",
      "#Val#  epoch: 46, dice: 0.7944804137525298\n",
      "#Test#  epoch: 46, dice: 0.7800680640079285\n",
      "#Train#  epoch: 47, loss: 0.11270623654127121, dice: 0.9168994327622738\n",
      "#Val#  epoch: 47, dice: 0.7763848298039887\n",
      "#Test#  epoch: 47, dice: 0.7566861115768992\n",
      "#Train#  epoch: 48, loss: 0.11151223629713058, dice: 0.9180263429573958\n",
      "#Val#  epoch: 48, dice: 0.7879044412789836\n",
      "#Test#  epoch: 48, dice: 0.7724030667654399\n",
      "#Train#  epoch: 49, loss: 0.11011397838592529, dice: 0.9209613780481178\n",
      "#Val#  epoch: 49, dice: 0.7940164260294597\n",
      "#Test#  epoch: 49, dice: 0.7793253725093297\n",
      "#Train#  epoch: 50, loss: 0.10868146270513535, dice: 0.9238003560458007\n",
      "#Val#  epoch: 50, dice: 0.7690236618347086\n",
      "#Test#  epoch: 50, dice: 0.7484116627965463\n",
      "#Train#  epoch: 51, loss: 0.1076418086886406, dice: 0.925563417193093\n",
      "#Val#  epoch: 51, dice: 0.7941421082323646\n",
      "#Test#  epoch: 51, dice: 0.7770736858342459\n",
      "#Train#  epoch: 52, loss: 0.10621018707752228, dice: 0.9286156234276162\n",
      "#Val#  epoch: 52, dice: 0.7924437297438499\n",
      "#Test#  epoch: 52, dice: 0.7756523407897523\n",
      "#Train#  epoch: 53, loss: 0.10429628193378448, dice: 0.930153222718021\n",
      "#Val#  epoch: 53, dice: 0.7641361554856817\n",
      "#Test#  epoch: 53, dice: 0.7443040643675537\n",
      "#Train#  epoch: 54, loss: 0.10103275626897812, dice: 0.9313018062180228\n",
      "#Val#  epoch: 54, dice: 0.796414069862034\n",
      "#Test#  epoch: 54, dice: 0.7804871714239185\n",
      "#Train#  epoch: 55, loss: 0.09741196036338806, dice: 0.9348691232521115\n",
      "#Val#  epoch: 55, dice: 0.7922843103973695\n",
      "#Test#  epoch: 55, dice: 0.775093594844687\n",
      "#Train#  epoch: 56, loss: 0.09533634781837463, dice: 0.9363711088583097\n",
      "#Val#  epoch: 56, dice: 0.7756814456225042\n",
      "#Test#  epoch: 56, dice: 0.7565435373197653\n",
      "#Train#  epoch: 57, loss: 0.09445197880268097, dice: 0.9364549900782453\n",
      "#Val#  epoch: 57, dice: 0.7957314437779583\n",
      "#Test#  epoch: 57, dice: 0.7828227555930609\n",
      "#Train#  epoch: 58, loss: 0.09357298910617828, dice: 0.9374753539692587\n",
      "#Val#  epoch: 58, dice: 0.7865754336551058\n",
      "#Test#  epoch: 58, dice: 0.7730422778578908\n",
      "#Train#  epoch: 59, loss: 0.09359937906265259, dice: 0.9333088069480047\n",
      "#Val#  epoch: 59, dice: 0.787983783815589\n",
      "#Test#  epoch: 59, dice: 0.7738239351419256\n",
      "#Train#  epoch: 60, loss: 0.09251733124256134, dice: 0.9370658555265473\n",
      "#Val#  epoch: 60, dice: 0.792229410125682\n",
      "#Test#  epoch: 60, dice: 0.781482467602989\n",
      "#Train#  epoch: 61, loss: 0.09136085957288742, dice: 0.9417147478346178\n",
      "#Val#  epoch: 61, dice: 0.7935138773269098\n",
      "#Test#  epoch: 61, dice: 0.7842261904761905\n",
      "#Train#  epoch: 62, loss: 0.09152119606733322, dice: 0.9382755384178999\n",
      "#Val#  epoch: 62, dice: 0.7935036040868486\n",
      "#Test#  epoch: 62, dice: 0.776516531753353\n",
      "#Train#  epoch: 63, loss: 0.08977542817592621, dice: 0.9461239442366955\n",
      "#Val#  epoch: 63, dice: 0.785686701586525\n",
      "#Test#  epoch: 63, dice: 0.7687325696845924\n",
      "#Train#  epoch: 64, loss: 0.08947231620550156, dice: 0.9439061235059854\n",
      "#Val#  epoch: 64, dice: 0.7924654436776185\n",
      "#Test#  epoch: 64, dice: 0.779315911126271\n",
      "#Train#  epoch: 65, loss: 0.08858932554721832, dice: 0.9469070250989563\n",
      "#Val#  epoch: 65, dice: 0.7937780950443322\n",
      "#Test#  epoch: 65, dice: 0.7803923459390062\n",
      "#Train#  epoch: 66, loss: 0.08804292976856232, dice: 0.9460541479265533\n",
      "#Val#  epoch: 66, dice: 0.7906888958540236\n",
      "#Test#  epoch: 66, dice: 0.7731309352941451\n",
      "#Train#  epoch: 67, loss: 0.08720265328884125, dice: 0.9493580100599945\n",
      "#Val#  epoch: 67, dice: 0.7870438439383353\n",
      "#Test#  epoch: 67, dice: 0.7681847975983839\n",
      "#Train#  epoch: 68, loss: 0.0865684375166893, dice: 0.9498596921660566\n",
      "#Val#  epoch: 68, dice: 0.7937625325985609\n",
      "#Test#  epoch: 68, dice: 0.7801492490719774\n",
      "#Train#  epoch: 69, loss: 0.08564122766256332, dice: 0.9506988488606929\n",
      "#Val#  epoch: 69, dice: 0.7965612636811805\n",
      "#Test#  epoch: 69, dice: 0.7840326931724982\n",
      "#Train#  epoch: 70, loss: 0.08473315834999084, dice: 0.951476200138367\n",
      "#Val#  epoch: 70, dice: 0.7874463762485228\n",
      "#Test#  epoch: 70, dice: 0.7713653555438427\n",
      "#Train#  epoch: 71, loss: 0.08388396352529526, dice: 0.9522220514334048\n",
      "#Val#  epoch: 71, dice: 0.7922318212923086\n",
      "#Test#  epoch: 71, dice: 0.7746783095930165\n",
      "#Train#  epoch: 72, loss: 0.08312730491161346, dice: 0.954115154275932\n",
      "#Val#  epoch: 72, dice: 0.7975921828294009\n",
      "#Test#  epoch: 72, dice: 0.7830498265527506\n",
      "#Train#  epoch: 73, loss: 0.08244317770004272, dice: 0.9543228529535639\n",
      "#Val#  epoch: 73, dice: 0.7944250926326909\n",
      "#Test#  epoch: 73, dice: 0.7805327413866081\n",
      "#Train#  epoch: 74, loss: 0.08174775540828705, dice: 0.9561184556805523\n",
      "#Val#  epoch: 74, dice: 0.7913065586169291\n",
      "#Test#  epoch: 74, dice: 0.7759699418350945\n",
      "#Train#  epoch: 75, loss: 0.08121310919523239, dice: 0.9561292997906875\n",
      "#Val#  epoch: 75, dice: 0.7941962078800566\n",
      "#Test#  epoch: 75, dice: 0.7789319257766321\n",
      "#Train#  epoch: 76, loss: 0.08057244122028351, dice: 0.9567757149073031\n",
      "#Val#  epoch: 76, dice: 0.7936938951728033\n",
      "#Test#  epoch: 76, dice: 0.7781225419296367\n",
      "#Train#  epoch: 77, loss: 0.08008341491222382, dice: 0.9567607798530192\n",
      "#Val#  epoch: 77, dice: 0.7887931268413513\n",
      "#Test#  epoch: 77, dice: 0.7722958266402953\n",
      "#Train#  epoch: 78, loss: 0.07975637912750244, dice: 0.9550376812240376\n",
      "#Val#  epoch: 78, dice: 0.7928727473980449\n",
      "#Test#  epoch: 78, dice: 0.7791144743860069\n",
      "#Train#  epoch: 79, loss: 0.07957850396633148, dice: 0.9533533216037591\n",
      "#Val#  epoch: 79, dice: 0.7895281219829564\n",
      "#Test#  epoch: 79, dice: 0.77846433886253\n",
      "#Train#  epoch: 80, loss: 0.07924026250839233, dice: 0.9516889045734055\n",
      "#Val#  epoch: 80, dice: 0.7955444173494821\n",
      "#Test#  epoch: 80, dice: 0.7829946129334648\n",
      "#Train#  epoch: 81, loss: 0.07825500518083572, dice: 0.9571598080146694\n",
      "#Val#  epoch: 81, dice: 0.7962396646519575\n",
      "#Test#  epoch: 81, dice: 0.780933158415302\n",
      "#Train#  epoch: 82, loss: 0.07753024250268936, dice: 0.9600701666347528\n",
      "#Val#  epoch: 82, dice: 0.7929533535743859\n",
      "#Test#  epoch: 82, dice: 0.7790518706912916\n",
      "#Train#  epoch: 83, loss: 0.07741712778806686, dice: 0.9569297760331673\n",
      "#Val#  epoch: 83, dice: 0.7951750837656353\n",
      "#Test#  epoch: 83, dice: 0.781506661020106\n",
      "#Train#  epoch: 84, loss: 0.07677794247865677, dice: 0.9595310848298142\n",
      "#Val#  epoch: 84, dice: 0.793105533257756\n",
      "#Test#  epoch: 84, dice: 0.7776354330617278\n",
      "#Train#  epoch: 85, loss: 0.0761793702840805, dice: 0.9615159253349342\n",
      "#Val#  epoch: 85, dice: 0.7905871608874504\n",
      "#Test#  epoch: 85, dice: 0.7748627493360225\n",
      "#Train#  epoch: 86, loss: 0.07595076411962509, dice: 0.95968595658796\n",
      "#Val#  epoch: 86, dice: 0.7961777286318478\n",
      "#Test#  epoch: 86, dice: 0.7830800112607005\n",
      "#Train#  epoch: 87, loss: 0.07532286643981934, dice: 0.9620540780130548\n",
      "#Val#  epoch: 87, dice: 0.7952677426060456\n",
      "#Test#  epoch: 87, dice: 0.7804814517200759\n",
      "#Train#  epoch: 88, loss: 0.07487797737121582, dice: 0.9627509072440706\n",
      "#Val#  epoch: 88, dice: 0.791325972561342\n",
      "#Test#  epoch: 88, dice: 0.7762506105292064\n",
      "#Train#  epoch: 89, loss: 0.0745614618062973, dice: 0.9619310539461374\n",
      "#Val#  epoch: 89, dice: 0.7978338272738249\n",
      "#Test#  epoch: 89, dice: 0.7840914650254885\n",
      "#Train#  epoch: 90, loss: 0.0740128606557846, dice: 0.9638976515948126\n",
      "#Val#  epoch: 90, dice: 0.7946957718175125\n",
      "#Test#  epoch: 90, dice: 0.7809799507755022\n",
      "#Train#  epoch: 91, loss: 0.07361922413110733, dice: 0.9639394694970473\n",
      "#Val#  epoch: 91, dice: 0.7896328767739975\n",
      "#Test#  epoch: 91, dice: 0.7750129574761315\n",
      "#Train#  epoch: 92, loss: 0.07330787181854248, dice: 0.9636737488260328\n",
      "#Val#  epoch: 92, dice: 0.7958974961471756\n",
      "#Test#  epoch: 92, dice: 0.7803114372397975\n",
      "#Train#  epoch: 93, loss: 0.07279538363218307, dice: 0.9653554009888641\n",
      "#Val#  epoch: 93, dice: 0.7965250672889604\n",
      "#Test#  epoch: 93, dice: 0.7816343038647773\n",
      "#Train#  epoch: 94, loss: 0.07245548069477081, dice: 0.9651047080958579\n",
      "#Val#  epoch: 94, dice: 0.7923138738848708\n",
      "#Test#  epoch: 94, dice: 0.7782630638504959\n",
      "#Train#  epoch: 95, loss: 0.07208447903394699, dice: 0.9651849461309056\n",
      "#Val#  epoch: 95, dice: 0.7918373713857539\n",
      "#Test#  epoch: 95, dice: 0.7774633431815577\n",
      "#Train#  epoch: 96, loss: 0.07164093106985092, dice: 0.9662042451686476\n",
      "#Val#  epoch: 96, dice: 0.7980580595253902\n",
      "#Test#  epoch: 96, dice: 0.7842851207238816\n",
      "#Train#  epoch: 97, loss: 0.071317657828331, dice: 0.9663063124154597\n",
      "#Val#  epoch: 97, dice: 0.7918710562047182\n",
      "#Test#  epoch: 97, dice: 0.7755424889246879\n",
      "#Train#  epoch: 98, loss: 0.07103438675403595, dice: 0.965724803921988\n",
      "#Val#  epoch: 98, dice: 0.7921021189277727\n",
      "#Test#  epoch: 98, dice: 0.7791892277317528\n",
      "#Train#  epoch: 99, loss: 0.07088211178779602, dice: 0.9654020362030332\n",
      "#Val#  epoch: 99, dice: 0.792059551401172\n",
      "#Test#  epoch: 99, dice: 0.7784044552352796\n",
      "#Train#  epoch: 100, loss: 0.07086843252182007, dice: 0.9626838475862173\n",
      "#Val#  epoch: 100, dice: 0.7945168496369883\n",
      "#Test#  epoch: 100, dice: 0.78497717196573\n",
      "#Train#  epoch: 101, loss: 0.07088352739810944, dice: 0.9610641552509568\n",
      "#Val#  epoch: 101, dice: 0.7859691932042401\n",
      "#Test#  epoch: 101, dice: 0.7713857021538169\n",
      "#Train#  epoch: 102, loss: 0.0703887790441513, dice: 0.9623650634992922\n",
      "#Val#  epoch: 102, dice: 0.7982851298371397\n",
      "#Test#  epoch: 102, dice: 0.7893102147814224\n",
      "#Train#  epoch: 103, loss: 0.06931156665086746, dice: 0.9675804674603811\n",
      "#Val#  epoch: 103, dice: 0.7972774050800441\n",
      "#Test#  epoch: 103, dice: 0.7854514385719942\n",
      "#Train#  epoch: 104, loss: 0.06918035447597504, dice: 0.9663380609773784\n",
      "#Val#  epoch: 104, dice: 0.789351658046152\n",
      "#Test#  epoch: 104, dice: 0.7730088152802247\n",
      "#Train#  epoch: 105, loss: 0.06907308846712112, dice: 0.9650434571954812\n",
      "#Val#  epoch: 105, dice: 0.7952325734817995\n",
      "#Test#  epoch: 105, dice: 0.7819565403438622\n",
      "#Train#  epoch: 106, loss: 0.06833907961845398, dice: 0.9683300456785133\n",
      "#Val#  epoch: 106, dice: 0.7955837618138191\n",
      "#Test#  epoch: 106, dice: 0.7837196966458811\n",
      "#Train#  epoch: 107, loss: 0.06822217255830765, dice: 0.9676803685771175\n",
      "#Val#  epoch: 107, dice: 0.7939466755425627\n",
      "#Test#  epoch: 107, dice: 0.7796924779730122\n",
      "#Train#  epoch: 108, loss: 0.06793250143527985, dice: 0.967193224691979\n",
      "#Val#  epoch: 108, dice: 0.7951933913556571\n",
      "#Test#  epoch: 108, dice: 0.7819245487218265\n",
      "#Train#  epoch: 109, loss: 0.0673779770731926, dice: 0.9691292647513275\n",
      "#Val#  epoch: 109, dice: 0.7928639218260517\n",
      "#Test#  epoch: 109, dice: 0.7803364537331863\n",
      "#Train#  epoch: 110, loss: 0.06723037362098694, dice: 0.9687159509877917\n",
      "#Val#  epoch: 110, dice: 0.7948816916313937\n",
      "#Test#  epoch: 110, dice: 0.7821145241997404\n",
      "#Train#  epoch: 111, loss: 0.06685440987348557, dice: 0.9691335664503247\n",
      "#Val#  epoch: 111, dice: 0.7963451940295238\n",
      "#Test#  epoch: 111, dice: 0.7826542651126426\n",
      "#Train#  epoch: 112, loss: 0.06647162139415741, dice: 0.9698709390298175\n",
      "#Val#  epoch: 112, dice: 0.7933998438916565\n",
      "#Test#  epoch: 112, dice: 0.7786346742855237\n",
      "#Train#  epoch: 113, loss: 0.06624102592468262, dice: 0.9697490136276353\n",
      "#Val#  epoch: 113, dice: 0.7923676774929757\n",
      "#Test#  epoch: 113, dice: 0.7798364217734046\n",
      "#Train#  epoch: 114, loss: 0.06589516997337341, dice: 0.9702414363572502\n",
      "#Val#  epoch: 114, dice: 0.7953356423009614\n",
      "#Test#  epoch: 114, dice: 0.7827991623589212\n",
      "#Train#  epoch: 115, loss: 0.06555996090173721, dice: 0.9707421876083417\n",
      "#Val#  epoch: 115, dice: 0.793961295837528\n",
      "#Test#  epoch: 115, dice: 0.7804676225468739\n",
      "#Train#  epoch: 116, loss: 0.06536604464054108, dice: 0.9707116750951756\n",
      "#Val#  epoch: 116, dice: 0.7933287978158382\n",
      "#Test#  epoch: 116, dice: 0.7800743762017367\n",
      "#Train#  epoch: 117, loss: 0.06500442326068878, dice: 0.9710949812886\n",
      "#Val#  epoch: 117, dice: 0.7947928939350113\n",
      "#Test#  epoch: 117, dice: 0.7824949022160336\n",
      "#Train#  epoch: 118, loss: 0.06471940875053406, dice: 0.9713907218518755\n",
      "#Val#  epoch: 118, dice: 0.7937393409622711\n",
      "#Test#  epoch: 118, dice: 0.7803944381781057\n",
      "#Train#  epoch: 119, loss: 0.06450358033180237, dice: 0.9713944938118082\n",
      "#Val#  epoch: 119, dice: 0.793170358650728\n",
      "#Test#  epoch: 119, dice: 0.7787275372781638\n",
      "#Train#  epoch: 120, loss: 0.06417497247457504, dice: 0.9716288092730819\n",
      "#Val#  epoch: 120, dice: 0.7936976897430098\n",
      "#Test#  epoch: 120, dice: 0.7810096309109951\n",
      "#Train#  epoch: 121, loss: 0.0638943612575531, dice: 0.9718600071199263\n",
      "#Val#  epoch: 121, dice: 0.794380704526807\n",
      "#Test#  epoch: 121, dice: 0.7822416271629584\n",
      "#Train#  epoch: 122, loss: 0.06373219937086105, dice: 0.9716527225701069\n",
      "#Val#  epoch: 122, dice: 0.7916841430004344\n",
      "#Test#  epoch: 122, dice: 0.7783990260977363\n",
      "#Train#  epoch: 123, loss: 0.06358592212200165, dice: 0.9703296665847032\n",
      "#Val#  epoch: 123, dice: 0.7929458254657297\n",
      "#Test#  epoch: 123, dice: 0.7798789836752674\n",
      "#Train#  epoch: 124, loss: 0.0636831596493721, dice: 0.9685510169877328\n",
      "#Val#  epoch: 124, dice: 0.7862963887373197\n",
      "#Test#  epoch: 124, dice: 0.7751441428673662\n",
      "#Train#  epoch: 125, loss: 0.06409915536642075, dice: 0.9635738244748732\n",
      "#Val#  epoch: 125, dice: 0.7864001291192417\n",
      "#Test#  epoch: 125, dice: 0.7772788889496871\n",
      "#Train#  epoch: 126, loss: 0.06425604969263077, dice: 0.9622056788802247\n",
      "#Val#  epoch: 126, dice: 0.7943454919008363\n",
      "#Test#  epoch: 126, dice: 0.784517657968981\n",
      "#Train#  epoch: 127, loss: 0.06281264871358871, dice: 0.9691654169506668\n",
      "#Val#  epoch: 127, dice: 0.7942661542185094\n",
      "#Test#  epoch: 127, dice: 0.7839194478420712\n",
      "#Train#  epoch: 128, loss: 0.06281789392232895, dice: 0.9679740317521857\n",
      "#Val#  epoch: 128, dice: 0.7929083326545701\n",
      "#Test#  epoch: 128, dice: 0.7802553568825827\n",
      "#Train#  epoch: 129, loss: 0.06261216104030609, dice: 0.9680885795923446\n",
      "#Val#  epoch: 129, dice: 0.7954387603794222\n",
      "#Test#  epoch: 129, dice: 0.7815157204790554\n",
      "#Train#  epoch: 130, loss: 0.06197020038962364, dice: 0.9707709036019696\n",
      "#Val#  epoch: 130, dice: 0.7933874824631324\n",
      "#Test#  epoch: 130, dice: 0.7836074548976599\n",
      "#Train#  epoch: 131, loss: 0.06211480498313904, dice: 0.9687755609099366\n",
      "#Val#  epoch: 131, dice: 0.7966688076862152\n",
      "#Test#  epoch: 131, dice: 0.7888494696388086\n",
      "#Train#  epoch: 132, loss: 0.061636120080947876, dice: 0.9701482762022275\n",
      "#Val#  epoch: 132, dice: 0.7923948803621216\n",
      "#Test#  epoch: 132, dice: 0.7787542056750898\n",
      "#Train#  epoch: 133, loss: 0.06135761737823486, dice: 0.9709569462523802\n",
      "#Val#  epoch: 133, dice: 0.7928606986497762\n",
      "#Test#  epoch: 133, dice: 0.781796769437455\n",
      "#Train#  epoch: 134, loss: 0.061147816479206085, dice: 0.9709256257259757\n",
      "#Val#  epoch: 134, dice: 0.7970543620483428\n",
      "#Test#  epoch: 134, dice: 0.787147969746195\n",
      "#Train#  epoch: 135, loss: 0.06080835685133934, dice: 0.9718967045587202\n",
      "#Val#  epoch: 135, dice: 0.796062315378689\n",
      "#Test#  epoch: 135, dice: 0.7855063533026776\n",
      "#Train#  epoch: 136, loss: 0.060593705624341965, dice: 0.9719062240854558\n",
      "#Val#  epoch: 136, dice: 0.7932879467605166\n",
      "#Test#  epoch: 136, dice: 0.7823222255310053\n",
      "#Train#  epoch: 137, loss: 0.0602288655936718, dice: 0.9727634694498459\n",
      "#Val#  epoch: 137, dice: 0.7925596745153954\n",
      "#Test#  epoch: 137, dice: 0.780552801277545\n",
      "#Train#  epoch: 138, loss: 0.060072313994169235, dice: 0.9723391886879519\n",
      "#Val#  epoch: 138, dice: 0.7970793350431871\n",
      "#Test#  epoch: 138, dice: 0.7867755127818307\n",
      "#Train#  epoch: 139, loss: 0.05977344140410423, dice: 0.9733932301603212\n",
      "#Val#  epoch: 139, dice: 0.795726341533419\n",
      "#Test#  epoch: 139, dice: 0.7852793628628281\n",
      "#Train#  epoch: 140, loss: 0.05961619317531586, dice: 0.9730446212757078\n",
      "#Val#  epoch: 140, dice: 0.7917659621557358\n",
      "#Test#  epoch: 140, dice: 0.7798194550440652\n",
      "#Train#  epoch: 141, loss: 0.05925528332591057, dice: 0.9738688762690496\n",
      "#Val#  epoch: 141, dice: 0.7935883252616309\n",
      "#Test#  epoch: 141, dice: 0.7811375554716051\n",
      "#Train#  epoch: 142, loss: 0.05906444042921066, dice: 0.9738117684529665\n",
      "#Val#  epoch: 142, dice: 0.796753927740045\n",
      "#Test#  epoch: 142, dice: 0.7846558030657285\n",
      "#Train#  epoch: 143, loss: 0.05881930887699127, dice: 0.9740934532994452\n",
      "#Val#  epoch: 143, dice: 0.7947581923822732\n",
      "#Test#  epoch: 143, dice: 0.783427117297562\n",
      "#Train#  epoch: 144, loss: 0.058575164526700974, dice: 0.9743115859063952\n",
      "#Val#  epoch: 144, dice: 0.7942299174987013\n",
      "#Test#  epoch: 144, dice: 0.7829771266590834\n",
      "#Train#  epoch: 145, loss: 0.05839529260993004, dice: 0.9743225672075629\n",
      "#Val#  epoch: 145, dice: 0.7952004777255407\n",
      "#Test#  epoch: 145, dice: 0.7850288256135868\n",
      "#Train#  epoch: 146, loss: 0.05811316519975662, dice: 0.9746951834534248\n",
      "#Val#  epoch: 146, dice: 0.795424280029433\n",
      "#Test#  epoch: 146, dice: 0.7841774284601482\n",
      "#Train#  epoch: 147, loss: 0.05788703262805939, dice: 0.9749054836507348\n",
      "#Val#  epoch: 147, dice: 0.7943675045693741\n",
      "#Test#  epoch: 147, dice: 0.7837602423422309\n",
      "#Train#  epoch: 148, loss: 0.05766644328832626, dice: 0.9751009868730918\n",
      "#Val#  epoch: 148, dice: 0.7942062799228027\n",
      "#Test#  epoch: 148, dice: 0.7834860940982469\n",
      "#Train#  epoch: 149, loss: 0.05745114013552666, dice: 0.9752729069487417\n",
      "#Val#  epoch: 149, dice: 0.7954790598588123\n",
      "#Test#  epoch: 149, dice: 0.7843446955355611\n",
      "#Train#  epoch: 150, loss: 0.05723636597394943, dice: 0.9754410576899377\n",
      "#Val#  epoch: 150, dice: 0.7943082998384734\n",
      "#Test#  epoch: 150, dice: 0.7828612282733834\n",
      "#Train#  epoch: 151, loss: 0.05701566860079765, dice: 0.9754009342048638\n",
      "#Val#  epoch: 151, dice: 0.7931168800425246\n",
      "#Test#  epoch: 151, dice: 0.7837781238498231\n",
      "#Train#  epoch: 152, loss: 0.056852858513593674, dice: 0.9753555846311512\n",
      "#Val#  epoch: 152, dice: 0.7951641926943869\n",
      "#Test#  epoch: 152, dice: 0.7832281414347823\n",
      "#Train#  epoch: 153, loss: 0.056717973202466965, dice: 0.9749251776624852\n",
      "#Val#  epoch: 153, dice: 0.7941835081626372\n",
      "#Test#  epoch: 153, dice: 0.7847291535923517\n",
      "#Train#  epoch: 154, loss: 0.0567505806684494, dice: 0.9735331024047003\n",
      "#Val#  epoch: 154, dice: 0.7897275560583983\n",
      "#Test#  epoch: 154, dice: 0.7801498263849226\n",
      "#Train#  epoch: 155, loss: 0.05703723430633545, dice: 0.9708535837944396\n",
      "#Val#  epoch: 155, dice: 0.7915317663715614\n",
      "#Test#  epoch: 155, dice: 0.7838313279260243\n",
      "#Train#  epoch: 156, loss: 0.05734022706747055, dice: 0.9689582066135769\n",
      "#Val#  epoch: 156, dice: 0.7925822637077038\n",
      "#Test#  epoch: 156, dice: 0.7821850164685444\n",
      "#Train#  epoch: 157, loss: 0.05663949251174927, dice: 0.9705912112155318\n",
      "#Val#  epoch: 157, dice: 0.7953244262824408\n",
      "#Test#  epoch: 157, dice: 0.7855351410562567\n",
      "#Train#  epoch: 158, loss: 0.0557643286883831, dice: 0.9748974137483507\n",
      "#Val#  epoch: 158, dice: 0.7922906318234239\n",
      "#Test#  epoch: 158, dice: 0.7841637075109172\n",
      "#Train#  epoch: 159, loss: 0.05579804629087448, dice: 0.9737809240768956\n",
      "#Val#  epoch: 159, dice: 0.7959600116473878\n",
      "#Test#  epoch: 159, dice: 0.7867776414612503\n",
      "#Train#  epoch: 160, loss: 0.05561324954032898, dice: 0.9735723054701869\n",
      "#Val#  epoch: 160, dice: 0.7927348240180246\n",
      "#Test#  epoch: 160, dice: 0.7826149764579924\n",
      "#Train#  epoch: 161, loss: 0.05529940873384476, dice: 0.9743862914309085\n",
      "#Val#  epoch: 161, dice: 0.789556269222649\n",
      "#Test#  epoch: 161, dice: 0.7799340658250873\n",
      "#Train#  epoch: 162, loss: 0.05496426671743393, dice: 0.9752552394041242\n",
      "#Val#  epoch: 162, dice: 0.7958329374485549\n",
      "#Test#  epoch: 162, dice: 0.7883269795607888\n",
      "#Train#  epoch: 163, loss: 0.05490797385573387, dice: 0.9742717324591208\n",
      "#Val#  epoch: 163, dice: 0.7953352355937506\n",
      "#Test#  epoch: 163, dice: 0.785016567276901\n",
      "#Train#  epoch: 164, loss: 0.05456578731536865, dice: 0.9754658589507159\n",
      "#Val#  epoch: 164, dice: 0.7929341859701897\n",
      "#Test#  epoch: 164, dice: 0.7814101138953448\n",
      "#Train#  epoch: 165, loss: 0.054332926869392395, dice: 0.9757506902203539\n",
      "#Val#  epoch: 165, dice: 0.7949291784154312\n",
      "#Test#  epoch: 165, dice: 0.7858248414041545\n",
      "#Train#  epoch: 166, loss: 0.054277338087558746, dice: 0.9751816368088023\n",
      "#Val#  epoch: 166, dice: 0.793964935128283\n",
      "#Test#  epoch: 166, dice: 0.7830323443368886\n",
      "#Train#  epoch: 167, loss: 0.054010309278964996, dice: 0.9759237680677109\n",
      "#Val#  epoch: 167, dice: 0.794899356284201\n",
      "#Test#  epoch: 167, dice: 0.7859866754008054\n",
      "#Train#  epoch: 168, loss: 0.05372091755270958, dice: 0.976525250965242\n",
      "#Val#  epoch: 168, dice: 0.7959515228545802\n",
      "#Test#  epoch: 168, dice: 0.787143889294122\n",
      "#Train#  epoch: 169, loss: 0.05359749495983124, dice: 0.9760623397818987\n",
      "#Val#  epoch: 169, dice: 0.7931492091195225\n",
      "#Test#  epoch: 169, dice: 0.7812865571223113\n",
      "#Train#  epoch: 170, loss: 0.053305771201848984, dice: 0.9767139661943487\n",
      "#Val#  epoch: 170, dice: 0.7943407336588333\n",
      "#Test#  epoch: 170, dice: 0.7845511633359191\n",
      "#Train#  epoch: 171, loss: 0.05309530347585678, dice: 0.9770023371411528\n",
      "#Val#  epoch: 171, dice: 0.7959868070857369\n",
      "#Test#  epoch: 171, dice: 0.7861535896476888\n",
      "#Train#  epoch: 172, loss: 0.052970483899116516, dice: 0.9766561681760052\n",
      "#Val#  epoch: 172, dice: 0.7943832536717241\n",
      "#Test#  epoch: 172, dice: 0.7827020860976228\n",
      "#Train#  epoch: 173, loss: 0.05273249372839928, dice: 0.9769839877997668\n",
      "#Val#  epoch: 173, dice: 0.7942464163963104\n",
      "#Test#  epoch: 173, dice: 0.7850115771438848\n",
      "#Train#  epoch: 174, loss: 0.0526115745306015, dice: 0.9766274260705194\n",
      "#Val#  epoch: 174, dice: 0.7950158694849149\n",
      "#Test#  epoch: 174, dice: 0.7853566839129116\n",
      "#Train#  epoch: 175, loss: 0.0525776669383049, dice: 0.975270984544517\n",
      "#Val#  epoch: 175, dice: 0.790935480588403\n",
      "#Test#  epoch: 175, dice: 0.7825849821740439\n",
      "#Train#  epoch: 176, loss: 0.0527399405837059, dice: 0.9729077221001127\n",
      "#Val#  epoch: 176, dice: 0.7910743065342714\n",
      "#Test#  epoch: 176, dice: 0.7813569569253818\n",
      "#Train#  epoch: 177, loss: 0.053302567452192307, dice: 0.969173944824391\n",
      "#Val#  epoch: 177, dice: 0.789040310996389\n",
      "#Test#  epoch: 177, dice: 0.7816699194517118\n",
      "#Train#  epoch: 178, loss: 0.053268350660800934, dice: 0.9691363488422169\n",
      "#Val#  epoch: 178, dice: 0.7946740714623567\n",
      "#Test#  epoch: 178, dice: 0.7886317472657745\n",
      "#Train#  epoch: 179, loss: 0.05200181156396866, dice: 0.9747729204782762\n",
      "#Val#  epoch: 179, dice: 0.7958785539260597\n",
      "#Test#  epoch: 179, dice: 0.7857645518818906\n",
      "#Train#  epoch: 180, loss: 0.05176180228590965, dice: 0.9752549568963403\n",
      "#Val#  epoch: 180, dice: 0.7899007670743401\n",
      "#Test#  epoch: 180, dice: 0.7807560682806753\n",
      "#Train#  epoch: 181, loss: 0.052168108522892, dice: 0.9724986057474043\n",
      "#Val#  epoch: 181, dice: 0.7949514660262184\n",
      "#Test#  epoch: 181, dice: 0.7890811824729375\n",
      "#Train#  epoch: 182, loss: 0.05150160938501358, dice: 0.9750040084789795\n",
      "#Val#  epoch: 182, dice: 0.7963722859347353\n",
      "#Test#  epoch: 182, dice: 0.7855752526459487\n",
      "#Train#  epoch: 183, loss: 0.051320046186447144, dice: 0.9752635490929491\n",
      "#Val#  epoch: 183, dice: 0.793009786555122\n",
      "#Test#  epoch: 183, dice: 0.7826819444521764\n",
      "#Train#  epoch: 184, loss: 0.05128416419029236, dice: 0.9747034663042679\n",
      "#Val#  epoch: 184, dice: 0.7937611303351115\n",
      "#Test#  epoch: 184, dice: 0.7855389399585104\n",
      "#Train#  epoch: 185, loss: 0.05089261755347252, dice: 0.9760044982401327\n",
      "#Val#  epoch: 185, dice: 0.7943461540488026\n",
      "#Test#  epoch: 185, dice: 0.7848514836427216\n",
      "#Train#  epoch: 186, loss: 0.05078951269388199, dice: 0.9754778191456672\n",
      "#Val#  epoch: 186, dice: 0.7946890023936404\n",
      "#Test#  epoch: 186, dice: 0.7855214721361485\n",
      "#Train#  epoch: 187, loss: 0.05049329251050949, dice: 0.9761470414346778\n",
      "#Val#  epoch: 187, dice: 0.7958401944971866\n",
      "#Test#  epoch: 187, dice: 0.7887041473995811\n",
      "#Train#  epoch: 188, loss: 0.05030547082424164, dice: 0.976455023918858\n",
      "#Val#  epoch: 188, dice: 0.7951946331918549\n",
      "#Test#  epoch: 188, dice: 0.7848044866099393\n",
      "#Train#  epoch: 189, loss: 0.05010311305522919, dice: 0.976729414625311\n",
      "#Val#  epoch: 189, dice: 0.7947021134392499\n",
      "#Test#  epoch: 189, dice: 0.7840682007706428\n",
      "#Train#  epoch: 190, loss: 0.049836426973342896, dice: 0.9774483405153556\n",
      "#Val#  epoch: 190, dice: 0.7966672352646926\n",
      "#Test#  epoch: 190, dice: 0.7887730807657175\n",
      "#Train#  epoch: 191, loss: 0.04977327212691307, dice: 0.9769558426896939\n",
      "#Val#  epoch: 191, dice: 0.795773513363328\n",
      "#Test#  epoch: 191, dice: 0.7855923046886639\n",
      "#Train#  epoch: 192, loss: 0.04951595515012741, dice: 0.9778090183958008\n",
      "#Val#  epoch: 192, dice: 0.7941805214493336\n",
      "#Test#  epoch: 192, dice: 0.7839985834800111\n",
      "#Train#  epoch: 193, loss: 0.04934500902891159, dice: 0.9783804943254141\n",
      "#Val#  epoch: 193, dice: 0.7957331258407915\n",
      "#Test#  epoch: 193, dice: 0.7876320549317376\n",
      "#Train#  epoch: 194, loss: 0.049195654690265656, dice: 0.9785123000834031\n",
      "#Val#  epoch: 194, dice: 0.7963877159510253\n",
      "#Test#  epoch: 194, dice: 0.7863783843209509\n",
      "#Train#  epoch: 195, loss: 0.048931919038295746, dice: 0.9794821380546349\n",
      "#Val#  epoch: 195, dice: 0.795630371418819\n",
      "#Test#  epoch: 195, dice: 0.7850239475581906\n",
      "#Train#  epoch: 196, loss: 0.04879049211740494, dice: 0.9795410776255814\n",
      "#Val#  epoch: 196, dice: 0.7955946855480589\n",
      "#Test#  epoch: 196, dice: 0.7880084896690382\n",
      "#Train#  epoch: 197, loss: 0.0485718697309494, dice: 0.9805023038050369\n",
      "#Val#  epoch: 197, dice: 0.7956668572269351\n",
      "#Test#  epoch: 197, dice: 0.7864090772429578\n",
      "#Train#  epoch: 198, loss: 0.048408981412649155, dice: 0.9808246440604873\n",
      "#Val#  epoch: 198, dice: 0.7952234645101157\n",
      "#Test#  epoch: 198, dice: 0.7845074990843274\n",
      "#Train#  epoch: 199, loss: 0.04823610931634903, dice: 0.9811764072204869\n",
      "#Val#  epoch: 199, dice: 0.7961711247379157\n",
      "#Test#  epoch: 199, dice: 0.7872501010406449\n",
      "#Train#  epoch: 200, loss: 0.048033829778432846, dice: 0.9815811394034585\n",
      "#Val#  epoch: 200, dice: 0.7955937883741065\n",
      "#Test#  epoch: 200, dice: 0.7873407976029255\n"
     ]
    }
   ],
   "source": [
    "print('#----------Start training----------#')\n",
    "torch.cuda.empty_cache()\n",
    "info = \"%d-resizeh, %d-resizew, %f-outer_lr\"%(config.resize_h,config.resize_w,config.outer_lr)\n",
    "print(info)\n",
    "logger.info(info)\n",
    "best_dice_val = 0.0\n",
    "best_dice_test = 0.0\n",
    "train_csv = os.path.join(csv_save,\"train.csv\")\n",
    "val_csv = os.path.join(csv_save,\"val.csv\")\n",
    "test_csv = os.path.join(csv_save,\"test.csv\")\n",
    "train_columns = ['Epoch','Loss',\"Mdice\"]\n",
    "train_df = pd.DataFrame(columns=train_columns)\n",
    "val_columns = ['Epoch','Mdice']\n",
    "val_df = pd.DataFrame(columns=val_columns)\n",
    "test_columns = ['Epoch','Mdice']\n",
    "test_df = pd.DataFrame(columns=test_columns)\n",
    "for epoch in range(start_epoch, config.epoch_num+1):\n",
    "    \n",
    "    # train part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    loss_list = []    \n",
    "    base_net.train()\n",
    "    meta_optimizer.zero_grad()\n",
    "    for category_index in range(num_categories):\n",
    "        for image,mask in train_loader_list[category_index]:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)     # torch.Size([bs,out_channels=1,512,512])\n",
    "            predicted = predicted.squeeze(1)    # torch.Size([bs,512,512])\n",
    "            loss = criterion(predicted,mask)\n",
    "            loss = loss/num_categories\n",
    "            loss.backward()\n",
    "            predicted = (predicted > threshold).long()\n",
    "            temp_predicted = predicted.cpu().detach().numpy()       # threshold alternative\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "    meta_optimizer.step()\n",
    "    loss_list.append(loss.cpu().detach().numpy())\n",
    "    \n",
    "    # train_dice,train_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "    train_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "    train_mloss = np.mean(loss_list)\n",
    "    log_train = f'epoch: {epoch}, loss: {train_mloss}, dice: {train_dice}'\n",
    "    print(\"#Train# \",log_train)\n",
    "    temp_result = pd.Series([epoch,train_mloss,train_dice],index=train_columns)\n",
    "    train_df = train_df.append(temp_result, ignore_index=True)\n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    \n",
    "    # validation part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in val_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "        # val_dice,val_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        val_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_val = f'epoch: {epoch}, dice: {val_dice}'\n",
    "        print(\"#Val# \",log_val)\n",
    "        temp_result = pd.Series([epoch,val_dice],index=val_columns)\n",
    "        val_df = val_df.append(temp_result, ignore_index=True)\n",
    "        val_df.to_csv(val_csv, index=False)\n",
    "        # logger.info(log_val)\n",
    "\n",
    "    if val_dice > best_dice_val:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_val.pth'))\n",
    "        best_dice_val = val_dice\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # test part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in test_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "        # test_dice,test_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        test_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_test = f'epoch: {epoch}, dice: {test_dice}'\n",
    "        print(\"#Test# \",log_test)\n",
    "        temp_result = pd.Series([epoch,test_dice],index=test_columns)\n",
    "        test_df = test_df.append(temp_result, ignore_index=True)\n",
    "        test_df.to_csv(test_csv, index=False)\n",
    "        logger.info(log_test)\n",
    "\n",
    "    if test_dice > best_dice_test:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_test.pth'))\n",
    "        best_dice_test = test_dice\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best dice in testset:0.7893102147814224\n"
     ]
    }
   ],
   "source": [
    "best_result_test = \"Best dice in testset:\" + str(best_dice_test)\n",
    "print(best_result_test)\n",
    "logger.info(best_result_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
