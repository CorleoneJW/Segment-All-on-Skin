{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import *\n",
    "from models.meta import Meta\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from models.basenet import *\n",
    "from utils import *\n",
    "from configs.config_setting_baseline import setting_config\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics as metrics\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.init as init\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = setting_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    support_images = batch['support_images'].squeeze(0)\n",
    "    support_masks = batch['support_masks'].squeeze(0)\n",
    "    query_images = batch['query_images'].squeeze(0)\n",
    "    query_masks = batch['query_masks'].squeeze(0)\n",
    "    return support_images, support_masks, query_images, query_masks\n",
    "\n",
    "# the function of copying the images\n",
    "def copy_file_to_folder(source_file, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    dest_path = os.path.join(dest_folder, os.path.basename(source_file))\n",
    "    shutil.copy(source_file, dest_path)\n",
    "\n",
    "def evaluation_api(predicted_list,groudtruth_list):\n",
    "    pre = np.array([item for sublist in predicted_list for item in sublist]).reshape(-1)\n",
    "    gts = np.array([item for sublist in groudtruth_list for item in sublist]).reshape(-1)\n",
    "    # confusion_matrix = metrics.confusion_matrix(gts,pre)\n",
    "    # TN, FP, FN, TP = confusion[0,0], confusion[0,1], confusion[1,0], confusion[1,1] \n",
    "    dice = metrics.f1_score(gts,pre)\n",
    "\n",
    "    return dice\n",
    "\n",
    "def evaluation_epoch(predicted_list,groundtruth_list):\n",
    "    TP = [0]*config.num_classes\n",
    "    FP = [0]*config.num_classes\n",
    "    FN = [0]*config.num_classes\n",
    "    dice = [0.0]*config.num_classes\n",
    "    \n",
    "    for i in range(len(predicted_list)):\n",
    "        preds = np.array(predicted_list[i]).reshape(-1)\n",
    "        gts = np.array(groundtruth_list[i]).reshape(-1)\n",
    "        for j in range(len(preds)):\n",
    "            if preds[j] == gts[j]:\n",
    "                TP[gts[j]] += 1\n",
    "            else:\n",
    "                FP[preds[j]] += 1\n",
    "                FN[gts[j]] += 1        \n",
    "    \n",
    "    for i in range(config.num_classes):\n",
    "        dice[i] = (2 * TP[i])/(FP[i]+FN[i]+2*TP[i]+1)\n",
    "\n",
    "    mdice = (2*np.sum(TP))/(np.sum(FP)+np.sum(FN)+2*np.sum(TP)+1)    \n",
    "    return dice,mdice\n",
    "\n",
    "def evaluation_basenet(base_net,query_images,query_masks,criterion):\n",
    "    predicted = base_net(query_images)\n",
    "    loss = criterion(predicted,query_masks)\n",
    "    predicted = torch.argmax(predicted,dim=1).long()\n",
    "    predict_numpy = predicted.detach().cpu().numpy().reshape(-1)\n",
    "    masks_numpy = query_masks.long().detach().cpu().numpy().reshape(-1)\n",
    "    accuracy = metrics.accuracy_score(masks_numpy,predict_numpy)\n",
    "    f1_score = metrics.f1_score(masks_numpy,predict_numpy,average=None)\n",
    "    return accuracy,f1_score,loss\n",
    "\n",
    "def initialize_weights_he(model):\n",
    "    for param in model.parameters():\n",
    "        init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "def initialize_weights_xavier(model):\n",
    "    for param in model.parameters():\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "def initialize_weights_normal(model):\n",
    "    for param in model.parameters():\n",
    "        init.normal_(param, mean=0, std=1)\n",
    "\n",
    "def remove_exsits_folder(folderpath):\n",
    "    if os.path.exists(folderpath):\n",
    "        shutil.rmtree(folderpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Creating logger----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Creating logger----------#')\n",
    "sys.path.append(config.work_dir + '/')\n",
    "log_dir = os.path.join(config.work_dir, 'log')\n",
    "checkpoint_dir = os.path.join(config.work_dir, 'checkpoints')\n",
    "resume_model = os.path.join(checkpoint_dir, 'latest.pth')\n",
    "outputs = os.path.join(config.work_dir, 'outputs')\n",
    "csv_save = os.path.join(config.work_dir, 'csv')\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "if not os.path.exists(csv_save):\n",
    "    os.makedirs(csv_save)\n",
    "\n",
    "global logger\n",
    "logger = get_logger('test', log_dir)\n",
    "global writer\n",
    "writer = SummaryWriter(config.work_dir + 'summary')\n",
    "\n",
    "log_config_info(config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------GPU init----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------GPU init----------#')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu_id\n",
    "set_seed(config.seed)\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Datasets----------#\n",
      "trian_dataset length: 900\n",
      "val_dataset length: 546\n",
      "test_dataset length: 546\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Datasets----------#')\n",
    "# create the dataset and dataloader\n",
    "batch_size = config.batch_size\n",
    "train_dataset = HAMALL_datasets(config, train=True)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "val_dataset = HAMALL_datasets(config, train=False,val=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "test_dataset = HAMALL_datasets(config, train=False)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "print(\"trian_dataset length:\",len(train_dataset))\n",
    "print(\"val_dataset length:\",len(val_dataset))\n",
    "print(\"test_dataset length:\",len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Model----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Model----------#')\n",
    "in_channels = config.in_channels\n",
    "out_channels = config.out_channels\n",
    "base_net = smp.Unet(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# base_net = smp.UnetPlusPlus(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# initialize_weights_he(base_net)\n",
    "base_net = base_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing loss, opt, sch and amp----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing loss, opt, sch and amp----------#')\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "meta_optimizer = get_optimizer(config, base_net)\n",
    "meta_scheduler = get_scheduler(config, meta_optimizer)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Set other params----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Set other params----------#')\n",
    "min_loss = 999\n",
    "start_epoch = 1\n",
    "min_epoch = 1\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Start training----------#\n",
      "128-resizeh, 128-resizew, 0.000100-outer_lr\n",
      "#Train#  epoch: 1, loss: 0.6088895201683044, dice: 0.6131106248781977\n",
      "#Val#  epoch: 1, dice: 0.6626652295672113\n",
      "#Test#  epoch: 1, dice: 0.6816687876800144\n",
      "#Train#  epoch: 2, loss: 0.46793049573898315, dice: 0.7169476172826484\n",
      "#Val#  epoch: 2, dice: 0.6903764031287335\n",
      "#Test#  epoch: 2, dice: 0.6774759883309243\n",
      "#Train#  epoch: 3, loss: 0.4144618809223175, dice: 0.7616970119930201\n",
      "#Val#  epoch: 3, dice: 0.6701026418648544\n",
      "#Test#  epoch: 3, dice: 0.6235649726331698\n",
      "#Train#  epoch: 4, loss: 0.3680786192417145, dice: 0.8099765705879147\n",
      "#Val#  epoch: 4, dice: 0.7625660041080887\n",
      "#Test#  epoch: 4, dice: 0.7570327790362006\n",
      "#Train#  epoch: 5, loss: 0.3456106185913086, dice: 0.8244840877984725\n",
      "#Val#  epoch: 5, dice: 0.6632573186926352\n",
      "#Test#  epoch: 5, dice: 0.6392283446593682\n",
      "#Train#  epoch: 6, loss: 0.31706714630126953, dice: 0.8462579911245729\n",
      "#Val#  epoch: 6, dice: 0.33261880272672895\n",
      "#Test#  epoch: 6, dice: 0.3393585200693391\n",
      "#Train#  epoch: 7, loss: 0.29803401231765747, dice: 0.8578106628089596\n",
      "#Val#  epoch: 7, dice: 0.7795198575829284\n",
      "#Test#  epoch: 7, dice: 0.773336440809389\n",
      "#Train#  epoch: 8, loss: 0.2768588662147522, dice: 0.8726674607745207\n",
      "#Val#  epoch: 8, dice: 0.6279842876329517\n",
      "#Test#  epoch: 8, dice: 0.6182548606392555\n",
      "#Train#  epoch: 9, loss: 0.257974237203598, dice: 0.8833603884404421\n",
      "#Val#  epoch: 9, dice: 0.5253178139306737\n",
      "#Test#  epoch: 9, dice: 0.5245084600469805\n",
      "#Train#  epoch: 10, loss: 0.24865926802158356, dice: 0.8846476250085096\n",
      "#Val#  epoch: 10, dice: 0.7599147597191581\n",
      "#Test#  epoch: 10, dice: 0.7521014042178817\n",
      "#Train#  epoch: 11, loss: 0.227617546916008, dice: 0.9010090428019714\n",
      "#Val#  epoch: 11, dice: 0.7102196227641063\n",
      "#Test#  epoch: 11, dice: 0.7301275872954678\n",
      "#Train#  epoch: 12, loss: 0.2252890169620514, dice: 0.8955993573224199\n",
      "#Val#  epoch: 12, dice: 0.7557824852905128\n",
      "#Test#  epoch: 12, dice: 0.7445826934574943\n",
      "#Train#  epoch: 13, loss: 0.21733783185482025, dice: 0.8929945885638634\n",
      "#Val#  epoch: 13, dice: 0.5945240889104022\n",
      "#Test#  epoch: 13, dice: 0.5991042059812188\n",
      "#Train#  epoch: 14, loss: 0.19897675514221191, dice: 0.9143001882892591\n",
      "#Val#  epoch: 14, dice: 0.7749050959761006\n",
      "#Test#  epoch: 14, dice: 0.7727905372247909\n",
      "#Train#  epoch: 15, loss: 0.1878143846988678, dice: 0.9171939547875108\n",
      "#Val#  epoch: 15, dice: 0.7751797709106502\n",
      "#Test#  epoch: 15, dice: 0.7638873851547618\n",
      "#Train#  epoch: 16, loss: 0.17742128670215607, dice: 0.921729672391588\n",
      "#Val#  epoch: 16, dice: 0.7572803700618994\n",
      "#Test#  epoch: 16, dice: 0.7464906467618416\n",
      "#Train#  epoch: 17, loss: 0.16503289341926575, dice: 0.9311097156296526\n",
      "#Val#  epoch: 17, dice: 0.7767637303339637\n",
      "#Test#  epoch: 17, dice: 0.7679516234983746\n",
      "#Train#  epoch: 18, loss: 0.15701930224895477, dice: 0.9376144338334176\n",
      "#Val#  epoch: 18, dice: 0.747610978764024\n",
      "#Test#  epoch: 18, dice: 0.7431049785931275\n",
      "#Train#  epoch: 19, loss: 0.1527831107378006, dice: 0.9339867438202473\n",
      "#Val#  epoch: 19, dice: 0.764635171642236\n",
      "#Test#  epoch: 19, dice: 0.7530737024401287\n",
      "#Train#  epoch: 20, loss: 0.1554081290960312, dice: 0.9274208984824787\n",
      "#Val#  epoch: 20, dice: 0.7817733757703893\n",
      "#Test#  epoch: 20, dice: 0.7772007127578183\n",
      "#Train#  epoch: 21, loss: 0.15627066791057587, dice: 0.9219287362205719\n",
      "#Val#  epoch: 21, dice: 0.7240728861159802\n",
      "#Test#  epoch: 21, dice: 0.7178951975419895\n",
      "#Train#  epoch: 22, loss: 0.1491798460483551, dice: 0.9271444159038054\n",
      "#Val#  epoch: 22, dice: 0.7657940041827599\n",
      "#Test#  epoch: 22, dice: 0.7544318796135117\n",
      "#Train#  epoch: 23, loss: 0.13383521139621735, dice: 0.936722943695644\n",
      "#Val#  epoch: 23, dice: 0.7896021070409328\n",
      "#Test#  epoch: 23, dice: 0.7805864279913449\n",
      "#Train#  epoch: 24, loss: 0.12369117140769958, dice: 0.9453870341675958\n",
      "#Val#  epoch: 24, dice: 0.7915414153842686\n",
      "#Test#  epoch: 24, dice: 0.781436303249263\n",
      "#Train#  epoch: 25, loss: 0.1134214699268341, dice: 0.9531426051039161\n",
      "#Val#  epoch: 25, dice: 0.7948750499863529\n",
      "#Test#  epoch: 25, dice: 0.7836082331745428\n",
      "#Train#  epoch: 26, loss: 0.10699586570262909, dice: 0.9540147511876211\n",
      "#Val#  epoch: 26, dice: 0.7747298017034667\n",
      "#Test#  epoch: 26, dice: 0.7681389905284526\n",
      "#Train#  epoch: 27, loss: 0.10306274145841599, dice: 0.955725552384712\n",
      "#Val#  epoch: 27, dice: 0.7966393273593226\n",
      "#Test#  epoch: 27, dice: 0.7874528946604518\n",
      "#Train#  epoch: 28, loss: 0.09779439121484756, dice: 0.960178651617842\n",
      "#Val#  epoch: 28, dice: 0.7846756108140416\n",
      "#Test#  epoch: 28, dice: 0.7738062760695235\n",
      "#Train#  epoch: 29, loss: 0.09851880371570587, dice: 0.9555718271004358\n",
      "#Val#  epoch: 29, dice: 0.7928053141087272\n",
      "#Test#  epoch: 29, dice: 0.7853444883835798\n",
      "#Train#  epoch: 30, loss: 0.09634075313806534, dice: 0.9536590422223759\n",
      "#Val#  epoch: 30, dice: 0.797829852078688\n",
      "#Test#  epoch: 30, dice: 0.7912375903217741\n",
      "#Train#  epoch: 31, loss: 0.09542886167764664, dice: 0.954181373331531\n",
      "#Val#  epoch: 31, dice: 0.7862110530737481\n",
      "#Test#  epoch: 31, dice: 0.7737709444909094\n",
      "#Train#  epoch: 32, loss: 0.09419640898704529, dice: 0.9547112270542313\n",
      "#Val#  epoch: 32, dice: 0.7953424526967852\n",
      "#Test#  epoch: 32, dice: 0.7914098668102176\n",
      "#Train#  epoch: 33, loss: 0.08814011514186859, dice: 0.9571231033285831\n",
      "#Val#  epoch: 33, dice: 0.7959545293241194\n",
      "#Test#  epoch: 33, dice: 0.7854025270548926\n",
      "#Train#  epoch: 34, loss: 0.08268623799085617, dice: 0.9598399714153548\n",
      "#Val#  epoch: 34, dice: 0.7901405171632996\n",
      "#Test#  epoch: 34, dice: 0.7791534328536457\n",
      "#Train#  epoch: 35, loss: 0.07723095268011093, dice: 0.9646120253135655\n",
      "#Val#  epoch: 35, dice: 0.7924050257403498\n",
      "#Test#  epoch: 35, dice: 0.7861726197745705\n",
      "#Train#  epoch: 36, loss: 0.07477612048387527, dice: 0.9660707729025152\n",
      "#Val#  epoch: 36, dice: 0.7897889599936095\n",
      "#Test#  epoch: 36, dice: 0.7815848604348118\n",
      "#Train#  epoch: 37, loss: 0.07123909145593643, dice: 0.9666388617273137\n",
      "#Val#  epoch: 37, dice: 0.7715025184637518\n",
      "#Test#  epoch: 37, dice: 0.7622814867337493\n",
      "#Train#  epoch: 38, loss: 0.07106383889913559, dice: 0.9663813002077156\n",
      "#Val#  epoch: 38, dice: 0.8005966570028262\n",
      "#Test#  epoch: 38, dice: 0.7918927092635131\n",
      "#Train#  epoch: 39, loss: 0.06942440569400787, dice: 0.9661323268524501\n",
      "#Val#  epoch: 39, dice: 0.7963730557798415\n",
      "#Test#  epoch: 39, dice: 0.7901534411857586\n",
      "#Train#  epoch: 40, loss: 0.06709828972816467, dice: 0.9673042395847476\n",
      "#Val#  epoch: 40, dice: 0.7869171030123718\n",
      "#Test#  epoch: 40, dice: 0.7770385327022915\n",
      "#Train#  epoch: 41, loss: 0.06671886891126633, dice: 0.9670788736675278\n",
      "#Val#  epoch: 41, dice: 0.7837594655273137\n",
      "#Test#  epoch: 41, dice: 0.7758784503912026\n",
      "#Train#  epoch: 42, loss: 0.06928424537181854, dice: 0.964546266737377\n",
      "#Val#  epoch: 42, dice: 0.7691617986116068\n",
      "#Test#  epoch: 42, dice: 0.7616708681310502\n",
      "#Train#  epoch: 43, loss: 0.07394570857286453, dice: 0.9580601169295984\n",
      "#Val#  epoch: 43, dice: 0.8029591684516415\n",
      "#Test#  epoch: 43, dice: 0.7960846109914618\n",
      "#Train#  epoch: 44, loss: 0.06962327659130096, dice: 0.9604978021899928\n",
      "#Val#  epoch: 44, dice: 0.78171663645352\n",
      "#Test#  epoch: 44, dice: 0.772518631351597\n",
      "#Train#  epoch: 45, loss: 0.06478717923164368, dice: 0.9663450184299877\n",
      "#Val#  epoch: 45, dice: 0.7812424148996018\n",
      "#Test#  epoch: 45, dice: 0.7755877542964668\n",
      "#Train#  epoch: 46, loss: 0.06173999235033989, dice: 0.9673252529617383\n",
      "#Val#  epoch: 46, dice: 0.798535368346448\n",
      "#Test#  epoch: 46, dice: 0.7905968145526295\n",
      "#Train#  epoch: 47, loss: 0.05766016244888306, dice: 0.9691855743027242\n",
      "#Val#  epoch: 47, dice: 0.7993748196824504\n",
      "#Test#  epoch: 47, dice: 0.7884743570655176\n",
      "#Train#  epoch: 48, loss: 0.05746603012084961, dice: 0.9695575874866009\n",
      "#Val#  epoch: 48, dice: 0.8068574000508797\n",
      "#Test#  epoch: 48, dice: 0.7981636108618138\n",
      "#Train#  epoch: 49, loss: 0.054755911231040955, dice: 0.9726775260537353\n",
      "#Val#  epoch: 49, dice: 0.7866665638284399\n",
      "#Test#  epoch: 49, dice: 0.7770556380969817\n",
      "#Train#  epoch: 50, loss: 0.05513298511505127, dice: 0.9700674046792834\n",
      "#Val#  epoch: 50, dice: 0.7957569151987245\n",
      "#Test#  epoch: 50, dice: 0.7869464859114378\n",
      "#Train#  epoch: 51, loss: 0.05417341738939285, dice: 0.9690652748162056\n",
      "#Val#  epoch: 51, dice: 0.7967630515357332\n",
      "#Test#  epoch: 51, dice: 0.7868560064288439\n",
      "#Train#  epoch: 52, loss: 0.053536996245384216, dice: 0.9716037369973821\n",
      "#Val#  epoch: 52, dice: 0.7972798087982698\n",
      "#Test#  epoch: 52, dice: 0.7887597824453563\n",
      "#Train#  epoch: 53, loss: 0.05254949629306793, dice: 0.9715049582809255\n",
      "#Val#  epoch: 53, dice: 0.7880921973585748\n",
      "#Test#  epoch: 53, dice: 0.7746722384884036\n",
      "#Train#  epoch: 54, loss: 0.05495200306177139, dice: 0.9680955718762031\n",
      "#Val#  epoch: 54, dice: 0.7977994840006863\n",
      "#Test#  epoch: 54, dice: 0.7914680934484197\n",
      "#Train#  epoch: 55, loss: 0.0503305047750473, dice: 0.9720894732017848\n",
      "#Val#  epoch: 55, dice: 0.7930812081399397\n",
      "#Test#  epoch: 55, dice: 0.7831932005574389\n",
      "#Train#  epoch: 56, loss: 0.04803766310214996, dice: 0.9746313344676417\n",
      "#Val#  epoch: 56, dice: 0.7978805225258179\n",
      "#Test#  epoch: 56, dice: 0.7889702253112704\n",
      "#Train#  epoch: 57, loss: 0.04873106628656387, dice: 0.9730132385760406\n",
      "#Val#  epoch: 57, dice: 0.7883596113851151\n",
      "#Test#  epoch: 57, dice: 0.780097914498004\n",
      "#Train#  epoch: 58, loss: 0.04475503787398338, dice: 0.9750729340246387\n",
      "#Val#  epoch: 58, dice: 0.8008487611068348\n",
      "#Test#  epoch: 58, dice: 0.7906548757045451\n",
      "#Train#  epoch: 59, loss: 0.04522603377699852, dice: 0.975103114740473\n",
      "#Val#  epoch: 59, dice: 0.7941699903434677\n",
      "#Test#  epoch: 59, dice: 0.7842276214815689\n",
      "#Train#  epoch: 60, loss: 0.044164400547742844, dice: 0.9755793258967577\n",
      "#Val#  epoch: 60, dice: 0.7942637336227877\n",
      "#Test#  epoch: 60, dice: 0.7877685559745997\n",
      "#Train#  epoch: 61, loss: 0.04593387618660927, dice: 0.9737230661075665\n",
      "#Val#  epoch: 61, dice: 0.7974160149818282\n",
      "#Test#  epoch: 61, dice: 0.7858858065714205\n",
      "#Train#  epoch: 62, loss: 0.04429822042584419, dice: 0.9736501215188843\n",
      "#Val#  epoch: 62, dice: 0.7940761915946708\n",
      "#Test#  epoch: 62, dice: 0.7849671309564639\n",
      "#Train#  epoch: 63, loss: 0.04234188050031662, dice: 0.9769114300804592\n",
      "#Val#  epoch: 63, dice: 0.793215431373424\n",
      "#Test#  epoch: 63, dice: 0.7834930017629429\n"
     ]
    }
   ],
   "source": [
    "print('#----------Start training----------#')\n",
    "torch.cuda.empty_cache()\n",
    "info = \"%d-resizeh, %d-resizew, %f-outer_lr\"%(config.resize_h,config.resize_w,config.outer_lr)\n",
    "print(info)\n",
    "logger.info(info)\n",
    "best_dice_val = 0.0\n",
    "best_dice_test = 0.0\n",
    "train_csv = os.path.join(csv_save,\"train.csv\")\n",
    "val_csv = os.path.join(csv_save,\"val.csv\")\n",
    "test_csv = os.path.join(csv_save,\"test.csv\")\n",
    "train_columns = ['Epoch','Loss',\"Mdice\"]\n",
    "train_df = pd.DataFrame(columns=train_columns)\n",
    "val_columns = ['Epoch','Mdice']\n",
    "val_df = pd.DataFrame(columns=val_columns)\n",
    "test_columns = ['Epoch','Mdice']\n",
    "test_df = pd.DataFrame(columns=test_columns)\n",
    "for epoch in range(start_epoch, config.epoch_num+1):\n",
    "    # train part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    loss_list = []    \n",
    "    base_net.train()\n",
    "    for image,mask in train_loader:\n",
    "        # claer the meta_optimizer, setting zero\n",
    "        meta_optimizer.zero_grad()\n",
    "        image = image.to(device)\n",
    "        mask = mask.to(device)\n",
    "        image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "        mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "        mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "        predicted = base_net(image)     # torch.Size([bs,out_channels=1,512,512])\n",
    "        predicted = predicted.squeeze(1)    # torch.Size([bs,512,512])\n",
    "        loss = criterion(predicted,mask)\n",
    "        loss.backward()\n",
    "        meta_optimizer.step()\n",
    "        loss_list.append(loss.cpu().detach().numpy())\n",
    "        predicted = (predicted > threshold).long()\n",
    "        temp_predicted = predicted.cpu().detach().numpy()       # threshold alternative\n",
    "        predicted_list.append(temp_predicted)\n",
    "        groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "    # train_dice,train_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "    train_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "    train_mloss = np.mean(loss_list)\n",
    "    log_train = f'epoch: {epoch}, loss: {train_mloss}, dice: {train_dice}'\n",
    "    print(\"#Train# \",log_train)\n",
    "    temp_result = pd.Series([epoch,train_mloss,train_dice],index=train_columns)\n",
    "    train_df = train_df.append(temp_result, ignore_index=True)\n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    \n",
    "    # validation part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in val_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "        # val_dice,val_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        val_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_val = f'epoch: {epoch}, dice: {val_dice}'\n",
    "        print(\"#Val# \",log_val)\n",
    "        temp_result = pd.Series([epoch,val_dice],index=val_columns)\n",
    "        val_df = val_df.append(temp_result, ignore_index=True)\n",
    "        val_df.to_csv(val_csv, index=False)\n",
    "        # logger.info(log_val)\n",
    "\n",
    "    if val_dice > best_dice_val:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_val.pth'))\n",
    "        best_dice_val = val_dice\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # test part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in test_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "        # test_dice,test_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        test_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_test = f'epoch: {epoch}, dice: {test_dice}'\n",
    "        print(\"#Test# \",log_test)\n",
    "        temp_result = pd.Series([epoch,test_dice],index=test_columns)\n",
    "        test_df = test_df.append(temp_result, ignore_index=True)\n",
    "        test_df.to_csv(test_csv, index=False)\n",
    "        logger.info(log_test)\n",
    "\n",
    "    if test_dice > best_dice_test:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_test.pth'))\n",
    "        best_dice_test = test_dice\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best dice in testset:0.7995751834376551\n"
     ]
    }
   ],
   "source": [
    "best_result_test = \"Best dice in testset:\" + str(best_dice_test)\n",
    "print(best_result_test)\n",
    "logger.info(best_result_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
