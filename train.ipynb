{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangjie/anaconda3/envs/dataEngineering/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets.dataset import HAM_datasets\n",
    "from models.meta import Meta\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from models.basenet import *\n",
    "from utils import *\n",
    "from configs.config_setting import setting_config\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics as metrics\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.init as init\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = setting_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    support_images = batch['support_images'].squeeze(0)\n",
    "    support_masks = batch['support_masks'].squeeze(0)\n",
    "    query_images = batch['query_images'].squeeze(0)\n",
    "    query_masks = batch['query_masks'].squeeze(0)\n",
    "    return support_images, support_masks, query_images, query_masks\n",
    "\n",
    "# the function of copying the images\n",
    "def copy_file_to_folder(source_file, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    dest_path = os.path.join(dest_folder, os.path.basename(source_file))\n",
    "    shutil.copy(source_file, dest_path)\n",
    "\n",
    "def evaluation_basenet(base_net,query_images,query_masks,criterion):\n",
    "        predicted = base_net(query_images)\n",
    "        loss = criterion(predicted,query_masks)\n",
    "        predicted = torch.argmax(predicted,dim=1).long()\n",
    "        predict_numpy = predicted.detach().cpu().numpy().reshape(-1)\n",
    "        masks_numpy = query_masks.long().detach().cpu().numpy().reshape(-1)\n",
    "        accuracy = metrics.accuracy_score(masks_numpy,predict_numpy)\n",
    "        f1_score = metrics.f1_score(masks_numpy,predict_numpy,average=None)\n",
    "        return accuracy,f1_score,loss\n",
    "\n",
    "def initialize_weights_he(model):\n",
    "    for param in model.parameters():\n",
    "        init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "def initialize_weights_xavier(model):\n",
    "    for param in model.parameters():\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "def initialize_weights_normal(model):\n",
    "    for param in model.parameters():\n",
    "        init.normal_(param, mean=0, std=1)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Generating data----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Generating data----------#')\n",
    "images_resources_path = \"./data/HAM10000/origin/images/\"         # the resource folder of images\n",
    "masks_resources_path = \"./data/HAM10000/origin/masks/\"           # the resource folder of masks\n",
    "ratio = 0.8     # the dataset and testset ratio\n",
    "categories = config.categories\n",
    "categories_dictionary = {}\n",
    "category_id = 1\n",
    "# prepare the csv for groundtruth\n",
    "origin_groundtruth_csv = \"./data/HAM10000/origin/groundtruth/HAM10000_groundtruth.csv\"   # read the csv file\n",
    "origin_groundtruth = pd.read_csv(origin_groundtruth_csv)    # read the csv file of groundtruth\n",
    "\n",
    "# generating the folders for each category in train folder and test folder\n",
    "# create folders for each categories\n",
    "trainset_images_path = \"./data/HAM10000/train/images/\"     # the images path for train dataset\n",
    "trainset_masks_path = \"./data/HAM10000/train/masks/\"     # the masks path for train dataset\n",
    "testset_images_path = \"./data/HAM10000/test/images/\"     # the images path for test dataset\n",
    "testset_masks_path = \"./data/HAM10000/test/masks/\"      # the masks path for test dataset\n",
    "\n",
    "for category in categories:\n",
    "    # prepare the address for folders\n",
    "    category_images_train_path = os.path.join(trainset_images_path,category)\n",
    "    category_masks_train_path = os.path.join(trainset_masks_path,category)\n",
    "    category_images_test_path = os.path.join(testset_images_path,category)\n",
    "    category_masks_test_path = os.path.join(testset_masks_path,category)\n",
    "    #delete the previously exsited folders\n",
    "    shutil.rmtree(category_images_train_path)\n",
    "    shutil.rmtree(category_masks_train_path)\n",
    "    shutil.rmtree(category_images_test_path)\n",
    "    shutil.rmtree(category_masks_test_path)\n",
    "    # create corresponding folder for each categories\n",
    "    os.makedirs(category_images_train_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_train_path, exist_ok=True)\n",
    "    os.makedirs(category_images_test_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_test_path, exist_ok=True)\n",
    "\n",
    "    # generate the data in trainset and testset for each categories\n",
    "    dest_folder_images = \"./data/HAM10000/train/images/\"+category    # the destination train set folder of copying the images\n",
    "    dest_folder_masks = \"./data/HAM10000/train/masks/\"+category    # the destination trian set folder of copying the masks\n",
    "    dest_folder_images_change = \"./data/HAM10000/test/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change = \"./data/HAM10000/test/masks/\"+category      # the destination folder of test set masks\n",
    "    data_categories = origin_groundtruth[origin_groundtruth['dx'] == category]      # extract each categories \n",
    "    length_categories = len(data_categories)\n",
    "    chaneg_folder_point = math.floor(length_categories * ratio)     # get the point to change directory name \n",
    "    elements_count = 0\n",
    "    for image_name in data_categories['image_id']:      # each image_id in each categories\n",
    "        if elements_count == chaneg_folder_point:\n",
    "            dest_folder_images = dest_folder_images_change\n",
    "            dest_folder_masks = dest_folder_masks_change\n",
    "        images_file = image_name+\".jpg\"\n",
    "        masks_file = image_name+\"_segmentation.png\"\n",
    "        source_image = images_resources_path+images_file    # the full path of source of image : path + image file name\n",
    "        source_mask = masks_resources_path+masks_file       # the full path of source of mask : path + mask file name\n",
    "        copy_file_to_folder(source_image,dest_folder_images)\n",
    "        # masks should be preprocess to the form of output for network (Width*Height*Category)\n",
    "        image = Image.open(source_mask)\n",
    "        image_array = np.array(image)\n",
    "        image_array[image_array == 255] = category_id\n",
    "        image = Image.fromarray(image_array)\n",
    "        image.save(os.path.join(dest_folder_masks, masks_file))\n",
    "        elements_count +=1\n",
    "    categories_dictionary[category] = category_id       # add the category id in the categories_dictionary\n",
    "    category_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------GPU init----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------GPU init----------#')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu_id\n",
    "set_seed(config.seed)\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Model----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Model----------#')\n",
    "in_channels = config.in_channels\n",
    "out_channels = config.num_classes\n",
    "base_net = smp.Unet(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.num_classes, activation=None, aux_params=None)\n",
    "# base_net = UNet(in_channels,out_channels)\n",
    "# initialize_weights_he(base_net)\n",
    "base_net = base_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing loss, opt, sch and amp----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing loss, opt, sch and amp----------#')\n",
    "criterion = config.criterion\n",
    "meta_optimizer = get_optimizer(config, base_net)\n",
    "meta_scheduler = get_scheduler(config, meta_optimizer)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Set other params----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Set other params----------#')\n",
    "min_loss = 999\n",
    "start_epoch = 1\n",
    "min_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Start training----------#\n",
      "batch_size:1, 3-way, 30-shot, 30-query, 128-resizeh, 128-resizew\n",
      "Evaluation: Epoch: 1, loss: 1.9312800168991089, accuracy: 0.1160, f1_score: [0.06876786 0.08344376 0.1349995  0.1691668 ]\n",
      "Evaluation: Epoch: 2, loss: 1.9309858083724976, accuracy: 0.1139, f1_score: [0.06849712 0.07991345 0.1376839  0.16240363]\n",
      "Evaluation: Epoch: 3, loss: 1.918222427368164, accuracy: 0.1170, f1_score: [0.07058752 0.0855085  0.13101303 0.171616  ]\n",
      "Evaluation: Epoch: 4, loss: 1.9293087720870972, accuracy: 0.1132, f1_score: [0.06910938 0.0972418  0.16063865 0.13698703]\n",
      "Evaluation: Epoch: 5, loss: 1.9156304597854614, accuracy: 0.1153, f1_score: [0.06647595 0.09340527 0.15244535 0.15201795]\n",
      "Evaluation: Epoch: 6, loss: 1.945850133895874, accuracy: 0.1097, f1_score: [0.06835393 0.06487806 0.13260642 0.1584317 ]\n",
      "Evaluation: Epoch: 7, loss: 1.9363045692443848, accuracy: 0.1177, f1_score: [0.06976467 0.07519325 0.13914865 0.17273103]\n",
      "Evaluation: Epoch: 8, loss: 1.9136894941329956, accuracy: 0.1223, f1_score: [0.06924168 0.0964791  0.14802273 0.17435521]\n"
     ]
    }
   ],
   "source": [
    "print('#----------Start training----------#')\n",
    "print(\n",
    "            \"batch_size:%d, %d-way, %d-shot, %d-query, %d-resizeh, %d-resizew\"\n",
    "            % (\n",
    "                config.batch_size,\n",
    "                config.n_way,\n",
    "                config.k_shot,\n",
    "                config.k_query,\n",
    "                config.resize_h,\n",
    "                config.resize_w\n",
    "            )\n",
    "        )\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(start_epoch, config.epoch_num+1):\n",
    "    step = 0        # according to the step, decide to print the result or do the evaluation\n",
    "    # create the dataset and dataloader\n",
    "    train_dataset = HAM_datasets(config, train=True)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=config.dataloader_bs, num_workers=config.num_workers)\n",
    "    test_dataset = HAM_datasets(config, train=False)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=config.dataloader_bs, num_workers=config.num_workers)\n",
    "    # numerate to train\n",
    "    for i,batch in enumerate(train_dataset):\n",
    "        # claer the meta_optimizer, setting zero\n",
    "        meta_optimizer.zero_grad()\n",
    "        support_images, support_masks, query_images, query_masks = preprocess_batch(batch)\n",
    "        support_images, support_masks, query_images, query_masks = support_images.to(device), support_masks.to(device), query_images.to(device), query_masks.to(device)\n",
    "        support_masks = torch.squeeze(support_masks,dim=1).long()\n",
    "        query_masks = torch.squeeze(query_masks,dim=1).long()\n",
    "        # deep copy the base_net for inner loop, preparing the loss and optimizer\n",
    "        temp_net = deepcopy(base_net)\n",
    "        inner_optimizer = optim.Adam(temp_net.parameters(), lr=config.inner_lr)\n",
    "        temp_loss = None\n",
    "        for inner_step in range(config.inner_steps):\n",
    "            inner_optimizer.zero_grad()\n",
    "            predicted = temp_net(support_images)\n",
    "            loss = criterion(predicted,support_masks)\n",
    "            loss.backward()\n",
    "            inner_optimizer.step()\n",
    "        query_predicted = temp_net(query_images)\n",
    "        meta_loss = criterion(query_predicted,query_masks)\n",
    "        meta_loss.backward()\n",
    "        meta_optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        accuracy,f1_score,loss_score = evaluation_basenet(base_net,query_images,query_masks,criterion)\n",
    "        log_info = f'Epoch: {epoch}, loss: {loss_score}, accuracy: {accuracy:.4f}, f1_score: {f1_score}'\n",
    "        print(\"Evaluation:\",log_info)\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
