{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import *\n",
    "from models.meta import Meta\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from models.basenet import *\n",
    "from utils import *\n",
    "from configs.config_setting import setting_config\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics as metrics\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.init as init\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = setting_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    support_images = batch['support_images'].squeeze(0)\n",
    "    support_masks = batch['support_masks'].squeeze(0)\n",
    "    query_images = batch['query_images'].squeeze(0)\n",
    "    query_masks = batch['query_masks'].squeeze(0)\n",
    "    return support_images, support_masks, query_images, query_masks\n",
    "\n",
    "# the function of copying the images\n",
    "def copy_file_to_folder(source_file, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    dest_path = os.path.join(dest_folder, os.path.basename(source_file))\n",
    "    shutil.copy(source_file, dest_path)\n",
    "\n",
    "def evaluation_api(predicted_list,groudtruth_list):\n",
    "    pre = np.array([item for sublist in predicted_list for item in sublist]).reshape(-1)\n",
    "    gts = np.array([item for sublist in groudtruth_list for item in sublist]).reshape(-1)\n",
    "    # confusion_matrix = metrics.confusion_matrix(gts,pre)\n",
    "    # TN, FP, FN, TP = confusion[0,0], confusion[0,1], confusion[1,0], confusion[1,1] \n",
    "    dice = metrics.f1_score(gts,pre)\n",
    "\n",
    "    return dice\n",
    "\n",
    "def evaluation_epoch(predicted_list,groundtruth_list):\n",
    "    TP = [0]*config.num_classes\n",
    "    FP = [0]*config.num_classes\n",
    "    FN = [0]*config.num_classes\n",
    "    dice = [0.0]*config.num_classes\n",
    "    \n",
    "    for i in range(len(predicted_list)):\n",
    "        preds = np.array(predicted_list[i]).reshape(-1)\n",
    "        gts = np.array(groundtruth_list[i]).reshape(-1)\n",
    "        for j in range(len(preds)):\n",
    "            if preds[j] == gts[j]:\n",
    "                TP[gts[j]] += 1\n",
    "            else:\n",
    "                FP[preds[j]] += 1\n",
    "                FN[gts[j]] += 1        \n",
    "    \n",
    "    for i in range(config.num_classes):\n",
    "        dice[i] = (2 * TP[i])/(FP[i]+FN[i]+2*TP[i]+1)\n",
    "\n",
    "    mdice = (2*np.sum(TP))/(np.sum(FP)+np.sum(FN)+2*np.sum(TP)+1)    \n",
    "    return dice,mdice\n",
    "\n",
    "def evaluation_basenet(base_net,query_images,query_masks,criterion):\n",
    "    predicted = base_net(query_images)\n",
    "    loss = criterion(predicted,query_masks)\n",
    "    predicted = torch.argmax(predicted,dim=1).long()\n",
    "    predict_numpy = predicted.detach().cpu().numpy().reshape(-1)\n",
    "    masks_numpy = query_masks.long().detach().cpu().numpy().reshape(-1)\n",
    "    accuracy = metrics.accuracy_score(masks_numpy,predict_numpy)\n",
    "    f1_score = metrics.f1_score(masks_numpy,predict_numpy,average=None)\n",
    "    return accuracy,f1_score,loss\n",
    "\n",
    "def initialize_weights_he(model):\n",
    "    for param in model.parameters():\n",
    "        init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "def initialize_weights_xavier(model):\n",
    "    for param in model.parameters():\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "def initialize_weights_normal(model):\n",
    "    for param in model.parameters():\n",
    "        init.normal_(param, mean=0, std=1)\n",
    "\n",
    "def remove_exsits_folder(folderpath):\n",
    "    if os.path.exists(folderpath):\n",
    "        shutil.rmtree(folderpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Creating logger----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Creating logger----------#')\n",
    "sys.path.append(config.work_dir + '/')\n",
    "log_dir = os.path.join(config.work_dir, 'log')\n",
    "checkpoint_dir = os.path.join(config.work_dir, 'checkpoints')\n",
    "resume_model = os.path.join(checkpoint_dir, 'latest.pth')\n",
    "outputs = os.path.join(config.work_dir, 'outputs')\n",
    "csv_save = os.path.join(config.work_dir, 'csv')\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "if not os.path.exists(csv_save):\n",
    "    os.makedirs(csv_save)\n",
    "\n",
    "global logger\n",
    "logger = get_logger('test', log_dir)\n",
    "global writer\n",
    "writer = SummaryWriter(config.work_dir + 'summary')\n",
    "\n",
    "log_config_info(config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Generating data----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Generating data----------#')\n",
    "images_resources_path = \"./data/HAM10000/origin/images/\"         # the resource folder of images\n",
    "masks_resources_path = \"./data/HAM10000/origin/masks/\"           # the resource folder of masks\n",
    "ratio = [0.6,0.2]     # the ratio point of train dataset and validation set and testset\n",
    "trian_num = 300     # the number of data in train dataset\n",
    "categories = config.categories\n",
    "categories_dictionary = {}\n",
    "category_id = 1\n",
    "# prepare the csv for groundtruth\n",
    "origin_groundtruth_csv = \"./data/HAM10000/origin/groundtruth/HAM10000_groundtruth.csv\"   # read the csv file\n",
    "origin_groundtruth = pd.read_csv(origin_groundtruth_csv)    # read the csv file of groundtruth\n",
    "\n",
    "# generating the folders for each category in train folder and test folder\n",
    "# create folders for each categories\n",
    "trainset_images_path = \"./data/HAM10000/train/images/\"     # the images path for train dataset\n",
    "trainset_masks_path = \"./data/HAM10000/train/masks/\"     # the masks path for train dataset\n",
    "valset_images_path = \"./data/HAM10000/val/images/\"     # the images path for validation dataset\n",
    "valset_masks_path = \"./data/HAM10000/val/masks/\"      # the masks path for validation dataset\n",
    "testset_images_path = \"./data/HAM10000/test/images/\"     # the images path for test dataset\n",
    "testset_masks_path = \"./data/HAM10000/test/masks/\"      # the masks path for test dataset\n",
    "\n",
    "for category in categories:\n",
    "    # prepare the address for folders\n",
    "    category_images_train_path = os.path.join(trainset_images_path,category)\n",
    "    category_masks_train_path = os.path.join(trainset_masks_path,category)\n",
    "    category_images_val_path = os.path.join(valset_images_path,category)\n",
    "    category_masks_val_path = os.path.join(valset_masks_path,category)\n",
    "    category_images_test_path = os.path.join(testset_images_path,category)\n",
    "    category_masks_test_path = os.path.join(testset_masks_path,category)\n",
    "    #delete the previously exsited folders\n",
    "    remove_exsits_folder(category_images_train_path)\n",
    "    remove_exsits_folder(category_masks_train_path)\n",
    "    remove_exsits_folder(category_images_val_path)\n",
    "    remove_exsits_folder(category_masks_val_path)\n",
    "    remove_exsits_folder(category_images_test_path)\n",
    "    remove_exsits_folder(category_masks_test_path)\n",
    "    # create corresponding folder for each categories\n",
    "    os.makedirs(category_images_train_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_train_path, exist_ok=True)\n",
    "    os.makedirs(category_images_val_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_val_path, exist_ok=True)\n",
    "    os.makedirs(category_images_test_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_test_path, exist_ok=True)\n",
    "\n",
    "    # generate the data in trainset and testset for each categories\n",
    "    dest_folder_images = \"./data/HAM10000/train/images/\"+category    # the destination train set folder of copying the images\n",
    "    dest_folder_masks = \"./data/HAM10000/train/masks/\"+category    # the destination trian set folder of copying the masks\n",
    "    dest_folder_images_change_val = \"./data/HAM10000/val/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_val = \"./data/HAM10000/val/masks/\"+category      # the destination folder of test set masks\n",
    "    dest_folder_images_change_test = \"./data/HAM10000/test/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_test = \"./data/HAM10000/test/masks/\"+category      # the destination folder of test set masks\n",
    "    data_categories = origin_groundtruth[origin_groundtruth['dx'] == category]      # extract each categories \n",
    "    data_categories = data_categories.sample(frac=1,random_state=config.seed)       # random sample the datagenerating\n",
    "    length_categories = len(data_categories)\n",
    "    change_folder_point_valset = math.floor(trian_num)     # get the point to change directory name\n",
    "    change_folder_point_testset = math.floor(trian_num + ((length_categories-trian_num)*0.5))     # get the point to change directory name \n",
    "    elements_count = 0\n",
    "    for image_name in data_categories['image_id']:      # each image_id in each categories\n",
    "        if elements_count == change_folder_point_valset:\n",
    "            dest_folder_images = dest_folder_images_change_val\n",
    "            dest_folder_masks = dest_folder_masks_change_val\n",
    "        elif elements_count == change_folder_point_testset:\n",
    "            dest_folder_images = dest_folder_images_change_test\n",
    "            dest_folder_masks = dest_folder_masks_change_test\n",
    "        images_file = image_name+\".jpg\"\n",
    "        masks_file = image_name+\"_segmentation.png\"\n",
    "        source_image = images_resources_path+images_file    # the full path of source of image : path + image file name\n",
    "        source_mask = masks_resources_path+masks_file       # the full path of source of mask : path + mask file name\n",
    "        copy_file_to_folder(source_image,dest_folder_images)\n",
    "        # masks should be preprocess to the form of output for network (Width*Height*Category)\n",
    "        image = Image.open(source_mask)\n",
    "        image_array = np.array(image)\n",
    "        image_array[image_array == 255] = 1\n",
    "        image = Image.fromarray(image_array)\n",
    "        image.save(os.path.join(dest_folder_masks, masks_file))\n",
    "        elements_count +=1\n",
    "    categories_dictionary[category] = category_id       # add the category id in the categories_dictionary\n",
    "    category_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------GPU init----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------GPU init----------#')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu_id\n",
    "set_seed(config.seed)\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Datasets----------#\n",
      "trian_dataset_list length: 3\n",
      "trian_dataset(mel) length: 300\n",
      "trian_dataset(bkl) length: 300\n",
      "trian_dataset(bcc) length: 300\n",
      "val_dataset length: 912\n",
      "test_dataset length: 914\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Datasets----------#')\n",
    "# create the dataset and dataloader\n",
    "batch_size = config.batch_size\n",
    "categories = config.categories\n",
    "num_categories = len(categories)\n",
    "train_dataset_list = []\n",
    "train_loader_list = []\n",
    "for i in range(num_categories):\n",
    "    train_dataset = HAMALL_datasets(config, train=True,categories = [categories[i]])\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "    train_dataset_list.append(train_dataset)\n",
    "    train_loader_list.append(train_loader)\n",
    "val_dataset = HAMALL_datasets(config, train=False,val=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "test_dataset = HAMALL_datasets(config, train=False)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "print(\"trian_dataset_list length:\",len(train_loader_list))\n",
    "for i in range(num_categories):\n",
    "    print(\"trian_dataset(\"+categories[i]+\") length:\",len(train_dataset_list[i]))\n",
    "print(\"val_dataset length:\",len(val_dataset))\n",
    "print(\"test_dataset length:\",len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Model----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Model----------#')\n",
    "in_channels = config.in_channels\n",
    "out_channels = config.out_channels\n",
    "base_net = smp.Unet(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# base_net = smp.UnetPlusPlus(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# initialize_weights_he(base_net)\n",
    "base_net = base_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing loss, opt, sch and amp----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing loss, opt, sch and amp----------#')\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "meta_optimizer = get_optimizer(config, base_net)\n",
    "meta_scheduler = get_scheduler(config, meta_optimizer)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Set other params----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Set other params----------#')\n",
    "min_loss = 999\n",
    "start_epoch = 1\n",
    "min_epoch = 1\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Start training----------#\n",
      "128-resizeh, 128-resizew, 0.000100-outer_lr\n",
      "#Train#  epoch: 1, loss: 0.30117738246917725, dice: 0.3885132387151951\n",
      "#Val#  epoch: 1, dice: 0.0717111743014563\n",
      "#Test#  epoch: 1, dice: 0.07226221506112744\n",
      "#Train#  epoch: 2, loss: 0.2618381977081299, dice: 0.5061705429771868\n",
      "#Val#  epoch: 2, dice: 0.479684211965644\n",
      "#Test#  epoch: 2, dice: 0.46192760006324907\n",
      "#Train#  epoch: 3, loss: 0.24053256213665009, dice: 0.5767657847875722\n",
      "#Val#  epoch: 3, dice: 0.6190229545547911\n",
      "#Test#  epoch: 3, dice: 0.5971198149591946\n",
      "#Train#  epoch: 4, loss: 0.22732792794704437, dice: 0.620284550837944\n",
      "#Val#  epoch: 4, dice: 0.6853359839217056\n",
      "#Test#  epoch: 4, dice: 0.6604535859838496\n",
      "#Train#  epoch: 5, loss: 0.2175447791814804, dice: 0.648204486868923\n",
      "#Val#  epoch: 5, dice: 0.7125356213476519\n",
      "#Test#  epoch: 5, dice: 0.6866282363396556\n",
      "#Train#  epoch: 6, loss: 0.2099681794643402, dice: 0.6657348195443377\n",
      "#Val#  epoch: 6, dice: 0.7212846744172723\n",
      "#Test#  epoch: 6, dice: 0.6981562156304383\n",
      "#Train#  epoch: 7, loss: 0.20352695882320404, dice: 0.6777832647487518\n",
      "#Val#  epoch: 7, dice: 0.7284130580954574\n",
      "#Test#  epoch: 7, dice: 0.7059680315691579\n",
      "#Train#  epoch: 8, loss: 0.19784699380397797, dice: 0.6869509768339334\n",
      "#Val#  epoch: 8, dice: 0.735165189972111\n",
      "#Test#  epoch: 8, dice: 0.7128548251009138\n",
      "#Train#  epoch: 9, loss: 0.19286245107650757, dice: 0.6947050706959051\n",
      "#Val#  epoch: 9, dice: 0.7416763585261859\n",
      "#Test#  epoch: 9, dice: 0.7197461256704506\n",
      "#Train#  epoch: 10, loss: 0.18839846551418304, dice: 0.7018775455049565\n",
      "#Val#  epoch: 10, dice: 0.7480189900612361\n",
      "#Test#  epoch: 10, dice: 0.7259984613319415\n",
      "#Train#  epoch: 11, loss: 0.18423131108283997, dice: 0.7087746486203436\n",
      "#Val#  epoch: 11, dice: 0.7540188815159125\n",
      "#Test#  epoch: 11, dice: 0.7320331682467346\n",
      "#Train#  epoch: 12, loss: 0.18027135729789734, dice: 0.7152314736783972\n",
      "#Val#  epoch: 12, dice: 0.7595530702083816\n",
      "#Test#  epoch: 12, dice: 0.7374512816646003\n",
      "#Train#  epoch: 13, loss: 0.17657622694969177, dice: 0.7216034310534165\n",
      "#Val#  epoch: 13, dice: 0.76458791709437\n",
      "#Test#  epoch: 13, dice: 0.7425121319026756\n",
      "#Train#  epoch: 14, loss: 0.1730061024427414, dice: 0.7281991782856486\n",
      "#Val#  epoch: 14, dice: 0.7689010818862206\n",
      "#Test#  epoch: 14, dice: 0.7466959756645227\n",
      "#Train#  epoch: 15, loss: 0.16962677240371704, dice: 0.7353623439917857\n",
      "#Val#  epoch: 15, dice: 0.7723277200487473\n",
      "#Test#  epoch: 15, dice: 0.7499484179065633\n",
      "#Train#  epoch: 16, loss: 0.16642114520072937, dice: 0.7435177406189432\n",
      "#Val#  epoch: 16, dice: 0.7741743037722324\n",
      "#Test#  epoch: 16, dice: 0.7519254438610674\n",
      "#Train#  epoch: 17, loss: 0.1633642464876175, dice: 0.7526657178540505\n",
      "#Val#  epoch: 17, dice: 0.7746241801613559\n",
      "#Test#  epoch: 17, dice: 0.7526360385670142\n",
      "#Train#  epoch: 18, loss: 0.16038893163204193, dice: 0.7626324360035656\n",
      "#Val#  epoch: 18, dice: 0.7750924475808858\n",
      "#Test#  epoch: 18, dice: 0.7535358389312747\n",
      "#Train#  epoch: 19, loss: 0.15730084478855133, dice: 0.7734645976323513\n",
      "#Val#  epoch: 19, dice: 0.7775655849724366\n",
      "#Test#  epoch: 19, dice: 0.7561573257218637\n",
      "#Train#  epoch: 20, loss: 0.15399318933486938, dice: 0.7844055577661626\n",
      "#Val#  epoch: 20, dice: 0.7812213041269014\n",
      "#Test#  epoch: 20, dice: 0.7593964977306077\n",
      "#Train#  epoch: 21, loss: 0.15072807669639587, dice: 0.7945568492855972\n",
      "#Val#  epoch: 21, dice: 0.7832853174480625\n",
      "#Test#  epoch: 21, dice: 0.7610076318624202\n",
      "#Train#  epoch: 22, loss: 0.14785991609096527, dice: 0.8030669243981112\n",
      "#Val#  epoch: 22, dice: 0.783182568547942\n",
      "#Test#  epoch: 22, dice: 0.761073119885059\n",
      "#Train#  epoch: 23, loss: 0.14558760821819305, dice: 0.8099469904169238\n",
      "#Val#  epoch: 23, dice: 0.7849085549440077\n",
      "#Test#  epoch: 23, dice: 0.7638802537612134\n",
      "#Train#  epoch: 24, loss: 0.1433895081281662, dice: 0.8171215228354355\n",
      "#Val#  epoch: 24, dice: 0.7841693130519656\n",
      "#Test#  epoch: 24, dice: 0.7649508665477887\n",
      "#Train#  epoch: 25, loss: 0.14097769558429718, dice: 0.824590610944951\n",
      "#Val#  epoch: 25, dice: 0.7752338231539451\n",
      "#Test#  epoch: 25, dice: 0.7568263077352345\n",
      "#Train#  epoch: 26, loss: 0.13846534490585327, dice: 0.8327941323274287\n",
      "#Val#  epoch: 26, dice: 0.773032385906248\n",
      "#Test#  epoch: 26, dice: 0.7552003002896892\n",
      "#Train#  epoch: 27, loss: 0.13614130020141602, dice: 0.8402074618211479\n",
      "#Val#  epoch: 27, dice: 0.7792507831100566\n",
      "#Test#  epoch: 27, dice: 0.7619834968283226\n",
      "#Train#  epoch: 28, loss: 0.13389527797698975, dice: 0.8461554649013014\n",
      "#Val#  epoch: 28, dice: 0.7737543405762716\n",
      "#Test#  epoch: 28, dice: 0.7558065928654143\n",
      "#Train#  epoch: 29, loss: 0.13169324398040771, dice: 0.8519839148117172\n",
      "#Val#  epoch: 29, dice: 0.7673800360781138\n",
      "#Test#  epoch: 29, dice: 0.7488266518245349\n",
      "#Train#  epoch: 30, loss: 0.12925243377685547, dice: 0.8581756538937947\n",
      "#Val#  epoch: 30, dice: 0.7679974512060485\n",
      "#Test#  epoch: 30, dice: 0.7490044069576953\n",
      "#Train#  epoch: 31, loss: 0.12655746936798096, dice: 0.8640785808050793\n",
      "#Val#  epoch: 31, dice: 0.7601039714739971\n",
      "#Test#  epoch: 31, dice: 0.7410117884572096\n",
      "#Train#  epoch: 32, loss: 0.1231178566813469, dice: 0.8702086205106572\n",
      "#Val#  epoch: 32, dice: 0.7577702124215241\n",
      "#Test#  epoch: 32, dice: 0.7386524166191872\n",
      "#Train#  epoch: 33, loss: 0.11962728202342987, dice: 0.8762479881988874\n",
      "#Val#  epoch: 33, dice: 0.75733029206387\n",
      "#Test#  epoch: 33, dice: 0.7378608666747156\n",
      "#Train#  epoch: 34, loss: 0.11683766543865204, dice: 0.882270124617234\n",
      "#Val#  epoch: 34, dice: 0.7470166082363002\n",
      "#Test#  epoch: 34, dice: 0.7278724609949241\n",
      "#Train#  epoch: 35, loss: 0.11423860490322113, dice: 0.8881637050424165\n",
      "#Val#  epoch: 35, dice: 0.7588313784175648\n",
      "#Test#  epoch: 35, dice: 0.7398451897564546\n",
      "#Train#  epoch: 36, loss: 0.11170163005590439, dice: 0.8934769288500183\n",
      "#Val#  epoch: 36, dice: 0.7545361493692301\n",
      "#Test#  epoch: 36, dice: 0.7353953291881289\n",
      "#Train#  epoch: 37, loss: 0.10909190773963928, dice: 0.8992833248960226\n",
      "#Val#  epoch: 37, dice: 0.7603340818949005\n",
      "#Test#  epoch: 37, dice: 0.7412847118631649\n",
      "#Train#  epoch: 38, loss: 0.10665714740753174, dice: 0.9049966014293218\n",
      "#Val#  epoch: 38, dice: 0.7666267263844992\n",
      "#Test#  epoch: 38, dice: 0.7475543689206197\n",
      "#Train#  epoch: 39, loss: 0.10447894036769867, dice: 0.910254684907168\n",
      "#Val#  epoch: 39, dice: 0.7574933933322112\n",
      "#Test#  epoch: 39, dice: 0.7385746360887897\n",
      "#Train#  epoch: 40, loss: 0.10264116525650024, dice: 0.9149540726074659\n",
      "#Val#  epoch: 40, dice: 0.7747862786278629\n",
      "#Test#  epoch: 40, dice: 0.7550837880374116\n",
      "#Train#  epoch: 41, loss: 0.10122712701559067, dice: 0.9174185108290447\n",
      "#Val#  epoch: 41, dice: 0.7475140846836753\n",
      "#Test#  epoch: 41, dice: 0.7282897399185307\n",
      "#Train#  epoch: 42, loss: 0.10050608962774277, dice: 0.9134371846833386\n",
      "#Val#  epoch: 42, dice: 0.7838880354569286\n",
      "#Test#  epoch: 42, dice: 0.7633988674061647\n",
      "#Train#  epoch: 43, loss: 0.10020764172077179, dice: 0.9126229612645123\n",
      "#Val#  epoch: 43, dice: 0.7905950715711738\n",
      "#Test#  epoch: 43, dice: 0.7711823840764759\n",
      "#Train#  epoch: 44, loss: 0.09696447849273682, dice: 0.926750728138887\n",
      "#Val#  epoch: 44, dice: 0.7701299142171459\n",
      "#Test#  epoch: 44, dice: 0.752630125478347\n",
      "#Train#  epoch: 45, loss: 0.09691561758518219, dice: 0.9210730210461728\n",
      "#Val#  epoch: 45, dice: 0.7909757527869015\n",
      "#Test#  epoch: 45, dice: 0.7720780838359514\n",
      "#Train#  epoch: 46, loss: 0.09467360377311707, dice: 0.932040146070239\n",
      "#Val#  epoch: 46, dice: 0.7885204791201759\n",
      "#Test#  epoch: 46, dice: 0.7681326435398113\n",
      "#Train#  epoch: 47, loss: 0.09451264142990112, dice: 0.9284701594645817\n",
      "#Val#  epoch: 47, dice: 0.7663293183426536\n",
      "#Test#  epoch: 47, dice: 0.7474050818842402\n",
      "#Train#  epoch: 48, loss: 0.09258803725242615, dice: 0.9374888503169462\n",
      "#Val#  epoch: 48, dice: 0.7702372511665531\n",
      "#Test#  epoch: 48, dice: 0.751999697696722\n",
      "#Train#  epoch: 49, loss: 0.09232208132743835, dice: 0.9347160833022613\n",
      "#Val#  epoch: 49, dice: 0.7898649694033792\n",
      "#Test#  epoch: 49, dice: 0.7700018235932593\n",
      "#Train#  epoch: 50, loss: 0.09077432751655579, dice: 0.9419314050545438\n",
      "#Val#  epoch: 50, dice: 0.7826169649649793\n",
      "#Test#  epoch: 50, dice: 0.762444803412411\n",
      "#Train#  epoch: 51, loss: 0.09030835330486298, dice: 0.9409765237876276\n",
      "#Val#  epoch: 51, dice: 0.7653764772596487\n",
      "#Test#  epoch: 51, dice: 0.7465890291318468\n",
      "#Train#  epoch: 52, loss: 0.08914869278669357, dice: 0.9452663045011358\n",
      "#Val#  epoch: 52, dice: 0.774189718150403\n",
      "#Test#  epoch: 52, dice: 0.7555417734138623\n",
      "#Train#  epoch: 53, loss: 0.08851093053817749, dice: 0.9451229049923908\n",
      "#Val#  epoch: 53, dice: 0.7863028058047413\n",
      "#Test#  epoch: 53, dice: 0.7677810479780672\n",
      "#Train#  epoch: 54, loss: 0.08748014271259308, dice: 0.9489775988928648\n",
      "#Val#  epoch: 54, dice: 0.7824095066720386\n",
      "#Test#  epoch: 54, dice: 0.7631865577585643\n",
      "#Train#  epoch: 55, loss: 0.08687138557434082, dice: 0.9494089505600621\n",
      "#Val#  epoch: 55, dice: 0.7778051856379374\n",
      "#Test#  epoch: 55, dice: 0.7577238962453454\n",
      "#Train#  epoch: 56, loss: 0.08592217415571213, dice: 0.9518284298022142\n",
      "#Val#  epoch: 56, dice: 0.7708645874365929\n",
      "#Test#  epoch: 56, dice: 0.7517576123537307\n",
      "#Train#  epoch: 57, loss: 0.08523120731115341, dice: 0.9525112954781702\n",
      "#Val#  epoch: 57, dice: 0.7780722860179529\n",
      "#Test#  epoch: 57, dice: 0.759469702642616\n",
      "#Train#  epoch: 58, loss: 0.08444727957248688, dice: 0.9548415237621668\n",
      "#Val#  epoch: 58, dice: 0.7883790058433093\n",
      "#Test#  epoch: 58, dice: 0.7696482842352851\n",
      "#Train#  epoch: 59, loss: 0.0837615430355072, dice: 0.9559745344390577\n",
      "#Val#  epoch: 59, dice: 0.776147749331919\n",
      "#Test#  epoch: 59, dice: 0.7587491742526649\n",
      "#Train#  epoch: 60, loss: 0.08299793303012848, dice: 0.957815503805988\n",
      "#Val#  epoch: 60, dice: 0.7801341501363988\n",
      "#Test#  epoch: 60, dice: 0.761818978094173\n",
      "#Train#  epoch: 61, loss: 0.08237694203853607, dice: 0.9583060945677747\n",
      "#Val#  epoch: 61, dice: 0.7816828435268244\n",
      "#Test#  epoch: 61, dice: 0.7623523370987133\n",
      "#Train#  epoch: 62, loss: 0.08164655417203903, dice: 0.9599266772635727\n",
      "#Val#  epoch: 62, dice: 0.7797332483623908\n",
      "#Test#  epoch: 62, dice: 0.7603826252645238\n",
      "#Train#  epoch: 63, loss: 0.08104927837848663, dice: 0.9608883648865802\n",
      "#Val#  epoch: 63, dice: 0.7807168292191283\n",
      "#Test#  epoch: 63, dice: 0.7627403866202791\n",
      "#Train#  epoch: 64, loss: 0.08038347959518433, dice: 0.9619869378184512\n",
      "#Val#  epoch: 64, dice: 0.779784605762934\n",
      "#Test#  epoch: 64, dice: 0.7617788631803635\n",
      "#Train#  epoch: 65, loss: 0.0798388123512268, dice: 0.9625226214944006\n",
      "#Val#  epoch: 65, dice: 0.7793488466510364\n",
      "#Test#  epoch: 65, dice: 0.7595045337377907\n",
      "#Train#  epoch: 66, loss: 0.07945521175861359, dice: 0.9616801093810601\n",
      "#Val#  epoch: 66, dice: 0.7878272809890127\n",
      "#Test#  epoch: 66, dice: 0.7696496426152012\n",
      "#Train#  epoch: 67, loss: 0.0798526406288147, dice: 0.9564732815982715\n",
      "#Val#  epoch: 67, dice: 0.7630911202212437\n",
      "#Test#  epoch: 67, dice: 0.7432673962602423\n",
      "#Train#  epoch: 68, loss: 0.08040507882833481, dice: 0.95019313057552\n",
      "#Val#  epoch: 68, dice: 0.7981350431162351\n",
      "#Test#  epoch: 68, dice: 0.7801262695580565\n",
      "#Train#  epoch: 69, loss: 0.07816621661186218, dice: 0.9610961984851074\n",
      "#Val#  epoch: 69, dice: 0.7988092303518372\n",
      "#Test#  epoch: 69, dice: 0.780759217217014\n",
      "#Train#  epoch: 70, loss: 0.07766154408454895, dice: 0.9621433459761282\n",
      "#Val#  epoch: 70, dice: 0.7804264280439832\n",
      "#Test#  epoch: 70, dice: 0.7609653183508731\n",
      "#Train#  epoch: 71, loss: 0.07738965004682541, dice: 0.9608644424227059\n",
      "#Val#  epoch: 71, dice: 0.7859429102929676\n",
      "#Test#  epoch: 71, dice: 0.7663995994556683\n",
      "#Train#  epoch: 72, loss: 0.07644600421190262, dice: 0.9645705876164906\n",
      "#Val#  epoch: 72, dice: 0.7904258417283947\n",
      "#Test#  epoch: 72, dice: 0.7721176465477961\n",
      "#Train#  epoch: 73, loss: 0.07614030689001083, dice: 0.9641699251178988\n",
      "#Val#  epoch: 73, dice: 0.7779487612052011\n",
      "#Test#  epoch: 73, dice: 0.7596460983823383\n",
      "#Train#  epoch: 74, loss: 0.07546836137771606, dice: 0.9666219614562584\n",
      "#Val#  epoch: 74, dice: 0.7722396251534962\n",
      "#Test#  epoch: 74, dice: 0.753394461484561\n",
      "#Train#  epoch: 75, loss: 0.07516989856958389, dice: 0.9657940949300544\n",
      "#Val#  epoch: 75, dice: 0.7848178550691773\n",
      "#Test#  epoch: 75, dice: 0.7642388285944104\n",
      "#Train#  epoch: 76, loss: 0.07443324476480484, dice: 0.9681035273909152\n",
      "#Val#  epoch: 76, dice: 0.7905957265715954\n",
      "#Test#  epoch: 76, dice: 0.7712546212043815\n",
      "#Train#  epoch: 77, loss: 0.07412154972553253, dice: 0.9679541774028412\n",
      "#Val#  epoch: 77, dice: 0.7862875010639394\n",
      "#Test#  epoch: 77, dice: 0.7676424663645541\n",
      "#Train#  epoch: 78, loss: 0.07351035624742508, dice: 0.9697452205171697\n",
      "#Val#  epoch: 78, dice: 0.778713055237134\n",
      "#Test#  epoch: 78, dice: 0.7603751789337473\n",
      "#Train#  epoch: 79, loss: 0.0731680691242218, dice: 0.9692492472622337\n",
      "#Val#  epoch: 79, dice: 0.7818381403177274\n",
      "#Test#  epoch: 79, dice: 0.7636645221361646\n",
      "#Train#  epoch: 80, loss: 0.07264753431081772, dice: 0.9707377553594384\n",
      "#Val#  epoch: 80, dice: 0.7884152064801115\n",
      "#Test#  epoch: 80, dice: 0.7694834532076809\n",
      "#Train#  epoch: 81, loss: 0.07226108014583588, dice: 0.9709752677505882\n",
      "#Val#  epoch: 81, dice: 0.7858546049422598\n",
      "#Test#  epoch: 81, dice: 0.7657021593835421\n",
      "#Train#  epoch: 82, loss: 0.07175169885158539, dice: 0.9720688278076597\n",
      "#Val#  epoch: 82, dice: 0.7807373133901108\n",
      "#Test#  epoch: 82, dice: 0.7599784912245526\n",
      "#Train#  epoch: 83, loss: 0.07136771827936172, dice: 0.9719544226299579\n",
      "#Val#  epoch: 83, dice: 0.7833704377858149\n",
      "#Test#  epoch: 83, dice: 0.7639627136224816\n",
      "#Train#  epoch: 84, loss: 0.07090756297111511, dice: 0.9730317262942371\n",
      "#Val#  epoch: 84, dice: 0.7837653010524415\n",
      "#Test#  epoch: 84, dice: 0.7648417539590527\n",
      "#Train#  epoch: 85, loss: 0.07058960199356079, dice: 0.9732042648103019\n",
      "#Val#  epoch: 85, dice: 0.7798835076102523\n",
      "#Test#  epoch: 85, dice: 0.7603279890670313\n",
      "#Train#  epoch: 86, loss: 0.0701199322938919, dice: 0.9741536329012255\n",
      "#Val#  epoch: 86, dice: 0.7818370904323547\n",
      "#Test#  epoch: 86, dice: 0.7612707877516193\n",
      "#Train#  epoch: 87, loss: 0.06977887451648712, dice: 0.9741188205111107\n",
      "#Val#  epoch: 87, dice: 0.7852723194186733\n",
      "#Test#  epoch: 87, dice: 0.76483150334588\n",
      "#Train#  epoch: 88, loss: 0.06933819502592087, dice: 0.9749313263891406\n",
      "#Val#  epoch: 88, dice: 0.7843181812027408\n",
      "#Test#  epoch: 88, dice: 0.7648710307835804\n",
      "#Train#  epoch: 89, loss: 0.06898947060108185, dice: 0.9751760115782836\n",
      "#Val#  epoch: 89, dice: 0.7804864508707554\n",
      "#Test#  epoch: 89, dice: 0.760497110476516\n",
      "#Train#  epoch: 90, loss: 0.06860019266605377, dice: 0.9757099008304312\n",
      "#Val#  epoch: 90, dice: 0.782700639465676\n",
      "#Test#  epoch: 90, dice: 0.7617594680007823\n",
      "#Train#  epoch: 91, loss: 0.06823937594890594, dice: 0.9760819731110388\n",
      "#Val#  epoch: 91, dice: 0.7870544748906502\n",
      "#Test#  epoch: 91, dice: 0.7664274483112564\n",
      "#Train#  epoch: 92, loss: 0.06787219643592834, dice: 0.9765010897809296\n",
      "#Val#  epoch: 92, dice: 0.7832631573119165\n",
      "#Test#  epoch: 92, dice: 0.763236674677275\n",
      "#Train#  epoch: 93, loss: 0.06750643253326416, dice: 0.9769435364544706\n",
      "#Val#  epoch: 93, dice: 0.7802930623709963\n",
      "#Test#  epoch: 93, dice: 0.7594926457725738\n",
      "#Train#  epoch: 94, loss: 0.06716497242450714, dice: 0.9771218867376972\n",
      "#Val#  epoch: 94, dice: 0.7838057172541428\n",
      "#Test#  epoch: 94, dice: 0.7628877388372435\n",
      "#Train#  epoch: 95, loss: 0.06680743396282196, dice: 0.9777193676877797\n",
      "#Val#  epoch: 95, dice: 0.7863126315253748\n",
      "#Test#  epoch: 95, dice: 0.7657683263588222\n",
      "#Train#  epoch: 96, loss: 0.06647172570228577, dice: 0.9779985288294339\n",
      "#Val#  epoch: 96, dice: 0.7814805545982103\n",
      "#Test#  epoch: 96, dice: 0.7602019439822841\n",
      "#Train#  epoch: 97, loss: 0.06614528596401215, dice: 0.9781993644592629\n",
      "#Val#  epoch: 97, dice: 0.7870954505476396\n",
      "#Test#  epoch: 97, dice: 0.7659897673904085\n",
      "#Train#  epoch: 98, loss: 0.0658116340637207, dice: 0.9784713085850949\n",
      "#Val#  epoch: 98, dice: 0.7807086874299403\n",
      "#Test#  epoch: 98, dice: 0.7596820186497711\n",
      "#Train#  epoch: 99, loss: 0.06555207073688507, dice: 0.978307915272316\n",
      "#Val#  epoch: 99, dice: 0.7862945201173933\n",
      "#Test#  epoch: 99, dice: 0.7664179310831654\n",
      "#Train#  epoch: 100, loss: 0.06552500277757645, dice: 0.9761197595546082\n",
      "#Val#  epoch: 100, dice: 0.7704427592173827\n",
      "#Test#  epoch: 100, dice: 0.747890174225867\n",
      "#Train#  epoch: 101, loss: 0.0660390704870224, dice: 0.9712882451182505\n",
      "#Val#  epoch: 101, dice: 0.7862728693962057\n",
      "#Test#  epoch: 101, dice: 0.7671978515857514\n",
      "#Train#  epoch: 102, loss: 0.06646513938903809, dice: 0.9663114892955834\n",
      "#Val#  epoch: 102, dice: 0.7756624899769107\n",
      "#Test#  epoch: 102, dice: 0.7539883550721318\n",
      "#Train#  epoch: 103, loss: 0.06509730219841003, dice: 0.9733424717413671\n",
      "#Val#  epoch: 103, dice: 0.7911880457836972\n",
      "#Test#  epoch: 103, dice: 0.7704622276421634\n",
      "#Train#  epoch: 104, loss: 0.064181849360466, dice: 0.9782878100183108\n",
      "#Val#  epoch: 104, dice: 0.7920529614853128\n",
      "#Test#  epoch: 104, dice: 0.7727889379634225\n",
      "#Train#  epoch: 105, loss: 0.06461682915687561, dice: 0.9730130359415389\n",
      "#Val#  epoch: 105, dice: 0.7922620077162444\n",
      "#Test#  epoch: 105, dice: 0.77096963386254\n",
      "#Train#  epoch: 106, loss: 0.06370938569307327, dice: 0.9780364400495131\n",
      "#Val#  epoch: 106, dice: 0.7756513465958262\n",
      "#Test#  epoch: 106, dice: 0.7550810318563453\n",
      "#Train#  epoch: 107, loss: 0.06367561221122742, dice: 0.9766086017218418\n",
      "#Val#  epoch: 107, dice: 0.7864574116061409\n",
      "#Test#  epoch: 107, dice: 0.7671129291325858\n",
      "#Train#  epoch: 108, loss: 0.06329337507486343, dice: 0.9774301191009461\n",
      "#Val#  epoch: 108, dice: 0.7945517118196205\n",
      "#Test#  epoch: 108, dice: 0.7752926667273948\n",
      "#Train#  epoch: 109, loss: 0.06288246810436249, dice: 0.9784961343200463\n",
      "#Val#  epoch: 109, dice: 0.7869387194732546\n",
      "#Test#  epoch: 109, dice: 0.766178833815978\n",
      "#Train#  epoch: 110, loss: 0.06266827881336212, dice: 0.9788249018904089\n",
      "#Val#  epoch: 110, dice: 0.7867343918808904\n",
      "#Test#  epoch: 110, dice: 0.7651712875765309\n",
      "#Train#  epoch: 111, loss: 0.06224054843187332, dice: 0.9798093164901291\n",
      "#Val#  epoch: 111, dice: 0.7917000537439715\n",
      "#Test#  epoch: 111, dice: 0.7710154491310379\n",
      "#Train#  epoch: 112, loss: 0.06205064803361893, dice: 0.9791672325577284\n",
      "#Val#  epoch: 112, dice: 0.7886782405311485\n",
      "#Test#  epoch: 112, dice: 0.7684776831685987\n",
      "#Train#  epoch: 113, loss: 0.061655864119529724, dice: 0.9807543485523061\n",
      "#Val#  epoch: 113, dice: 0.7849168211696621\n",
      "#Test#  epoch: 113, dice: 0.7650976868973971\n",
      "#Train#  epoch: 114, loss: 0.06146037578582764, dice: 0.9805084224220925\n",
      "#Val#  epoch: 114, dice: 0.7864117455590444\n",
      "#Test#  epoch: 114, dice: 0.7652623640427709\n",
      "#Train#  epoch: 115, loss: 0.0610990934073925, dice: 0.9811847060566592\n",
      "#Val#  epoch: 115, dice: 0.7879735181714772\n",
      "#Test#  epoch: 115, dice: 0.7670219628265693\n",
      "#Train#  epoch: 116, loss: 0.06088286638259888, dice: 0.9812203316522257\n",
      "#Val#  epoch: 116, dice: 0.7881873327592239\n",
      "#Test#  epoch: 116, dice: 0.7675160104049672\n",
      "#Train#  epoch: 117, loss: 0.06057300418615341, dice: 0.9818209914705626\n",
      "#Val#  epoch: 117, dice: 0.7874745289613208\n",
      "#Test#  epoch: 117, dice: 0.7661637256494023\n",
      "#Train#  epoch: 118, loss: 0.0603228360414505, dice: 0.9818721196359187\n",
      "#Val#  epoch: 118, dice: 0.7884768114347876\n",
      "#Test#  epoch: 118, dice: 0.7674203812388605\n",
      "#Train#  epoch: 119, loss: 0.06003574654459953, dice: 0.9822992443767496\n",
      "#Val#  epoch: 119, dice: 0.787923295368825\n",
      "#Test#  epoch: 119, dice: 0.7664153026190281\n",
      "#Train#  epoch: 120, loss: 0.059784069657325745, dice: 0.9823994759155569\n",
      "#Val#  epoch: 120, dice: 0.7847236251764333\n",
      "#Test#  epoch: 120, dice: 0.7637267656519247\n",
      "#Train#  epoch: 121, loss: 0.05951521545648575, dice: 0.9828084756470986\n",
      "#Val#  epoch: 121, dice: 0.7875494770173992\n",
      "#Test#  epoch: 121, dice: 0.7669037380779813\n",
      "#Train#  epoch: 122, loss: 0.05925774574279785, dice: 0.9829339329038268\n",
      "#Val#  epoch: 122, dice: 0.7892268320313338\n",
      "#Test#  epoch: 122, dice: 0.7684981471109483\n",
      "#Train#  epoch: 123, loss: 0.05901389569044113, dice: 0.9831069063590596\n",
      "#Val#  epoch: 123, dice: 0.7856450798721432\n",
      "#Test#  epoch: 123, dice: 0.7639244405672185\n",
      "#Train#  epoch: 124, loss: 0.058762915432453156, dice: 0.9833789150002804\n",
      "#Val#  epoch: 124, dice: 0.7864785216376503\n",
      "#Test#  epoch: 124, dice: 0.7653203872815543\n",
      "#Train#  epoch: 125, loss: 0.05849449336528778, dice: 0.9836241178635727\n",
      "#Val#  epoch: 125, dice: 0.7881804290591171\n",
      "#Test#  epoch: 125, dice: 0.7664768972392774\n",
      "#Train#  epoch: 126, loss: 0.05824565514922142, dice: 0.9838538993510543\n",
      "#Val#  epoch: 126, dice: 0.7862182414196353\n",
      "#Test#  epoch: 126, dice: 0.7646425633625243\n",
      "#Train#  epoch: 127, loss: 0.05801140516996384, dice: 0.9839713353553973\n",
      "#Val#  epoch: 127, dice: 0.7874737041545332\n",
      "#Test#  epoch: 127, dice: 0.7657540007876718\n",
      "#Train#  epoch: 128, loss: 0.05777498707175255, dice: 0.9840650169259767\n",
      "#Val#  epoch: 128, dice: 0.7885596994728947\n",
      "#Test#  epoch: 128, dice: 0.7674111797012407\n",
      "#Train#  epoch: 129, loss: 0.05752898380160332, dice: 0.9843556742489739\n",
      "#Val#  epoch: 129, dice: 0.7876782564091979\n",
      "#Test#  epoch: 129, dice: 0.7659154784414925\n",
      "#Train#  epoch: 130, loss: 0.057284221053123474, dice: 0.9844662733164907\n",
      "#Val#  epoch: 130, dice: 0.7866059056562635\n",
      "#Test#  epoch: 130, dice: 0.7649358478858992\n",
      "#Train#  epoch: 131, loss: 0.05705101788043976, dice: 0.9846960835946329\n",
      "#Val#  epoch: 131, dice: 0.7884084859077587\n",
      "#Test#  epoch: 131, dice: 0.7667761536826972\n",
      "#Train#  epoch: 132, loss: 0.056813545525074005, dice: 0.9848630081630223\n",
      "#Val#  epoch: 132, dice: 0.7871752471113225\n",
      "#Test#  epoch: 132, dice: 0.7653167573451993\n",
      "#Train#  epoch: 133, loss: 0.05658469349145889, dice: 0.9850045343984957\n",
      "#Val#  epoch: 133, dice: 0.7870042821729427\n",
      "#Test#  epoch: 133, dice: 0.7652305776071202\n",
      "#Train#  epoch: 134, loss: 0.05635955557227135, dice: 0.985124166154621\n",
      "#Val#  epoch: 134, dice: 0.7875988600979663\n",
      "#Test#  epoch: 134, dice: 0.7661083547491617\n",
      "#Train#  epoch: 135, loss: 0.05613461881875992, dice: 0.9853082253537857\n",
      "#Val#  epoch: 135, dice: 0.7874246495706513\n",
      "#Test#  epoch: 135, dice: 0.7654574706026172\n",
      "#Train#  epoch: 136, loss: 0.05591562017798424, dice: 0.9853537497424275\n",
      "#Val#  epoch: 136, dice: 0.786784321357954\n",
      "#Test#  epoch: 136, dice: 0.7653256068148148\n",
      "#Train#  epoch: 137, loss: 0.055705782026052475, dice: 0.9853888526166118\n",
      "#Val#  epoch: 137, dice: 0.7882306464293478\n",
      "#Test#  epoch: 137, dice: 0.7661086614372196\n",
      "#Train#  epoch: 138, loss: 0.05555425584316254, dice: 0.9849615336846362\n",
      "#Val#  epoch: 138, dice: 0.7854780790255053\n",
      "#Test#  epoch: 138, dice: 0.7639644022417109\n",
      "#Train#  epoch: 139, loss: 0.05550939589738846, dice: 0.9839363244480808\n",
      "#Val#  epoch: 139, dice: 0.7875440801884125\n",
      "#Test#  epoch: 139, dice: 0.7651892988314418\n",
      "#Train#  epoch: 140, loss: 0.05574915558099747, dice: 0.9807960026910758\n",
      "#Val#  epoch: 140, dice: 0.7854679087566944\n",
      "#Test#  epoch: 140, dice: 0.7647130447801849\n",
      "#Train#  epoch: 141, loss: 0.05621660500764847, dice: 0.977647582141124\n",
      "#Val#  epoch: 141, dice: 0.7844794245668656\n",
      "#Test#  epoch: 141, dice: 0.7617220682108721\n",
      "#Train#  epoch: 142, loss: 0.05599774047732353, dice: 0.9769773596729069\n",
      "#Val#  epoch: 142, dice: 0.7965345225787547\n",
      "#Test#  epoch: 142, dice: 0.7763949396792088\n",
      "#Train#  epoch: 143, loss: 0.05481220409274101, dice: 0.983373990568325\n",
      "#Val#  epoch: 143, dice: 0.7910405455719337\n",
      "#Test#  epoch: 143, dice: 0.7708857934165151\n",
      "#Train#  epoch: 144, loss: 0.0545005202293396, dice: 0.9840835062615502\n",
      "#Val#  epoch: 144, dice: 0.7863965448567257\n",
      "#Test#  epoch: 144, dice: 0.7638677785876525\n",
      "#Train#  epoch: 145, loss: 0.05464357137680054, dice: 0.9818142691518293\n",
      "#Val#  epoch: 145, dice: 0.7868963850463871\n",
      "#Test#  epoch: 145, dice: 0.7672197024886612\n",
      "#Train#  epoch: 146, loss: 0.054097287356853485, dice: 0.9841523943212002\n",
      "#Val#  epoch: 146, dice: 0.7940185307232995\n",
      "#Test#  epoch: 146, dice: 0.7732883090350073\n",
      "#Train#  epoch: 147, loss: 0.05388784036040306, dice: 0.9846601831598394\n",
      "#Val#  epoch: 147, dice: 0.7931437726511037\n",
      "#Test#  epoch: 147, dice: 0.771466241852798\n",
      "#Train#  epoch: 148, loss: 0.053803347051143646, dice: 0.9838998318843261\n",
      "#Val#  epoch: 148, dice: 0.7864254954021136\n",
      "#Test#  epoch: 148, dice: 0.7645739238451187\n",
      "#Train#  epoch: 149, loss: 0.05341078341007233, dice: 0.9851679671473812\n",
      "#Val#  epoch: 149, dice: 0.7877820199454015\n",
      "#Test#  epoch: 149, dice: 0.7661849773422363\n",
      "#Train#  epoch: 150, loss: 0.05320247262716293, dice: 0.9852583660892907\n",
      "#Val#  epoch: 150, dice: 0.7893910666599064\n",
      "#Test#  epoch: 150, dice: 0.7688564652031318\n",
      "#Train#  epoch: 151, loss: 0.0530705600976944, dice: 0.9847676761458413\n",
      "#Val#  epoch: 151, dice: 0.7888363457110276\n",
      "#Test#  epoch: 151, dice: 0.7682346386186597\n",
      "#Train#  epoch: 152, loss: 0.052763432264328, dice: 0.9858614475673554\n",
      "#Val#  epoch: 152, dice: 0.7891166931844082\n",
      "#Test#  epoch: 152, dice: 0.7685270509322639\n",
      "#Train#  epoch: 153, loss: 0.052559174597263336, dice: 0.9860775400741513\n",
      "#Val#  epoch: 153, dice: 0.789709136302511\n",
      "#Test#  epoch: 153, dice: 0.7688197834739748\n",
      "#Train#  epoch: 154, loss: 0.05240534991025925, dice: 0.9857978284424331\n",
      "#Val#  epoch: 154, dice: 0.79042130671007\n",
      "#Test#  epoch: 154, dice: 0.76878496587512\n",
      "#Train#  epoch: 155, loss: 0.05213182419538498, dice: 0.986457249418654\n",
      "#Val#  epoch: 155, dice: 0.7870748272544634\n",
      "#Test#  epoch: 155, dice: 0.7655588360759928\n",
      "#Train#  epoch: 156, loss: 0.05196508392691612, dice: 0.9863260966215719\n",
      "#Val#  epoch: 156, dice: 0.7884898364830313\n",
      "#Test#  epoch: 156, dice: 0.7672657202548913\n",
      "#Train#  epoch: 157, loss: 0.05176321789622307, dice: 0.9864643017276563\n",
      "#Val#  epoch: 157, dice: 0.7880534095211961\n",
      "#Test#  epoch: 157, dice: 0.766458360879023\n",
      "#Train#  epoch: 158, loss: 0.05153592675924301, dice: 0.98680676769952\n",
      "#Val#  epoch: 158, dice: 0.7875563742722764\n",
      "#Test#  epoch: 158, dice: 0.7659428638540071\n",
      "#Train#  epoch: 159, loss: 0.05137225612998009, dice: 0.9867828393508713\n",
      "#Val#  epoch: 159, dice: 0.7895706085786189\n",
      "#Test#  epoch: 159, dice: 0.7680618646937614\n",
      "#Train#  epoch: 160, loss: 0.05114959180355072, dice: 0.9869967953014683\n",
      "#Val#  epoch: 160, dice: 0.7883133949204107\n",
      "#Test#  epoch: 160, dice: 0.7669077030893192\n",
      "#Train#  epoch: 161, loss: 0.050957243889570236, dice: 0.9871950370655824\n",
      "#Val#  epoch: 161, dice: 0.7899987775151285\n",
      "#Test#  epoch: 161, dice: 0.768199356006564\n",
      "#Train#  epoch: 162, loss: 0.050768401473760605, dice: 0.9872524348033527\n",
      "#Val#  epoch: 162, dice: 0.7881510821136963\n",
      "#Test#  epoch: 162, dice: 0.7668380946326263\n",
      "#Train#  epoch: 163, loss: 0.05056757852435112, dice: 0.9873783194505535\n",
      "#Val#  epoch: 163, dice: 0.7874293690224538\n",
      "#Test#  epoch: 163, dice: 0.7664168033593485\n",
      "#Train#  epoch: 164, loss: 0.05038709565997124, dice: 0.9874658034560697\n",
      "#Val#  epoch: 164, dice: 0.7895136453529942\n",
      "#Test#  epoch: 164, dice: 0.7675681620726934\n",
      "#Train#  epoch: 165, loss: 0.050187453627586365, dice: 0.9875653895307019\n",
      "#Val#  epoch: 165, dice: 0.7889915132446715\n",
      "#Test#  epoch: 165, dice: 0.7674632897506981\n",
      "#Train#  epoch: 166, loss: 0.050007663667201996, dice: 0.987546740745276\n",
      "#Val#  epoch: 166, dice: 0.7867535478960633\n",
      "#Test#  epoch: 166, dice: 0.7656002268216616\n",
      "#Train#  epoch: 167, loss: 0.04982399567961693, dice: 0.9876347830596774\n",
      "#Val#  epoch: 167, dice: 0.7897017380873104\n",
      "#Test#  epoch: 167, dice: 0.7680015817341271\n",
      "#Train#  epoch: 168, loss: 0.04966317117214203, dice: 0.9874848399555507\n",
      "#Val#  epoch: 168, dice: 0.7867943063874363\n",
      "#Test#  epoch: 168, dice: 0.7643718014577847\n",
      "#Train#  epoch: 169, loss: 0.04951754957437515, dice: 0.9871798292594861\n",
      "#Val#  epoch: 169, dice: 0.790165057169577\n",
      "#Test#  epoch: 169, dice: 0.7689787264149355\n",
      "#Train#  epoch: 170, loss: 0.049385227262973785, dice: 0.9866725251495894\n",
      "#Val#  epoch: 170, dice: 0.7868011044740354\n",
      "#Test#  epoch: 170, dice: 0.7651968741788906\n",
      "#Train#  epoch: 171, loss: 0.049261581152677536, dice: 0.9862507919858512\n",
      "#Val#  epoch: 171, dice: 0.7870894173515196\n",
      "#Test#  epoch: 171, dice: 0.7655077467070205\n",
      "#Train#  epoch: 172, loss: 0.04921675845980644, dice: 0.985514844192342\n",
      "#Val#  epoch: 172, dice: 0.7958136245439807\n",
      "#Test#  epoch: 172, dice: 0.7754874963775149\n",
      "#Train#  epoch: 173, loss: 0.04906545579433441, dice: 0.9854761396800316\n",
      "#Val#  epoch: 173, dice: 0.7784486963245644\n",
      "#Test#  epoch: 173, dice: 0.7562558324075545\n",
      "#Train#  epoch: 174, loss: 0.04880710691213608, dice: 0.9861151505891737\n",
      "#Val#  epoch: 174, dice: 0.7943389933062822\n",
      "#Test#  epoch: 174, dice: 0.7737923760183804\n",
      "#Train#  epoch: 175, loss: 0.048439498990774155, dice: 0.9873937084397765\n",
      "#Val#  epoch: 175, dice: 0.7909575745050627\n",
      "#Test#  epoch: 175, dice: 0.7693783829642922\n",
      "#Train#  epoch: 176, loss: 0.04819674789905548, dice: 0.9880874385049007\n",
      "#Val#  epoch: 176, dice: 0.7840022275110279\n",
      "#Test#  epoch: 176, dice: 0.7625411323655453\n",
      "#Train#  epoch: 177, loss: 0.048082299530506134, dice: 0.9877407630383446\n",
      "#Val#  epoch: 177, dice: 0.790934047094309\n",
      "#Test#  epoch: 177, dice: 0.7691675933526275\n",
      "#Train#  epoch: 178, loss: 0.04794476926326752, dice: 0.9873452604821131\n",
      "#Val#  epoch: 178, dice: 0.7883806258591195\n",
      "#Test#  epoch: 178, dice: 0.767857102575844\n",
      "#Train#  epoch: 179, loss: 0.04771868512034416, dice: 0.9879482349245352\n",
      "#Val#  epoch: 179, dice: 0.7885645768393023\n",
      "#Test#  epoch: 179, dice: 0.7667031731204511\n",
      "#Train#  epoch: 180, loss: 0.047521546483039856, dice: 0.9881980134972045\n",
      "#Val#  epoch: 180, dice: 0.7912849720219388\n",
      "#Test#  epoch: 180, dice: 0.7704036591478024\n",
      "#Train#  epoch: 181, loss: 0.047319963574409485, dice: 0.9883595477652549\n",
      "#Val#  epoch: 181, dice: 0.7853200589905641\n",
      "#Test#  epoch: 181, dice: 0.7642298892757488\n",
      "#Train#  epoch: 182, loss: 0.04716181755065918, dice: 0.9884164541720057\n",
      "#Val#  epoch: 182, dice: 0.7889732734237943\n",
      "#Test#  epoch: 182, dice: 0.7668306291755377\n",
      "#Train#  epoch: 183, loss: 0.046966806054115295, dice: 0.9884994351498199\n",
      "#Val#  epoch: 183, dice: 0.7924675477046551\n",
      "#Test#  epoch: 183, dice: 0.7705739016742896\n",
      "#Train#  epoch: 184, loss: 0.046796731650829315, dice: 0.9885407268645101\n",
      "#Val#  epoch: 184, dice: 0.7859282446717063\n",
      "#Test#  epoch: 184, dice: 0.7647021115247316\n",
      "#Train#  epoch: 185, loss: 0.046597640961408615, dice: 0.9887734992534455\n",
      "#Val#  epoch: 185, dice: 0.7899562065916852\n",
      "#Test#  epoch: 185, dice: 0.7686166360969606\n",
      "#Train#  epoch: 186, loss: 0.04640906676650047, dice: 0.9889310544215894\n",
      "#Val#  epoch: 186, dice: 0.7890278476113561\n",
      "#Test#  epoch: 186, dice: 0.7669427239682379\n",
      "#Train#  epoch: 187, loss: 0.04624538868665695, dice: 0.9889021379543395\n",
      "#Val#  epoch: 187, dice: 0.7864414403563542\n",
      "#Test#  epoch: 187, dice: 0.7645384449497806\n",
      "#Train#  epoch: 188, loss: 0.04607939347624779, dice: 0.9889585756998307\n",
      "#Val#  epoch: 188, dice: 0.7914735088956248\n",
      "#Test#  epoch: 188, dice: 0.7703296085770813\n",
      "#Train#  epoch: 189, loss: 0.04589923471212387, dice: 0.988976432179297\n",
      "#Val#  epoch: 189, dice: 0.7880286541447952\n",
      "#Test#  epoch: 189, dice: 0.7657661774926878\n",
      "#Train#  epoch: 190, loss: 0.04571803659200668, dice: 0.9890735783837109\n",
      "#Val#  epoch: 190, dice: 0.7869760945445119\n",
      "#Test#  epoch: 190, dice: 0.7652473454804009\n",
      "#Train#  epoch: 191, loss: 0.04557554051280022, dice: 0.9887427933637993\n",
      "#Val#  epoch: 191, dice: 0.790948293102636\n",
      "#Test#  epoch: 191, dice: 0.7696660192921202\n",
      "#Train#  epoch: 192, loss: 0.045499883592128754, dice: 0.9882259144393418\n",
      "#Val#  epoch: 192, dice: 0.7874854224942187\n",
      "#Test#  epoch: 192, dice: 0.766125989043401\n",
      "#Train#  epoch: 193, loss: 0.04547907039523125, dice: 0.9868910715878804\n",
      "#Val#  epoch: 193, dice: 0.7875608340951266\n",
      "#Test#  epoch: 193, dice: 0.7655242854522255\n",
      "#Train#  epoch: 194, loss: 0.045475661754608154, dice: 0.9858979840706223\n",
      "#Val#  epoch: 194, dice: 0.7890907972696354\n",
      "#Test#  epoch: 194, dice: 0.7679179438563345\n",
      "#Train#  epoch: 195, loss: 0.045325543731451035, dice: 0.9855738612168518\n",
      "#Val#  epoch: 195, dice: 0.7915804396401585\n",
      "#Test#  epoch: 195, dice: 0.7697549742121376\n",
      "#Train#  epoch: 196, loss: 0.04503081738948822, dice: 0.9867768242809974\n",
      "#Val#  epoch: 196, dice: 0.7839877434986126\n",
      "#Test#  epoch: 196, dice: 0.7623167008438481\n",
      "#Train#  epoch: 197, loss: 0.044766396284103394, dice: 0.9876680813179073\n",
      "#Val#  epoch: 197, dice: 0.7940762644700543\n",
      "#Test#  epoch: 197, dice: 0.774069188982035\n",
      "#Train#  epoch: 198, loss: 0.04460012912750244, dice: 0.9875256015289718\n",
      "#Val#  epoch: 198, dice: 0.7931533369600618\n",
      "#Test#  epoch: 198, dice: 0.7711142476930615\n",
      "#Train#  epoch: 199, loss: 0.04439609870314598, dice: 0.9880528208751921\n",
      "#Val#  epoch: 199, dice: 0.7858894554997704\n",
      "#Test#  epoch: 199, dice: 0.7644759835975286\n",
      "#Train#  epoch: 200, loss: 0.044208355247974396, dice: 0.9881997297273448\n",
      "#Val#  epoch: 200, dice: 0.7901246776172721\n",
      "#Test#  epoch: 200, dice: 0.7694437461273301\n"
     ]
    }
   ],
   "source": [
    "print('#----------Start training----------#')\n",
    "torch.cuda.empty_cache()\n",
    "info = \"%d-resizeh, %d-resizew, %f-outer_lr\"%(config.resize_h,config.resize_w,config.outer_lr)\n",
    "print(info)\n",
    "logger.info(info)\n",
    "best_dice_val = 0.0\n",
    "best_dice_test = 0.0\n",
    "train_csv = os.path.join(csv_save,\"train.csv\")\n",
    "val_csv = os.path.join(csv_save,\"val.csv\")\n",
    "test_csv = os.path.join(csv_save,\"test.csv\")\n",
    "train_columns = ['Epoch','Loss',\"Mdice\"]\n",
    "train_df = pd.DataFrame(columns=train_columns)\n",
    "val_columns = ['Epoch','Mdice']\n",
    "val_df = pd.DataFrame(columns=val_columns)\n",
    "test_columns = ['Epoch','Mdice']\n",
    "test_df = pd.DataFrame(columns=test_columns)\n",
    "for epoch in range(start_epoch, config.epoch_num+1):\n",
    "    \n",
    "    # train part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    loss_list = []    \n",
    "    base_net.train()\n",
    "    meta_optimizer.zero_grad()\n",
    "    for category_index in range(num_categories):\n",
    "        for image,mask in train_loader_list[category_index]:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)     # torch.Size([bs,out_channels=1,512,512])\n",
    "            predicted = predicted.squeeze(1)    # torch.Size([bs,512,512])\n",
    "            loss = criterion(predicted,mask)\n",
    "            loss = loss/num_categories\n",
    "            loss.backward()\n",
    "            predicted = (predicted > threshold).long()\n",
    "            temp_predicted = predicted.cpu().detach().numpy()       # threshold alternative\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "    meta_optimizer.step()\n",
    "    loss_list.append(loss.cpu().detach().numpy())\n",
    "    \n",
    "    # train_dice,train_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "    train_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "    train_mloss = np.mean(loss_list)\n",
    "    log_train = f'epoch: {epoch}, loss: {train_mloss}, dice: {train_dice}'\n",
    "    print(\"#Train# \",log_train)\n",
    "    temp_result = pd.Series([epoch,train_mloss,train_dice],index=train_columns)\n",
    "    train_df = train_df.append(temp_result, ignore_index=True)\n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    \n",
    "    # validation part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in val_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "        # val_dice,val_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        val_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_val = f'epoch: {epoch}, dice: {val_dice}'\n",
    "        print(\"#Val# \",log_val)\n",
    "        temp_result = pd.Series([epoch,val_dice],index=val_columns)\n",
    "        val_df = val_df.append(temp_result, ignore_index=True)\n",
    "        val_df.to_csv(val_csv, index=False)\n",
    "        # logger.info(log_val)\n",
    "\n",
    "    if val_dice > best_dice_val:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_val.pth'))\n",
    "        best_dice_val = val_dice\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # test part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in test_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "        # test_dice,test_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        test_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_test = f'epoch: {epoch}, dice: {test_dice}'\n",
    "        print(\"#Test# \",log_test)\n",
    "        temp_result = pd.Series([epoch,test_dice],index=test_columns)\n",
    "        test_df = test_df.append(temp_result, ignore_index=True)\n",
    "        test_df.to_csv(test_csv, index=False)\n",
    "        logger.info(log_test)\n",
    "\n",
    "    if test_dice > best_dice_test:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_test.pth'))\n",
    "        best_dice_test = test_dice\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best dice in testset:0.780759217217014\n"
     ]
    }
   ],
   "source": [
    "best_result_test = \"Best dice in testset:\" + str(best_dice_test)\n",
    "print(best_result_test)\n",
    "logger.info(best_result_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
