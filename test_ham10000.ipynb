{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import *\n",
    "from models.meta import Meta\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from models.basenet import *\n",
    "from utils import *\n",
    "from configs.config_setting_test import setting_config\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics as metrics\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.init as init\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = setting_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    support_images = batch['support_images'].squeeze(0)\n",
    "    support_masks = batch['support_masks'].squeeze(0)\n",
    "    query_images = batch['query_images'].squeeze(0)\n",
    "    query_masks = batch['query_masks'].squeeze(0)\n",
    "    return support_images, support_masks, query_images, query_masks\n",
    "\n",
    "# the function of copying the images\n",
    "def copy_file_to_folder(source_file, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    dest_path = os.path.join(dest_folder, os.path.basename(source_file))\n",
    "    shutil.copy(source_file, dest_path)\n",
    "\n",
    "def evaluation_api(predicted_list,groudtruth_list):\n",
    "    pre = np.array([item for sublist in predicted_list for item in sublist]).reshape(-1)\n",
    "    gts = np.array([item for sublist in groudtruth_list for item in sublist]).reshape(-1)\n",
    "    # confusion_matrix = metrics.confusion_matrix(gts,pre)\n",
    "    # TN, FP, FN, TP = confusion[0,0], confusion[0,1], confusion[1,0], confusion[1,1] \n",
    "    dice = metrics.f1_score(gts,pre)\n",
    "\n",
    "    return dice\n",
    "\n",
    "def evaluation_epoch(predicted_list,groundtruth_list):\n",
    "    TP = [0]*config.num_classes\n",
    "    FP = [0]*config.num_classes\n",
    "    FN = [0]*config.num_classes\n",
    "    dice = [0.0]*config.num_classes\n",
    "    \n",
    "    for i in range(len(predicted_list)):\n",
    "        preds = np.array(predicted_list[i]).reshape(-1)\n",
    "        gts = np.array(groundtruth_list[i]).reshape(-1)\n",
    "        for j in range(len(preds)):\n",
    "            if preds[j] == gts[j]:\n",
    "                TP[gts[j]] += 1\n",
    "            else:\n",
    "                FP[preds[j]] += 1\n",
    "                FN[gts[j]] += 1        \n",
    "    \n",
    "    for i in range(config.num_classes):\n",
    "        dice[i] = (2 * TP[i])/(FP[i]+FN[i]+2*TP[i]+1)\n",
    "\n",
    "    mdice = (2*np.sum(TP))/(np.sum(FP)+np.sum(FN)+2*np.sum(TP)+1)    \n",
    "    return dice,mdice\n",
    "\n",
    "def evaluation_basenet(base_net,query_images,query_masks,criterion):\n",
    "    predicted = base_net(query_images)\n",
    "    loss = criterion(predicted,query_masks)\n",
    "    predicted = torch.argmax(predicted,dim=1).long()\n",
    "    predict_numpy = predicted.detach().cpu().numpy().reshape(-1)\n",
    "    masks_numpy = query_masks.long().detach().cpu().numpy().reshape(-1)\n",
    "    accuracy = metrics.accuracy_score(masks_numpy,predict_numpy)\n",
    "    f1_score = metrics.f1_score(masks_numpy,predict_numpy,average=None)\n",
    "    return accuracy,f1_score,loss\n",
    "\n",
    "def initialize_weights_he(model):\n",
    "    for param in model.parameters():\n",
    "        init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "def initialize_weights_xavier(model):\n",
    "    for param in model.parameters():\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "def initialize_weights_normal(model):\n",
    "    for param in model.parameters():\n",
    "        init.normal_(param, mean=0, std=1)\n",
    "\n",
    "def remove_exsits_folder(folderpath):\n",
    "    if os.path.exists(folderpath):\n",
    "        shutil.rmtree(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Creating logger----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Creating logger----------#')\n",
    "sys.path.append(config.work_dir + '/')\n",
    "log_dir = os.path.join(config.work_dir, 'log')\n",
    "checkpoint_dir = os.path.join(config.work_dir, 'checkpoints')\n",
    "resume_model = os.path.join(checkpoint_dir, 'latest.pth')\n",
    "outputs = os.path.join(config.work_dir, 'outputs')\n",
    "csv_save = os.path.join(config.work_dir, 'csv')\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "if not os.path.exists(csv_save):\n",
    "    os.makedirs(csv_save)\n",
    "\n",
    "global logger\n",
    "logger = get_logger('test', log_dir)\n",
    "global writer\n",
    "writer = SummaryWriter(config.work_dir + 'summary')\n",
    "\n",
    "log_config_info(config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Generating data----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Generating data----------#')\n",
    "images_resources_path = \"./data/HAM10000/origin/images/\"         # the resource folder of images\n",
    "masks_resources_path = \"./data/HAM10000/origin/masks/\"           # the resource folder of masks\n",
    "ratio = [0.6,0.2]     # the ratio point of train dataset and validation set and testset\n",
    "categories = config.categories\n",
    "categories_dictionary = {}\n",
    "category_id = 1\n",
    "# prepare the csv for groundtruth\n",
    "origin_groundtruth_csv = \"./data/HAM10000/origin/groundtruth/HAM10000_groundtruth.csv\"   # read the csv file\n",
    "origin_groundtruth = pd.read_csv(origin_groundtruth_csv)    # read the csv file of groundtruth\n",
    "\n",
    "# generating the folders for each category in train folder and test folder\n",
    "# create folders for each categories\n",
    "trainset_images_path = \"./data/HAM10000/train/images/\"     # the images path for train dataset\n",
    "trainset_masks_path = \"./data/HAM10000/train/masks/\"     # the masks path for train dataset\n",
    "valset_images_path = \"./data/HAM10000/val/images/\"     # the images path for validation dataset\n",
    "valset_masks_path = \"./data/HAM10000/val/masks/\"      # the masks path for validation dataset\n",
    "testset_images_path = \"./data/HAM10000/test/images/\"     # the images path for test dataset\n",
    "testset_masks_path = \"./data/HAM10000/test/masks/\"      # the masks path for test dataset\n",
    "\n",
    "for category in categories:\n",
    "    # prepare the address for folders\n",
    "    category_images_train_path = os.path.join(trainset_images_path,category)\n",
    "    category_masks_train_path = os.path.join(trainset_masks_path,category)\n",
    "    category_images_val_path = os.path.join(valset_images_path,category)\n",
    "    category_masks_val_path = os.path.join(valset_masks_path,category)\n",
    "    category_images_test_path = os.path.join(testset_images_path,category)\n",
    "    category_masks_test_path = os.path.join(testset_masks_path,category)\n",
    "    #delete the previously exsited folders\n",
    "    remove_exsits_folder(category_images_train_path)\n",
    "    remove_exsits_folder(category_masks_train_path)\n",
    "    remove_exsits_folder(category_images_val_path)\n",
    "    remove_exsits_folder(category_masks_val_path)\n",
    "    remove_exsits_folder(category_images_test_path)\n",
    "    remove_exsits_folder(category_masks_test_path)\n",
    "    # create corresponding folder for each categories\n",
    "    os.makedirs(category_images_train_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_train_path, exist_ok=True)\n",
    "    os.makedirs(category_images_val_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_val_path, exist_ok=True)\n",
    "    os.makedirs(category_images_test_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_test_path, exist_ok=True)\n",
    "\n",
    "    # generate the data in trainset and testset for each categories\n",
    "    dest_folder_images = \"./data/HAM10000/train/images/\"+category    # the destination train set folder of copying the images\n",
    "    dest_folder_masks = \"./data/HAM10000/train/masks/\"+category    # the destination trian set folder of copying the masks\n",
    "    dest_folder_images_change_val = \"./data/HAM10000/val/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_val = \"./data/HAM10000/val/masks/\"+category      # the destination folder of test set masks\n",
    "    dest_folder_images_change_test = \"./data/HAM10000/test/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_test = \"./data/HAM10000/test/masks/\"+category      # the destination folder of test set masks\n",
    "    data_categories = origin_groundtruth[origin_groundtruth['dx'] == category]      # extract each categories \n",
    "    data_categories = data_categories.sample(frac=1,random_state=config.seed)       # random sample the datagenerating\n",
    "    length_categories = len(data_categories)\n",
    "    change_folder_point_valset = math.floor(length_categories * ratio[0])     # get the point to change directory name\n",
    "    change_folder_point_testset = math.floor(length_categories * (ratio[0]+ratio[1]))     # get the point to change directory name \n",
    "    elements_count = 0\n",
    "    for image_name in data_categories['image_id']:      # each image_id in each categories\n",
    "        if elements_count == change_folder_point_valset:\n",
    "            dest_folder_images = dest_folder_images_change_val\n",
    "            dest_folder_masks = dest_folder_masks_change_val\n",
    "        elif elements_count == change_folder_point_testset:\n",
    "            dest_folder_images = dest_folder_images_change_test\n",
    "            dest_folder_masks = dest_folder_masks_change_test\n",
    "        images_file = image_name+\".jpg\"\n",
    "        masks_file = image_name+\"_segmentation.png\"\n",
    "        source_image = images_resources_path+images_file    # the full path of source of image : path + image file name\n",
    "        source_mask = masks_resources_path+masks_file       # the full path of source of mask : path + mask file name\n",
    "        copy_file_to_folder(source_image,dest_folder_images)\n",
    "        # masks should be preprocess to the form of output for network (Width*Height*Category)\n",
    "        image = Image.open(source_mask)\n",
    "        image_array = np.array(image)\n",
    "        image_array[image_array == 255] = 1\n",
    "        image = Image.fromarray(image_array)\n",
    "        image.save(os.path.join(dest_folder_masks, masks_file))\n",
    "        elements_count +=1\n",
    "    categories_dictionary[category] = category_id       # add the category id in the categories_dictionary\n",
    "    category_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------GPU init----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------GPU init----------#')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu_id\n",
    "set_seed(config.seed)\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Datasets----------#\n",
      "trian_dataset_list length: 1\n",
      "trian_dataset(df) length: 69\n",
      "val_dataset length: 23\n",
      "test_dataset length: 23\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Datasets----------#')\n",
    "# create the dataset and dataloader\n",
    "batch_size = config.batch_size\n",
    "categories = config.categories\n",
    "num_categories = len(categories)\n",
    "train_dataset_list = []\n",
    "train_loader_list = []\n",
    "for i in range(num_categories):\n",
    "    train_dataset = HAMALL_datasets(config, train=True,categories = [categories[i]],num_eachcat=config.num_eachcat)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "    train_dataset_list.append(train_dataset)\n",
    "    train_loader_list.append(train_loader)\n",
    "val_dataset = HAMALL_datasets(config, train=False,val=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "test_dataset = HAMALL_datasets(config, train=False)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "print(\"trian_dataset_list length:\",len(train_loader_list))\n",
    "for i in range(num_categories):\n",
    "    print(\"trian_dataset(\"+categories[i]+\") length:\",len(train_dataset_list[i]))\n",
    "print(\"val_dataset length:\",len(val_dataset))\n",
    "print(\"test_dataset length:\",len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Model----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Model----------#')\n",
    "in_channels = config.in_channels\n",
    "out_channels = config.out_channels\n",
    "base_net = smp.Unet(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# base_net = smp.UnetPlusPlus(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# initialize_weights_he(base_net)\n",
    "\n",
    "weights_dict = torch.load(config.dicts_path)\n",
    "base_net.load_state_dict(weights_dict,strict=False)\n",
    "base_net = base_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing loss, opt, sch and amp----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing loss, opt, sch and amp----------#')\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "meta_optimizer = get_optimizer(config, base_net)\n",
    "meta_scheduler = get_scheduler(config, meta_optimizer)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Set other params----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Set other params----------#')\n",
    "min_loss = 999\n",
    "start_epoch = 1\n",
    "min_epoch = 1\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Start training----------#\n",
      "128-resizeh, 128-resizew, 0.000001-outer_lr\n",
      "#Train#  epoch: 1, loss: 0.7111740708351135, dice: 0.7703666307394986\n",
      "#Val#  epoch: 1, dice: 0.8040242533123737\n",
      "#Test#  epoch: 1, dice: 0.8442455700733846\n",
      "#Train#  epoch: 2, loss: 0.710902214050293, dice: 0.7703979345283969\n",
      "#Val#  epoch: 2, dice: 0.8067211055276382\n",
      "#Test#  epoch: 2, dice: 0.8381038142406895\n",
      "#Train#  epoch: 3, loss: 0.709984302520752, dice: 0.7705426025260188\n",
      "#Val#  epoch: 3, dice: 0.8095005402109737\n",
      "#Test#  epoch: 3, dice: 0.8357266901782626\n",
      "#Train#  epoch: 4, loss: 0.7089492678642273, dice: 0.7706889389626711\n",
      "#Val#  epoch: 4, dice: 0.8119866235186628\n",
      "#Test#  epoch: 4, dice: 0.8345791424789402\n",
      "#Train#  epoch: 5, loss: 0.7074241042137146, dice: 0.7709145891882072\n",
      "#Val#  epoch: 5, dice: 0.8184113680930508\n",
      "#Test#  epoch: 5, dice: 0.8310236254203526\n",
      "#Train#  epoch: 6, loss: 0.7057659029960632, dice: 0.7710644777794105\n",
      "#Val#  epoch: 6, dice: 0.8199784630095486\n",
      "#Test#  epoch: 6, dice: 0.8281852039831582\n",
      "#Train#  epoch: 7, loss: 0.7036746144294739, dice: 0.771410060313792\n",
      "#Val#  epoch: 7, dice: 0.8177806700065967\n",
      "#Test#  epoch: 7, dice: 0.8268125659318064\n",
      "#Train#  epoch: 8, loss: 0.7014356255531311, dice: 0.7716112552470068\n",
      "#Val#  epoch: 8, dice: 0.8152132326117323\n",
      "#Test#  epoch: 8, dice: 0.8254432147845707\n",
      "#Train#  epoch: 9, loss: 0.6991576552391052, dice: 0.7720816027722819\n",
      "#Val#  epoch: 9, dice: 0.8124697771606281\n",
      "#Test#  epoch: 9, dice: 0.8249772497653322\n",
      "#Train#  epoch: 10, loss: 0.6973156332969666, dice: 0.7723434187164083\n",
      "#Val#  epoch: 10, dice: 0.8099300891264017\n",
      "#Test#  epoch: 10, dice: 0.8245560614582176\n",
      "#Train#  epoch: 11, loss: 0.6947048306465149, dice: 0.7726886467246363\n",
      "#Val#  epoch: 11, dice: 0.8080783061387872\n",
      "#Test#  epoch: 11, dice: 0.8247365104823003\n",
      "#Train#  epoch: 12, loss: 0.6916175484657288, dice: 0.7730770875197742\n",
      "#Val#  epoch: 12, dice: 0.8066031274716438\n",
      "#Test#  epoch: 12, dice: 0.8247658785681825\n",
      "#Train#  epoch: 13, loss: 0.6892094016075134, dice: 0.7734453916250232\n",
      "#Val#  epoch: 13, dice: 0.8056503711423059\n",
      "#Test#  epoch: 13, dice: 0.8249306785452334\n",
      "#Train#  epoch: 14, loss: 0.6865119934082031, dice: 0.7738585774371637\n",
      "#Val#  epoch: 14, dice: 0.8047999576629975\n",
      "#Test#  epoch: 14, dice: 0.8250830511323204\n",
      "#Train#  epoch: 15, loss: 0.6836796998977661, dice: 0.774204410167195\n",
      "#Val#  epoch: 15, dice: 0.8044938869919595\n",
      "#Test#  epoch: 15, dice: 0.8252720850077944\n",
      "#Train#  epoch: 16, loss: 0.6801310777664185, dice: 0.7746333589875148\n",
      "#Val#  epoch: 16, dice: 0.8044879130940015\n",
      "#Test#  epoch: 16, dice: 0.8252278657468636\n",
      "#Train#  epoch: 17, loss: 0.677219569683075, dice: 0.7750009687578919\n",
      "#Val#  epoch: 17, dice: 0.8045132626578101\n",
      "#Test#  epoch: 17, dice: 0.8251627332032896\n",
      "#Train#  epoch: 18, loss: 0.6742244958877563, dice: 0.7754860953348212\n",
      "#Val#  epoch: 18, dice: 0.8042661133263287\n",
      "#Test#  epoch: 18, dice: 0.8253096188125355\n",
      "#Train#  epoch: 19, loss: 0.6711295247077942, dice: 0.776004597025297\n",
      "#Val#  epoch: 19, dice: 0.8042574144252667\n",
      "#Test#  epoch: 19, dice: 0.8254054440237194\n",
      "#Train#  epoch: 20, loss: 0.6678166389465332, dice: 0.7764012840147646\n",
      "#Val#  epoch: 20, dice: 0.8041487211039817\n",
      "#Test#  epoch: 20, dice: 0.8256202332684374\n",
      "#Train#  epoch: 21, loss: 0.6643014550209045, dice: 0.7769257702145402\n",
      "#Val#  epoch: 21, dice: 0.8041251609331265\n",
      "#Test#  epoch: 21, dice: 0.825773081717872\n",
      "#Train#  epoch: 22, loss: 0.661238431930542, dice: 0.7774378876384674\n",
      "#Val#  epoch: 22, dice: 0.8041958349263268\n",
      "#Test#  epoch: 22, dice: 0.8260982936665273\n",
      "#Train#  epoch: 23, loss: 0.6577699780464172, dice: 0.7778413358602126\n",
      "#Val#  epoch: 23, dice: 0.8045208266503786\n",
      "#Test#  epoch: 23, dice: 0.8264138000028585\n",
      "#Train#  epoch: 24, loss: 0.6540127992630005, dice: 0.7781714849383619\n",
      "#Val#  epoch: 24, dice: 0.8045490913247227\n",
      "#Test#  epoch: 24, dice: 0.8264732793869557\n",
      "#Train#  epoch: 25, loss: 0.6507846713066101, dice: 0.7787220505362661\n",
      "#Val#  epoch: 25, dice: 0.804583560343767\n",
      "#Test#  epoch: 25, dice: 0.8265110558082324\n",
      "#Train#  epoch: 26, loss: 0.6468807458877563, dice: 0.7792128636445655\n",
      "#Val#  epoch: 26, dice: 0.8043372244750913\n",
      "#Test#  epoch: 26, dice: 0.8264101536788484\n",
      "#Train#  epoch: 27, loss: 0.6433855295181274, dice: 0.7795969537638231\n",
      "#Val#  epoch: 27, dice: 0.8041065092914604\n",
      "#Test#  epoch: 27, dice: 0.8265612421960251\n",
      "#Train#  epoch: 28, loss: 0.6397246718406677, dice: 0.7800895760574506\n",
      "#Val#  epoch: 28, dice: 0.8040132193972271\n",
      "#Test#  epoch: 28, dice: 0.8267037830836443\n",
      "#Train#  epoch: 29, loss: 0.6361238360404968, dice: 0.7805151879261101\n",
      "#Val#  epoch: 29, dice: 0.8040800210581732\n",
      "#Test#  epoch: 29, dice: 0.8269245221573687\n",
      "#Train#  epoch: 30, loss: 0.632112979888916, dice: 0.7807822979232993\n",
      "#Val#  epoch: 30, dice: 0.8040890643852144\n",
      "#Test#  epoch: 30, dice: 0.8269209438789202\n",
      "#Train#  epoch: 31, loss: 0.6284488439559937, dice: 0.7811773637562938\n",
      "#Val#  epoch: 31, dice: 0.8041077922590665\n",
      "#Test#  epoch: 31, dice: 0.8270632566228542\n",
      "#Train#  epoch: 32, loss: 0.6249870657920837, dice: 0.7816067065509702\n",
      "#Val#  epoch: 32, dice: 0.8041732632234468\n",
      "#Test#  epoch: 32, dice: 0.8271886762748494\n",
      "#Train#  epoch: 33, loss: 0.6210417151451111, dice: 0.7818908699156456\n",
      "#Val#  epoch: 33, dice: 0.8039292179699039\n",
      "#Test#  epoch: 33, dice: 0.8269954630676534\n",
      "#Train#  epoch: 34, loss: 0.6170234084129333, dice: 0.7822367418520905\n",
      "#Val#  epoch: 34, dice: 0.8035218362608962\n",
      "#Test#  epoch: 34, dice: 0.8272210475853162\n",
      "#Train#  epoch: 35, loss: 0.6127878427505493, dice: 0.7826177624138788\n",
      "#Val#  epoch: 35, dice: 0.8036346430198732\n",
      "#Test#  epoch: 35, dice: 0.8271521448992225\n",
      "#Train#  epoch: 36, loss: 0.6087138056755066, dice: 0.7829913866054563\n",
      "#Val#  epoch: 36, dice: 0.8036547280635284\n",
      "#Test#  epoch: 36, dice: 0.8270465231112734\n",
      "#Train#  epoch: 37, loss: 0.6044373512268066, dice: 0.7834200826000981\n",
      "#Val#  epoch: 37, dice: 0.8034066776135742\n",
      "#Test#  epoch: 37, dice: 0.8267283875537494\n",
      "#Train#  epoch: 38, loss: 0.5998009443283081, dice: 0.7836842541606382\n",
      "#Val#  epoch: 38, dice: 0.8033637737336574\n",
      "#Test#  epoch: 38, dice: 0.8263108949137993\n",
      "#Train#  epoch: 39, loss: 0.5952908396720886, dice: 0.7841542952895377\n",
      "#Val#  epoch: 39, dice: 0.8034816281473953\n",
      "#Test#  epoch: 39, dice: 0.8261850692892266\n",
      "#Train#  epoch: 40, loss: 0.591038703918457, dice: 0.7845854057806066\n",
      "#Val#  epoch: 40, dice: 0.8033978242002927\n",
      "#Test#  epoch: 40, dice: 0.8260101551884431\n",
      "#Train#  epoch: 41, loss: 0.5891126990318298, dice: 0.7847712545056945\n",
      "#Val#  epoch: 41, dice: 0.8035408162817922\n",
      "#Test#  epoch: 41, dice: 0.8257209475310407\n",
      "#Train#  epoch: 42, loss: 0.5866197943687439, dice: 0.7849337239008601\n",
      "#Val#  epoch: 42, dice: 0.8038502861402855\n",
      "#Test#  epoch: 42, dice: 0.8259224828375287\n",
      "#Train#  epoch: 43, loss: 0.5846632122993469, dice: 0.7851406589408579\n",
      "#Val#  epoch: 43, dice: 0.8043897023655424\n",
      "#Test#  epoch: 43, dice: 0.8259416409592817\n",
      "#Train#  epoch: 44, loss: 0.5818585753440857, dice: 0.7854001241358646\n",
      "#Val#  epoch: 44, dice: 0.8049686169512356\n",
      "#Test#  epoch: 44, dice: 0.8259815663589627\n",
      "#Train#  epoch: 45, loss: 0.5793758630752563, dice: 0.7855904542779176\n",
      "#Val#  epoch: 45, dice: 0.8054268841518298\n",
      "#Test#  epoch: 45, dice: 0.8260159463641791\n",
      "#Train#  epoch: 46, loss: 0.5769502520561218, dice: 0.7857297655963634\n",
      "#Val#  epoch: 46, dice: 0.805532139093783\n",
      "#Test#  epoch: 46, dice: 0.8260081833937856\n",
      "#Train#  epoch: 47, loss: 0.574713408946991, dice: 0.7859542287013094\n",
      "#Val#  epoch: 47, dice: 0.8057542583883334\n",
      "#Test#  epoch: 47, dice: 0.8262538327937046\n",
      "#Train#  epoch: 48, loss: 0.5721026062965393, dice: 0.7861475846309045\n",
      "#Val#  epoch: 48, dice: 0.8058264368421977\n",
      "#Test#  epoch: 48, dice: 0.8262389045325254\n",
      "#Train#  epoch: 49, loss: 0.5691623687744141, dice: 0.7863579740609365\n",
      "#Val#  epoch: 49, dice: 0.8058949069479452\n",
      "#Test#  epoch: 49, dice: 0.8263344661599321\n",
      "#Train#  epoch: 50, loss: 0.5669540762901306, dice: 0.7865611114604645\n",
      "#Val#  epoch: 50, dice: 0.8059759188568266\n",
      "#Test#  epoch: 50, dice: 0.8265859602232529\n",
      "#Train#  epoch: 51, loss: 0.5648142695426941, dice: 0.7867328889376516\n",
      "#Val#  epoch: 51, dice: 0.8060119853083317\n",
      "#Test#  epoch: 51, dice: 0.8266871549305841\n",
      "#Train#  epoch: 52, loss: 0.562193751335144, dice: 0.7869593026834483\n",
      "#Val#  epoch: 52, dice: 0.8061767510535544\n",
      "#Test#  epoch: 52, dice: 0.8266586606335488\n",
      "#Train#  epoch: 53, loss: 0.5598762631416321, dice: 0.7871237972887979\n",
      "#Val#  epoch: 53, dice: 0.8062709375631973\n",
      "#Test#  epoch: 53, dice: 0.8267938822184105\n",
      "#Train#  epoch: 54, loss: 0.5575991868972778, dice: 0.7872997266125245\n",
      "#Val#  epoch: 54, dice: 0.806177626546385\n",
      "#Test#  epoch: 54, dice: 0.8270517662106589\n",
      "#Train#  epoch: 55, loss: 0.5554056167602539, dice: 0.7875876079499907\n",
      "#Val#  epoch: 55, dice: 0.8063680541812345\n",
      "#Test#  epoch: 55, dice: 0.8270385545525665\n",
      "#Train#  epoch: 56, loss: 0.5531578063964844, dice: 0.7877822628135808\n",
      "#Val#  epoch: 56, dice: 0.8063801155703317\n",
      "#Test#  epoch: 56, dice: 0.8270459684304151\n",
      "#Train#  epoch: 57, loss: 0.5507470369338989, dice: 0.7879375166467463\n",
      "#Val#  epoch: 57, dice: 0.8064865150155698\n",
      "#Test#  epoch: 57, dice: 0.8271466521937842\n",
      "#Train#  epoch: 58, loss: 0.5484503507614136, dice: 0.7881391096702691\n",
      "#Val#  epoch: 58, dice: 0.8065940639349743\n",
      "#Test#  epoch: 58, dice: 0.8273315525590298\n",
      "#Train#  epoch: 59, loss: 0.5462731719017029, dice: 0.7883138005582067\n",
      "#Val#  epoch: 59, dice: 0.8064560119301609\n",
      "#Test#  epoch: 59, dice: 0.8273355091663513\n",
      "#Train#  epoch: 60, loss: 0.5447648167610168, dice: 0.7885074151322783\n",
      "#Val#  epoch: 60, dice: 0.8063234847785066\n",
      "#Test#  epoch: 60, dice: 0.8272729869462138\n",
      "#Train#  epoch: 61, loss: 0.5423766374588013, dice: 0.7887049398483961\n",
      "#Val#  epoch: 61, dice: 0.8064006617126214\n",
      "#Test#  epoch: 61, dice: 0.8273114164119848\n",
      "#Train#  epoch: 62, loss: 0.5409252047538757, dice: 0.7888336970638248\n",
      "#Val#  epoch: 62, dice: 0.8064057847350202\n",
      "#Test#  epoch: 62, dice: 0.8274923953558118\n",
      "#Train#  epoch: 63, loss: 0.5388407707214355, dice: 0.789057353563376\n",
      "#Val#  epoch: 63, dice: 0.8063556861572029\n",
      "#Test#  epoch: 63, dice: 0.8273639121898981\n",
      "#Train#  epoch: 64, loss: 0.5373101830482483, dice: 0.7892248299725091\n",
      "#Val#  epoch: 64, dice: 0.806256790579624\n",
      "#Test#  epoch: 64, dice: 0.8274749436052655\n",
      "#Train#  epoch: 65, loss: 0.535660445690155, dice: 0.7894160339586764\n",
      "#Val#  epoch: 65, dice: 0.8062234421599935\n",
      "#Test#  epoch: 65, dice: 0.8275556824671617\n",
      "#Train#  epoch: 66, loss: 0.5344845056533813, dice: 0.7897150203556889\n",
      "#Val#  epoch: 66, dice: 0.8062306721154988\n",
      "#Test#  epoch: 66, dice: 0.8274523377091414\n",
      "#Train#  epoch: 67, loss: 0.5329082608222961, dice: 0.7898080641964463\n",
      "#Val#  epoch: 67, dice: 0.8061933009977705\n",
      "#Test#  epoch: 67, dice: 0.8275355183068239\n",
      "#Train#  epoch: 68, loss: 0.5308460593223572, dice: 0.7900503722672609\n",
      "#Val#  epoch: 68, dice: 0.8062940046000061\n",
      "#Test#  epoch: 68, dice: 0.8275876831526335\n",
      "#Train#  epoch: 69, loss: 0.5294973850250244, dice: 0.7902613997396181\n",
      "#Val#  epoch: 69, dice: 0.8062997111313364\n",
      "#Test#  epoch: 69, dice: 0.8276388651024719\n",
      "#Train#  epoch: 70, loss: 0.5284475684165955, dice: 0.7903893574644149\n",
      "#Val#  epoch: 70, dice: 0.8063638082590551\n",
      "#Test#  epoch: 70, dice: 0.8277764297846224\n",
      "#Train#  epoch: 71, loss: 0.5268217325210571, dice: 0.7906450921560222\n",
      "#Val#  epoch: 71, dice: 0.8063363412200621\n",
      "#Test#  epoch: 71, dice: 0.8278430617093687\n",
      "#Train#  epoch: 72, loss: 0.5255479216575623, dice: 0.7908402263822377\n",
      "#Val#  epoch: 72, dice: 0.8062436554915429\n",
      "#Test#  epoch: 72, dice: 0.8278882955765534\n",
      "#Train#  epoch: 73, loss: 0.5238409042358398, dice: 0.7909821735967753\n",
      "#Val#  epoch: 73, dice: 0.8062221245743162\n",
      "#Test#  epoch: 73, dice: 0.8279199820248442\n",
      "#Train#  epoch: 74, loss: 0.5220478177070618, dice: 0.7911992808521527\n",
      "#Val#  epoch: 74, dice: 0.8062282520825278\n",
      "#Test#  epoch: 74, dice: 0.8279873193380096\n",
      "#Train#  epoch: 75, loss: 0.521376371383667, dice: 0.7913357555491248\n",
      "#Val#  epoch: 75, dice: 0.8061068031544494\n",
      "#Test#  epoch: 75, dice: 0.8281116308253951\n",
      "#Train#  epoch: 76, loss: 0.5200884342193604, dice: 0.7915868392635603\n",
      "#Val#  epoch: 76, dice: 0.8062390737145416\n",
      "#Test#  epoch: 76, dice: 0.828141599229974\n",
      "#Train#  epoch: 77, loss: 0.5189313888549805, dice: 0.7916992144320476\n",
      "#Val#  epoch: 77, dice: 0.8062610101436095\n",
      "#Test#  epoch: 77, dice: 0.8283621196727448\n",
      "#Train#  epoch: 78, loss: 0.5180667638778687, dice: 0.7918444785962448\n",
      "#Val#  epoch: 78, dice: 0.8065209082881957\n",
      "#Test#  epoch: 78, dice: 0.8282239206068557\n",
      "#Train#  epoch: 79, loss: 0.5162450075149536, dice: 0.7920220285272107\n",
      "#Val#  epoch: 79, dice: 0.8066048305952345\n",
      "#Test#  epoch: 79, dice: 0.8282641782479603\n",
      "#Train#  epoch: 80, loss: 0.5154610276222229, dice: 0.7921458069253466\n",
      "#Val#  epoch: 80, dice: 0.8065074359402314\n",
      "#Test#  epoch: 80, dice: 0.8284980168134308\n",
      "#Train#  epoch: 81, loss: 0.514641284942627, dice: 0.7923782469163926\n",
      "#Val#  epoch: 81, dice: 0.8064268311420356\n",
      "#Test#  epoch: 81, dice: 0.8284161573686367\n",
      "#Train#  epoch: 82, loss: 0.5143041014671326, dice: 0.792400799154215\n",
      "#Val#  epoch: 82, dice: 0.806476666886066\n",
      "#Test#  epoch: 82, dice: 0.8285142221968878\n",
      "#Train#  epoch: 83, loss: 0.5136050581932068, dice: 0.7925258992545464\n",
      "#Val#  epoch: 83, dice: 0.8065007127974559\n",
      "#Test#  epoch: 83, dice: 0.828500290303162\n",
      "#Train#  epoch: 84, loss: 0.5129014253616333, dice: 0.7925653945111493\n",
      "#Val#  epoch: 84, dice: 0.8065523715935212\n",
      "#Test#  epoch: 84, dice: 0.8284685441962679\n",
      "#Train#  epoch: 85, loss: 0.5126876831054688, dice: 0.792710364280785\n",
      "#Val#  epoch: 85, dice: 0.8064899575845568\n",
      "#Test#  epoch: 85, dice: 0.8285080330653863\n",
      "#Train#  epoch: 86, loss: 0.512061357498169, dice: 0.7928212591070929\n",
      "#Val#  epoch: 86, dice: 0.8064579779793825\n",
      "#Test#  epoch: 86, dice: 0.8284727169112408\n",
      "#Train#  epoch: 87, loss: 0.5116925239562988, dice: 0.7928921765699124\n",
      "#Val#  epoch: 87, dice: 0.8065098823240561\n",
      "#Test#  epoch: 87, dice: 0.8284821692558145\n",
      "#Train#  epoch: 88, loss: 0.5113281011581421, dice: 0.7929938823781668\n",
      "#Val#  epoch: 88, dice: 0.8065025252525253\n",
      "#Test#  epoch: 88, dice: 0.8285032414333547\n",
      "#Train#  epoch: 89, loss: 0.510262131690979, dice: 0.7931368134401166\n",
      "#Val#  epoch: 89, dice: 0.806410464346614\n",
      "#Test#  epoch: 89, dice: 0.828468037212748\n",
      "#Train#  epoch: 90, loss: 0.5099228024482727, dice: 0.7932327048408085\n",
      "#Val#  epoch: 90, dice: 0.8063834451313078\n",
      "#Test#  epoch: 90, dice: 0.8284322980304427\n",
      "#Train#  epoch: 91, loss: 0.5093100666999817, dice: 0.7933266952292759\n",
      "#Val#  epoch: 91, dice: 0.8063814866760168\n",
      "#Test#  epoch: 91, dice: 0.8282181268903702\n",
      "#Train#  epoch: 92, loss: 0.5092670321464539, dice: 0.7933909771211698\n",
      "#Val#  epoch: 92, dice: 0.80638995563505\n",
      "#Test#  epoch: 92, dice: 0.8283266541989491\n",
      "#Train#  epoch: 93, loss: 0.5084826350212097, dice: 0.7934522285823036\n",
      "#Val#  epoch: 93, dice: 0.8063769538955177\n",
      "#Test#  epoch: 93, dice: 0.8283956642076279\n",
      "#Train#  epoch: 94, loss: 0.5077880620956421, dice: 0.7936230524375943\n",
      "#Val#  epoch: 94, dice: 0.8061958422637441\n",
      "#Test#  epoch: 94, dice: 0.8283398156458806\n",
      "#Train#  epoch: 95, loss: 0.5075926184654236, dice: 0.793699128423214\n",
      "#Val#  epoch: 95, dice: 0.8063059904279377\n",
      "#Test#  epoch: 95, dice: 0.8282728257152628\n",
      "#Train#  epoch: 96, loss: 0.5069908499717712, dice: 0.7937244494484431\n",
      "#Val#  epoch: 96, dice: 0.8061777076761305\n",
      "#Test#  epoch: 96, dice: 0.828320677029164\n",
      "#Train#  epoch: 97, loss: 0.5064065456390381, dice: 0.7938604309546435\n",
      "#Val#  epoch: 97, dice: 0.8063037399970201\n",
      "#Test#  epoch: 97, dice: 0.8282990909868065\n",
      "#Train#  epoch: 98, loss: 0.5060257315635681, dice: 0.7939304340133738\n",
      "#Val#  epoch: 98, dice: 0.8062027052488135\n",
      "#Test#  epoch: 98, dice: 0.8282162701239493\n",
      "#Train#  epoch: 99, loss: 0.5058234930038452, dice: 0.7940549683555332\n",
      "#Val#  epoch: 99, dice: 0.8061823233230646\n",
      "#Test#  epoch: 99, dice: 0.8282061967296027\n",
      "#Train#  epoch: 100, loss: 0.5050686001777649, dice: 0.7940536251387273\n",
      "#Val#  epoch: 100, dice: 0.8059175796976376\n",
      "#Test#  epoch: 100, dice: 0.828434358004509\n",
      "#Train#  epoch: 101, loss: 0.5047468543052673, dice: 0.7941804047714783\n",
      "#Val#  epoch: 101, dice: 0.8062255990956054\n",
      "#Test#  epoch: 101, dice: 0.8281997314786127\n",
      "#Train#  epoch: 102, loss: 0.5042555928230286, dice: 0.7943251383663058\n",
      "#Val#  epoch: 102, dice: 0.8061342972943367\n",
      "#Test#  epoch: 102, dice: 0.8282184335834689\n",
      "#Train#  epoch: 103, loss: 0.5039843916893005, dice: 0.794314414893831\n",
      "#Val#  epoch: 103, dice: 0.8059969594609396\n",
      "#Test#  epoch: 103, dice: 0.8283093053735254\n",
      "#Train#  epoch: 104, loss: 0.5032098889350891, dice: 0.7944344655639259\n",
      "#Val#  epoch: 104, dice: 0.8060471717950515\n",
      "#Test#  epoch: 104, dice: 0.8282392322347453\n",
      "#Train#  epoch: 105, loss: 0.5027828216552734, dice: 0.7945099342897204\n",
      "#Val#  epoch: 105, dice: 0.8064005888822192\n",
      "#Test#  epoch: 105, dice: 0.8283048433048432\n",
      "#Train#  epoch: 106, loss: 0.5022377371788025, dice: 0.7946296201968316\n",
      "#Val#  epoch: 106, dice: 0.8062253263169886\n",
      "#Test#  epoch: 106, dice: 0.8283994586509011\n",
      "#Train#  epoch: 107, loss: 0.5020086169242859, dice: 0.7947926747861335\n",
      "#Val#  epoch: 107, dice: 0.8062234918854498\n",
      "#Test#  epoch: 107, dice: 0.8283220381838967\n",
      "#Train#  epoch: 108, loss: 0.5017852783203125, dice: 0.7947354733542993\n",
      "#Val#  epoch: 108, dice: 0.8061308994351967\n",
      "#Test#  epoch: 108, dice: 0.8284013133061272\n",
      "#Train#  epoch: 109, loss: 0.501076340675354, dice: 0.7948347417638986\n",
      "#Val#  epoch: 109, dice: 0.8061665710167658\n",
      "#Test#  epoch: 109, dice: 0.8283767854789945\n",
      "#Train#  epoch: 110, loss: 0.5007065534591675, dice: 0.794975972332996\n",
      "#Val#  epoch: 110, dice: 0.8061667060957338\n",
      "#Test#  epoch: 110, dice: 0.8283275709204075\n",
      "#Train#  epoch: 111, loss: 0.5000399947166443, dice: 0.7950875932370621\n",
      "#Val#  epoch: 111, dice: 0.8063203360799723\n",
      "#Test#  epoch: 111, dice: 0.8283496528395942\n",
      "#Train#  epoch: 112, loss: 0.4996505379676819, dice: 0.7951928361730364\n",
      "#Val#  epoch: 112, dice: 0.8061917714616103\n",
      "#Test#  epoch: 112, dice: 0.8283869038294479\n",
      "#Train#  epoch: 113, loss: 0.49913787841796875, dice: 0.7952775960620717\n",
      "#Val#  epoch: 113, dice: 0.8061318792019797\n",
      "#Test#  epoch: 113, dice: 0.8284480395333188\n",
      "#Train#  epoch: 114, loss: 0.4986625611782074, dice: 0.7953782858797491\n",
      "#Val#  epoch: 114, dice: 0.80608884529148\n",
      "#Test#  epoch: 114, dice: 0.82853562503115\n",
      "#Train#  epoch: 115, loss: 0.4981773793697357, dice: 0.7953933063255573\n",
      "#Val#  epoch: 115, dice: 0.8061003323393802\n",
      "#Test#  epoch: 115, dice: 0.8285134557881249\n",
      "#Train#  epoch: 116, loss: 0.49777671694755554, dice: 0.7954736791304488\n",
      "#Val#  epoch: 116, dice: 0.8060885786601973\n",
      "#Test#  epoch: 116, dice: 0.8285388859227621\n",
      "#Train#  epoch: 117, loss: 0.4974556565284729, dice: 0.7955646004601102\n",
      "#Val#  epoch: 117, dice: 0.8060330292586153\n",
      "#Test#  epoch: 117, dice: 0.8284738957252848\n",
      "#Train#  epoch: 118, loss: 0.4971773624420166, dice: 0.7955336710740987\n",
      "#Val#  epoch: 118, dice: 0.8061624429058774\n",
      "#Test#  epoch: 118, dice: 0.8284328206807448\n",
      "#Train#  epoch: 119, loss: 0.4966420829296112, dice: 0.7957506482084779\n",
      "#Val#  epoch: 119, dice: 0.806137327967842\n",
      "#Test#  epoch: 119, dice: 0.8284949528026538\n",
      "#Train#  epoch: 120, loss: 0.49588915705680847, dice: 0.7958226083226083\n",
      "#Val#  epoch: 120, dice: 0.8062288434337462\n",
      "#Test#  epoch: 120, dice: 0.8284206067552512\n",
      "#Train#  epoch: 121, loss: 0.495632141828537, dice: 0.7958392432452722\n",
      "#Val#  epoch: 121, dice: 0.8060242546298323\n",
      "#Test#  epoch: 121, dice: 0.8284750250923612\n",
      "#Train#  epoch: 122, loss: 0.49556684494018555, dice: 0.7958466282343477\n",
      "#Val#  epoch: 122, dice: 0.806119142899675\n",
      "#Test#  epoch: 122, dice: 0.8286415886686359\n",
      "#Train#  epoch: 123, loss: 0.49519792199134827, dice: 0.7959303510333657\n",
      "#Val#  epoch: 123, dice: 0.8059169628942161\n",
      "#Test#  epoch: 123, dice: 0.8285273061102493\n",
      "#Train#  epoch: 124, loss: 0.494973748922348, dice: 0.7959408856956308\n",
      "#Val#  epoch: 124, dice: 0.8060463324519777\n",
      "#Test#  epoch: 124, dice: 0.8285232343793371\n",
      "#Train#  epoch: 125, loss: 0.49469518661499023, dice: 0.7960349210094488\n",
      "#Val#  epoch: 125, dice: 0.8061648933841237\n",
      "#Test#  epoch: 125, dice: 0.8284608158501523\n",
      "#Train#  epoch: 126, loss: 0.49457356333732605, dice: 0.7960541310159354\n",
      "#Val#  epoch: 126, dice: 0.8060344450184309\n",
      "#Test#  epoch: 126, dice: 0.8284333610891673\n",
      "#Train#  epoch: 127, loss: 0.4944450557231903, dice: 0.7960289583054029\n",
      "#Val#  epoch: 127, dice: 0.805991971598545\n",
      "#Test#  epoch: 127, dice: 0.8285545521182491\n",
      "#Train#  epoch: 128, loss: 0.49415016174316406, dice: 0.79603851016449\n",
      "#Val#  epoch: 128, dice: 0.8061051589994614\n",
      "#Test#  epoch: 128, dice: 0.828529941419735\n",
      "#Train#  epoch: 129, loss: 0.49397921562194824, dice: 0.7961795053306734\n",
      "#Val#  epoch: 129, dice: 0.8059949822891445\n",
      "#Test#  epoch: 129, dice: 0.8285592285521117\n",
      "#Train#  epoch: 130, loss: 0.4937637746334076, dice: 0.796161725587781\n",
      "#Val#  epoch: 130, dice: 0.8060126152862952\n",
      "#Test#  epoch: 130, dice: 0.8285318845375204\n",
      "#Train#  epoch: 131, loss: 0.493732750415802, dice: 0.796236487781858\n",
      "#Val#  epoch: 131, dice: 0.8060445020333655\n",
      "#Test#  epoch: 131, dice: 0.8285447907251493\n",
      "#Train#  epoch: 132, loss: 0.4934036433696747, dice: 0.7962062432879226\n",
      "#Val#  epoch: 132, dice: 0.8060012520849842\n",
      "#Test#  epoch: 132, dice: 0.8284392569923849\n",
      "#Train#  epoch: 133, loss: 0.49326297640800476, dice: 0.7962633511594578\n",
      "#Val#  epoch: 133, dice: 0.80589005178308\n",
      "#Test#  epoch: 133, dice: 0.8286173816504881\n",
      "#Train#  epoch: 134, loss: 0.4928697645664215, dice: 0.7963939951760837\n",
      "#Val#  epoch: 134, dice: 0.8062132249929952\n",
      "#Test#  epoch: 134, dice: 0.8285776302258471\n",
      "#Train#  epoch: 135, loss: 0.492584228515625, dice: 0.7963698378520424\n",
      "#Val#  epoch: 135, dice: 0.805962308753037\n",
      "#Test#  epoch: 135, dice: 0.8284931506849315\n",
      "#Train#  epoch: 136, loss: 0.4922545552253723, dice: 0.7963933525062178\n",
      "#Val#  epoch: 136, dice: 0.8060119696511988\n",
      "#Test#  epoch: 136, dice: 0.8284643874947967\n",
      "#Train#  epoch: 137, loss: 0.4922010600566864, dice: 0.7965151590313987\n",
      "#Val#  epoch: 137, dice: 0.8059434895673722\n",
      "#Test#  epoch: 137, dice: 0.8285390004305117\n",
      "#Train#  epoch: 138, loss: 0.49214258790016174, dice: 0.796523273367888\n",
      "#Val#  epoch: 138, dice: 0.8059538141621977\n",
      "#Test#  epoch: 138, dice: 0.8285488599812131\n",
      "#Train#  epoch: 139, loss: 0.49206238985061646, dice: 0.7965114096479232\n",
      "#Val#  epoch: 139, dice: 0.8060612428962969\n",
      "#Test#  epoch: 139, dice: 0.8285483463412378\n",
      "#Train#  epoch: 140, loss: 0.4915195405483246, dice: 0.7966168962114386\n",
      "#Val#  epoch: 140, dice: 0.806013273329014\n",
      "#Test#  epoch: 140, dice: 0.8284230866407365\n",
      "#Train#  epoch: 141, loss: 0.4914393424987793, dice: 0.7966635291719965\n",
      "#Val#  epoch: 141, dice: 0.8061522026566728\n",
      "#Test#  epoch: 141, dice: 0.8284486071769178\n",
      "#Train#  epoch: 142, loss: 0.49166354537010193, dice: 0.7967058678405118\n",
      "#Val#  epoch: 142, dice: 0.8060871126054541\n",
      "#Test#  epoch: 142, dice: 0.8283707425383225\n",
      "#Train#  epoch: 143, loss: 0.49156877398490906, dice: 0.7967287808554031\n",
      "#Val#  epoch: 143, dice: 0.8059966733782719\n",
      "#Test#  epoch: 143, dice: 0.8284908030475023\n",
      "#Train#  epoch: 144, loss: 0.4911681115627289, dice: 0.7968390299887241\n",
      "#Val#  epoch: 144, dice: 0.8059914470430143\n",
      "#Test#  epoch: 144, dice: 0.8283437110834371\n",
      "#Train#  epoch: 145, loss: 0.4909035861492157, dice: 0.7968377920322657\n",
      "#Val#  epoch: 145, dice: 0.8061357159429681\n",
      "#Test#  epoch: 145, dice: 0.8284916300499884\n",
      "#Train#  epoch: 146, loss: 0.49078255891799927, dice: 0.7968125246381709\n",
      "#Val#  epoch: 146, dice: 0.8060358790722921\n",
      "#Test#  epoch: 146, dice: 0.8284805306648257\n",
      "#Train#  epoch: 147, loss: 0.49029308557510376, dice: 0.7968951544779983\n",
      "#Val#  epoch: 147, dice: 0.8061005612026021\n",
      "#Test#  epoch: 147, dice: 0.8284753722183681\n",
      "#Train#  epoch: 148, loss: 0.4902210235595703, dice: 0.7968753352069166\n",
      "#Val#  epoch: 148, dice: 0.8060662046380898\n",
      "#Test#  epoch: 148, dice: 0.828511661662374\n",
      "#Train#  epoch: 149, loss: 0.48999905586242676, dice: 0.7970012121732228\n",
      "#Val#  epoch: 149, dice: 0.8060179733769901\n",
      "#Test#  epoch: 149, dice: 0.8283558461609611\n",
      "#Train#  epoch: 150, loss: 0.49014827609062195, dice: 0.7970237552495937\n",
      "#Val#  epoch: 150, dice: 0.8060429361910765\n",
      "#Test#  epoch: 150, dice: 0.8284223220670004\n",
      "#Train#  epoch: 151, loss: 0.4897804260253906, dice: 0.7970132083339478\n",
      "#Val#  epoch: 151, dice: 0.8060012429645581\n",
      "#Test#  epoch: 151, dice: 0.8286310906523139\n",
      "#Train#  epoch: 152, loss: 0.48940593004226685, dice: 0.7970577863945414\n",
      "#Val#  epoch: 152, dice: 0.8060862140683495\n",
      "#Test#  epoch: 152, dice: 0.8285823043291105\n",
      "#Train#  epoch: 153, loss: 0.4891505241394043, dice: 0.7971097855132625\n",
      "#Val#  epoch: 153, dice: 0.8060326146437561\n",
      "#Test#  epoch: 153, dice: 0.8285530281196518\n",
      "#Train#  epoch: 154, loss: 0.48909926414489746, dice: 0.7971897269503309\n",
      "#Val#  epoch: 154, dice: 0.8060154984457774\n",
      "#Test#  epoch: 154, dice: 0.8285392051175318\n",
      "#Train#  epoch: 155, loss: 0.48890456557273865, dice: 0.797288401022749\n",
      "#Val#  epoch: 155, dice: 0.8058515062113161\n",
      "#Test#  epoch: 155, dice: 0.8285647196112056\n",
      "#Train#  epoch: 156, loss: 0.4887106120586395, dice: 0.7972303826593209\n",
      "#Val#  epoch: 156, dice: 0.8060584836280862\n",
      "#Test#  epoch: 156, dice: 0.8284854349589447\n",
      "#Train#  epoch: 157, loss: 0.4882696568965912, dice: 0.7973107062212044\n",
      "#Val#  epoch: 157, dice: 0.8059509428016178\n",
      "#Test#  epoch: 157, dice: 0.8285440851569477\n",
      "#Train#  epoch: 158, loss: 0.4882834553718567, dice: 0.7973590137600532\n",
      "#Val#  epoch: 158, dice: 0.8060559903356269\n",
      "#Test#  epoch: 158, dice: 0.8285472372034779\n",
      "#Train#  epoch: 159, loss: 0.4878581166267395, dice: 0.797445287284498\n",
      "#Val#  epoch: 159, dice: 0.8059830817772449\n",
      "#Test#  epoch: 159, dice: 0.8285878937932212\n",
      "#Train#  epoch: 160, loss: 0.4878081977367401, dice: 0.7975016392475418\n",
      "#Val#  epoch: 160, dice: 0.8060271071023758\n",
      "#Test#  epoch: 160, dice: 0.8285859631522964\n",
      "#Train#  epoch: 161, loss: 0.4876047670841217, dice: 0.797560671458971\n",
      "#Val#  epoch: 161, dice: 0.8059888311188137\n",
      "#Test#  epoch: 161, dice: 0.8285263992998609\n",
      "#Train#  epoch: 162, loss: 0.48749256134033203, dice: 0.7975176634497666\n",
      "#Val#  epoch: 162, dice: 0.8059587839109333\n",
      "#Test#  epoch: 162, dice: 0.8285703104710607\n",
      "#Train#  epoch: 163, loss: 0.48743781447410583, dice: 0.7975505366078659\n",
      "#Val#  epoch: 163, dice: 0.8060491758085478\n",
      "#Test#  epoch: 163, dice: 0.8286389151732039\n",
      "#Train#  epoch: 164, loss: 0.48741307854652405, dice: 0.7975000938604537\n",
      "#Val#  epoch: 164, dice: 0.8060371611864273\n",
      "#Test#  epoch: 164, dice: 0.8285365601995325\n",
      "#Train#  epoch: 165, loss: 0.48699328303337097, dice: 0.7975949915323213\n",
      "#Val#  epoch: 165, dice: 0.8060077722928264\n",
      "#Test#  epoch: 165, dice: 0.8286158432254186\n",
      "#Train#  epoch: 166, loss: 0.4869973659515381, dice: 0.7975627449692058\n",
      "#Val#  epoch: 166, dice: 0.8059850417718805\n",
      "#Test#  epoch: 166, dice: 0.8285870833689124\n",
      "#Train#  epoch: 167, loss: 0.4868951737880707, dice: 0.7975102276704243\n",
      "#Val#  epoch: 167, dice: 0.8060954314898533\n",
      "#Test#  epoch: 167, dice: 0.8285845408393784\n",
      "#Train#  epoch: 168, loss: 0.4868716299533844, dice: 0.7975863224941333\n",
      "#Val#  epoch: 168, dice: 0.8059138396628167\n",
      "#Test#  epoch: 168, dice: 0.8285933842311605\n",
      "#Train#  epoch: 169, loss: 0.4867915213108063, dice: 0.7976110981493251\n",
      "#Val#  epoch: 169, dice: 0.8059445455818512\n",
      "#Test#  epoch: 169, dice: 0.8285412359946345\n",
      "#Train#  epoch: 170, loss: 0.48642483353614807, dice: 0.797651229899484\n",
      "#Val#  epoch: 170, dice: 0.8059043109522079\n",
      "#Test#  epoch: 170, dice: 0.8285565880662009\n",
      "#Train#  epoch: 171, loss: 0.4862993359565735, dice: 0.7976646548406519\n",
      "#Val#  epoch: 171, dice: 0.8059483328300532\n",
      "#Test#  epoch: 171, dice: 0.8287138328868587\n",
      "#Train#  epoch: 172, loss: 0.48626765608787537, dice: 0.7976753510238728\n",
      "#Val#  epoch: 172, dice: 0.8059881759343944\n",
      "#Test#  epoch: 172, dice: 0.8287274732703562\n",
      "#Train#  epoch: 173, loss: 0.4861252009868622, dice: 0.7976849933556198\n",
      "#Val#  epoch: 173, dice: 0.8059068037628528\n",
      "#Test#  epoch: 173, dice: 0.8286624090512871\n",
      "#Train#  epoch: 174, loss: 0.48622170090675354, dice: 0.797790188598285\n",
      "#Val#  epoch: 174, dice: 0.8060216183099208\n",
      "#Test#  epoch: 174, dice: 0.8286247932120177\n",
      "#Train#  epoch: 175, loss: 0.48590055108070374, dice: 0.7977756501543422\n",
      "#Val#  epoch: 175, dice: 0.805850772912829\n",
      "#Test#  epoch: 175, dice: 0.8286926855992287\n",
      "#Train#  epoch: 176, loss: 0.4860343933105469, dice: 0.797820787530807\n",
      "#Val#  epoch: 176, dice: 0.805878054010529\n",
      "#Test#  epoch: 176, dice: 0.8285900267844757\n",
      "#Train#  epoch: 177, loss: 0.48568859696388245, dice: 0.7978368781963437\n",
      "#Val#  epoch: 177, dice: 0.8059269113457642\n",
      "#Test#  epoch: 177, dice: 0.8287064046558619\n",
      "#Train#  epoch: 178, loss: 0.4855650067329407, dice: 0.7978679610869375\n",
      "#Val#  epoch: 178, dice: 0.8058872170911303\n",
      "#Test#  epoch: 178, dice: 0.8286176664117657\n",
      "#Train#  epoch: 179, loss: 0.4854399263858795, dice: 0.7978502582586449\n",
      "#Val#  epoch: 179, dice: 0.8058715435771789\n",
      "#Test#  epoch: 179, dice: 0.8286926855992287\n",
      "#Train#  epoch: 180, loss: 0.4856085777282715, dice: 0.7978916119031942\n",
      "#Val#  epoch: 180, dice: 0.8058650051194092\n",
      "#Test#  epoch: 180, dice: 0.8286966232990234\n",
      "#Train#  epoch: 181, loss: 0.48526760935783386, dice: 0.7978206706412743\n",
      "#Val#  epoch: 181, dice: 0.8059632264783358\n",
      "#Test#  epoch: 181, dice: 0.8287364744214503\n",
      "#Train#  epoch: 182, loss: 0.4852345585823059, dice: 0.79786798967517\n",
      "#Val#  epoch: 182, dice: 0.8059731531878401\n",
      "#Test#  epoch: 182, dice: 0.82871014209244\n",
      "#Train#  epoch: 183, loss: 0.4854510724544525, dice: 0.7979140238849362\n",
      "#Val#  epoch: 183, dice: 0.8059158134243459\n",
      "#Test#  epoch: 183, dice: 0.8286258917584801\n",
      "#Train#  epoch: 184, loss: 0.4849644601345062, dice: 0.7979563923083113\n",
      "#Val#  epoch: 184, dice: 0.8059162017284761\n",
      "#Test#  epoch: 184, dice: 0.8286397336103483\n",
      "#Train#  epoch: 185, loss: 0.4847223460674286, dice: 0.7980074018450977\n",
      "#Val#  epoch: 185, dice: 0.8059137267942228\n",
      "#Test#  epoch: 185, dice: 0.8286184830667337\n",
      "#Train#  epoch: 186, loss: 0.4849204123020172, dice: 0.7980293452695436\n",
      "#Val#  epoch: 186, dice: 0.8059014499855613\n",
      "#Test#  epoch: 186, dice: 0.8286175600318653\n",
      "#Train#  epoch: 187, loss: 0.4849050045013428, dice: 0.7980175077239958\n",
      "#Val#  epoch: 187, dice: 0.8059807293444302\n",
      "#Test#  epoch: 187, dice: 0.828594702076271\n",
      "#Train#  epoch: 188, loss: 0.4847228527069092, dice: 0.7980458996344443\n",
      "#Val#  epoch: 188, dice: 0.8060021436227225\n",
      "#Test#  epoch: 188, dice: 0.8285865710555989\n",
      "#Train#  epoch: 189, loss: 0.484667032957077, dice: 0.7981060753359357\n",
      "#Val#  epoch: 189, dice: 0.8059675372971081\n",
      "#Test#  epoch: 189, dice: 0.8286212293682413\n",
      "#Train#  epoch: 190, loss: 0.4846244752407074, dice: 0.7980556356395283\n",
      "#Val#  epoch: 190, dice: 0.8060063265940085\n",
      "#Test#  epoch: 190, dice: 0.8286141149686965\n",
      "#Train#  epoch: 191, loss: 0.48457661271095276, dice: 0.7980974500359376\n",
      "#Val#  epoch: 191, dice: 0.806038198166663\n",
      "#Test#  epoch: 191, dice: 0.8285675662215138\n",
      "#Train#  epoch: 192, loss: 0.48438701033592224, dice: 0.7981247477246608\n",
      "#Val#  epoch: 192, dice: 0.8059521257279365\n",
      "#Test#  epoch: 192, dice: 0.828617571519028\n",
      "#Train#  epoch: 193, loss: 0.4841136038303375, dice: 0.7981279962452646\n",
      "#Val#  epoch: 193, dice: 0.805818404532231\n",
      "#Test#  epoch: 193, dice: 0.8285489649185845\n",
      "#Train#  epoch: 194, loss: 0.4841344356536865, dice: 0.798114624399925\n",
      "#Val#  epoch: 194, dice: 0.8059786389670396\n",
      "#Test#  epoch: 194, dice: 0.828738203897827\n",
      "#Train#  epoch: 195, loss: 0.4838894009590149, dice: 0.7981413810906312\n",
      "#Val#  epoch: 195, dice: 0.8060400276535604\n",
      "#Test#  epoch: 195, dice: 0.828616245940649\n",
      "#Train#  epoch: 196, loss: 0.4839644134044647, dice: 0.798204714568658\n",
      "#Val#  epoch: 196, dice: 0.8059261333555022\n",
      "#Test#  epoch: 196, dice: 0.8286408440433547\n",
      "#Train#  epoch: 197, loss: 0.4838937819004059, dice: 0.798217053847763\n",
      "#Val#  epoch: 197, dice: 0.806029183347553\n",
      "#Test#  epoch: 197, dice: 0.82861065856591\n",
      "#Train#  epoch: 198, loss: 0.48358240723609924, dice: 0.798250354340792\n",
      "#Val#  epoch: 198, dice: 0.8060293152483046\n",
      "#Test#  epoch: 198, dice: 0.8286125882583102\n",
      "#Train#  epoch: 199, loss: 0.48339325189590454, dice: 0.798240156192172\n",
      "#Val#  epoch: 199, dice: 0.8060493081628901\n",
      "#Test#  epoch: 199, dice: 0.8285438806841023\n",
      "#Train#  epoch: 200, loss: 0.48362278938293457, dice: 0.7982615412260399\n",
      "#Val#  epoch: 200, dice: 0.8060596248178568\n",
      "#Test#  epoch: 200, dice: 0.8286492676923952\n"
     ]
    }
   ],
   "source": [
    "print('#----------Start training----------#')\n",
    "torch.cuda.empty_cache()\n",
    "info = \"%d-resizeh, %d-resizew, %f-outer_lr\"%(config.resize_h,config.resize_w,config.outer_lr)\n",
    "print(info)\n",
    "logger.info(info)\n",
    "best_dice_val = 0.0\n",
    "best_dice_test = 0.0\n",
    "train_csv = os.path.join(csv_save,\"train.csv\")\n",
    "val_csv = os.path.join(csv_save,\"val.csv\")\n",
    "test_csv = os.path.join(csv_save,\"test.csv\")\n",
    "train_columns = ['Epoch','Loss',\"Mdice\"]\n",
    "train_df = pd.DataFrame(columns=train_columns)\n",
    "val_columns = ['Epoch','Mdice']\n",
    "val_df = pd.DataFrame(columns=val_columns)\n",
    "test_columns = ['Epoch','Mdice']\n",
    "test_df = pd.DataFrame(columns=test_columns)\n",
    "for epoch in range(start_epoch, config.epoch_num+1):\n",
    "    meta_scheduler.step()\n",
    "    # train part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    loss_list = []    \n",
    "    base_net.train()\n",
    "    meta_optimizer.zero_grad()\n",
    "    for category_index in range(num_categories):\n",
    "        for image,mask in train_loader_list[category_index]:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)     # torch.Size([bs,out_channels=1,512,512])\n",
    "            predicted = predicted.squeeze(1)    # torch.Size([bs,512,512])\n",
    "            loss = criterion(predicted,mask)\n",
    "            loss = loss/num_categories\n",
    "            loss.backward()\n",
    "            predicted = (predicted > threshold).long()\n",
    "            temp_predicted = predicted.cpu().detach().numpy()       # threshold alternative\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "    meta_optimizer.step()\n",
    "    loss_list.append(loss.cpu().detach().numpy())\n",
    "    \n",
    "    # train_dice,train_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "    train_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "    train_mloss = np.mean(loss_list)\n",
    "    log_train = f'epoch: {epoch}, loss: {train_mloss}, dice: {train_dice}'\n",
    "    print(\"#Train# \",log_train)\n",
    "    temp_result = pd.Series([epoch,train_mloss,train_dice],index=train_columns)\n",
    "    train_df = train_df.append(temp_result, ignore_index=True)\n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    \n",
    "    # validation part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in val_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "        # val_dice,val_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        val_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_val = f'epoch: {epoch}, dice: {val_dice}'\n",
    "        print(\"#Val# \",log_val)\n",
    "        temp_result = pd.Series([epoch,val_dice],index=val_columns)\n",
    "        val_df = val_df.append(temp_result, ignore_index=True)\n",
    "        val_df.to_csv(val_csv, index=False)\n",
    "        # logger.info(log_val)\n",
    "\n",
    "    if val_dice > best_dice_val:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_val.pth'))\n",
    "        best_dice_val = val_dice\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # test part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in test_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "        # test_dice,test_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        test_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_test = f'epoch: {epoch}, dice: {test_dice}'\n",
    "        print(\"#Test# \",log_test)\n",
    "        temp_result = pd.Series([epoch,test_dice],index=test_columns)\n",
    "        test_df = test_df.append(temp_result, ignore_index=True)\n",
    "        test_df.to_csv(test_csv, index=False)\n",
    "        logger.info(log_test)\n",
    "\n",
    "    if test_dice > best_dice_test:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_test.pth'))\n",
    "        best_dice_test = test_dice\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best dice in testset:0.8442455700733846\n"
     ]
    }
   ],
   "source": [
    "best_result_test = \"Best dice in testset:\" + str(best_dice_test)\n",
    "print(best_result_test)\n",
    "logger.info(best_result_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
