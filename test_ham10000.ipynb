{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import *\n",
    "from models.meta import Meta\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from models.basenet import *\n",
    "from utils import *\n",
    "from configs.config_setting_test import setting_config\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics as metrics\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.init as init\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = setting_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    support_images = batch['support_images'].squeeze(0)\n",
    "    support_masks = batch['support_masks'].squeeze(0)\n",
    "    query_images = batch['query_images'].squeeze(0)\n",
    "    query_masks = batch['query_masks'].squeeze(0)\n",
    "    return support_images, support_masks, query_images, query_masks\n",
    "\n",
    "# the function of copying the images\n",
    "def copy_file_to_folder(source_file, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    dest_path = os.path.join(dest_folder, os.path.basename(source_file))\n",
    "    shutil.copy(source_file, dest_path)\n",
    "\n",
    "# def evaluation_api(predicted_list,groudtruth_list):\n",
    "#     pre = np.array([item for sublist in predicted_list for item in sublist]).reshape(-1)\n",
    "#     gts = np.array([item for sublist in groudtruth_list for item in sublist]).reshape(-1)\n",
    "#     # confusion_matrix = metrics.confusion_matrix(gts,pre)\n",
    "#     # TN, FP, FN, TP = confusion[0,0], confusion[0,1], confusion[1,0], confusion[1,1] \n",
    "#     dice = metrics.f1_score(gts,pre)\n",
    "\n",
    "#     return dice\n",
    "\n",
    "def evaluation_api(predicted_list,groudtruth_list):\n",
    "    pre = np.array([item for sublist in predicted_list for item in sublist]).reshape(-1)\n",
    "    gts = np.array([item for sublist in groudtruth_list for item in sublist]).reshape(-1)\n",
    "    pre = torch.tensor(pre)\n",
    "    gts = torch.tensor(gts)\n",
    "    intersection = torch.sum(pre * gts)\n",
    "    union = torch.sum(pre + gts)\n",
    "    dice = (2 * intersection) / union\n",
    "    return dice\n",
    "\n",
    "def evaluation_epoch(predicted_list,groundtruth_list):\n",
    "    TP = [0]*config.num_classes\n",
    "    FP = [0]*config.num_classes\n",
    "    FN = [0]*config.num_classes\n",
    "    dice = [0.0]*config.num_classes\n",
    "    \n",
    "    for i in range(len(predicted_list)):\n",
    "        preds = np.array(predicted_list[i]).reshape(-1)\n",
    "        gts = np.array(groundtruth_list[i]).reshape(-1)\n",
    "        for j in range(len(preds)):\n",
    "            if preds[j] == gts[j]:\n",
    "                TP[gts[j]] += 1\n",
    "            else:\n",
    "                FP[preds[j]] += 1\n",
    "                FN[gts[j]] += 1        \n",
    "    \n",
    "    for i in range(config.num_classes):\n",
    "        dice[i] = (2 * TP[i])/(FP[i]+FN[i]+2*TP[i]+1)\n",
    "\n",
    "    mdice = (2*np.sum(TP))/(np.sum(FP)+np.sum(FN)+2*np.sum(TP)+1)    \n",
    "    return dice,mdice\n",
    "\n",
    "def evaluation_basenet(base_net,query_images,query_masks,criterion):\n",
    "    predicted = base_net(query_images)\n",
    "    loss = criterion(predicted,query_masks)\n",
    "    predicted = torch.argmax(predicted,dim=1).long()\n",
    "    predict_numpy = predicted.detach().cpu().numpy().reshape(-1)\n",
    "    masks_numpy = query_masks.long().detach().cpu().numpy().reshape(-1)\n",
    "    accuracy = metrics.accuracy_score(masks_numpy,predict_numpy)\n",
    "    f1_score = metrics.f1_score(masks_numpy,predict_numpy,average=None)\n",
    "    return accuracy,f1_score,loss\n",
    "\n",
    "def initialize_weights_he(model):\n",
    "    for param in model.parameters():\n",
    "        init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "def initialize_weights_xavier(model):\n",
    "    for param in model.parameters():\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "def initialize_weights_normal(model):\n",
    "    for param in model.parameters():\n",
    "        init.normal_(param, mean=0, std=1)\n",
    "\n",
    "def remove_exsits_folder(folderpath):\n",
    "    if os.path.exists(folderpath):\n",
    "        shutil.rmtree(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Creating logger----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Creating logger----------#')\n",
    "sys.path.append(config.work_dir + '/')\n",
    "log_dir = os.path.join(config.work_dir, 'log')\n",
    "checkpoint_dir = os.path.join(config.work_dir, 'checkpoints')\n",
    "resume_model = os.path.join(checkpoint_dir, 'latest.pth')\n",
    "outputs = os.path.join(config.work_dir, 'outputs')\n",
    "csv_save = os.path.join(config.work_dir, 'csv')\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "if not os.path.exists(csv_save):\n",
    "    os.makedirs(csv_save)\n",
    "\n",
    "global logger\n",
    "logger = get_logger('test', log_dir)\n",
    "global writer\n",
    "writer = SummaryWriter(config.work_dir + 'summary')\n",
    "\n",
    "log_config_info(config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Generating data----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Generating data----------#')\n",
    "images_resources_path = \"./data/HAM10000/origin/images/\"         # the resource folder of images\n",
    "masks_resources_path = \"./data/HAM10000/origin/masks/\"           # the resource folder of masks\n",
    "ratio = [0.6,0.2]     # the ratio point of train dataset and validation set and testset\n",
    "categories = config.categories\n",
    "categories_dictionary = {}\n",
    "category_id = 1\n",
    "# prepare the csv for groundtruth\n",
    "origin_groundtruth_csv = \"./data/HAM10000/origin/groundtruth/HAM10000_groundtruth.csv\"   # read the csv file\n",
    "origin_groundtruth = pd.read_csv(origin_groundtruth_csv)    # read the csv file of groundtruth\n",
    "\n",
    "# generating the folders for each category in train folder and test folder\n",
    "# create folders for each categories\n",
    "trainset_images_path = \"./data/HAM10000/train/images/\"     # the images path for train dataset\n",
    "trainset_masks_path = \"./data/HAM10000/train/masks/\"     # the masks path for train dataset\n",
    "valset_images_path = \"./data/HAM10000/val/images/\"     # the images path for validation dataset\n",
    "valset_masks_path = \"./data/HAM10000/val/masks/\"      # the masks path for validation dataset\n",
    "testset_images_path = \"./data/HAM10000/test/images/\"     # the images path for test dataset\n",
    "testset_masks_path = \"./data/HAM10000/test/masks/\"      # the masks path for test dataset\n",
    "\n",
    "for category in categories:\n",
    "    # prepare the address for folders\n",
    "    category_images_train_path = os.path.join(trainset_images_path,category)\n",
    "    category_masks_train_path = os.path.join(trainset_masks_path,category)\n",
    "    category_images_val_path = os.path.join(valset_images_path,category)\n",
    "    category_masks_val_path = os.path.join(valset_masks_path,category)\n",
    "    category_images_test_path = os.path.join(testset_images_path,category)\n",
    "    category_masks_test_path = os.path.join(testset_masks_path,category)\n",
    "    #delete the previously exsited folders\n",
    "    remove_exsits_folder(category_images_train_path)\n",
    "    remove_exsits_folder(category_masks_train_path)\n",
    "    remove_exsits_folder(category_images_val_path)\n",
    "    remove_exsits_folder(category_masks_val_path)\n",
    "    remove_exsits_folder(category_images_test_path)\n",
    "    remove_exsits_folder(category_masks_test_path)\n",
    "    # create corresponding folder for each categories\n",
    "    os.makedirs(category_images_train_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_train_path, exist_ok=True)\n",
    "    os.makedirs(category_images_val_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_val_path, exist_ok=True)\n",
    "    os.makedirs(category_images_test_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_test_path, exist_ok=True)\n",
    "\n",
    "    # generate the data in trainset and testset for each categories\n",
    "    dest_folder_images = \"./data/HAM10000/train/images/\"+category    # the destination train set folder of copying the images\n",
    "    dest_folder_masks = \"./data/HAM10000/train/masks/\"+category    # the destination trian set folder of copying the masks\n",
    "    dest_folder_images_change_val = \"./data/HAM10000/val/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_val = \"./data/HAM10000/val/masks/\"+category      # the destination folder of test set masks\n",
    "    dest_folder_images_change_test = \"./data/HAM10000/test/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_test = \"./data/HAM10000/test/masks/\"+category      # the destination folder of test set masks\n",
    "    data_categories = origin_groundtruth[origin_groundtruth['dx'] == category]      # extract each categories \n",
    "    data_categories = data_categories.sample(frac=1,random_state=config.seed)       # random sample the datagenerating\n",
    "    length_categories = len(data_categories)\n",
    "    change_folder_point_valset = math.floor(length_categories * ratio[0])     # get the point to change directory name\n",
    "    change_folder_point_testset = math.floor(length_categories * (ratio[0]+ratio[1]))     # get the point to change directory name \n",
    "    elements_count = 0\n",
    "    for image_name in data_categories['image_id']:      # each image_id in each categories\n",
    "        if elements_count == change_folder_point_valset:\n",
    "            dest_folder_images = dest_folder_images_change_val\n",
    "            dest_folder_masks = dest_folder_masks_change_val\n",
    "        elif elements_count == change_folder_point_testset:\n",
    "            dest_folder_images = dest_folder_images_change_test\n",
    "            dest_folder_masks = dest_folder_masks_change_test\n",
    "        images_file = image_name+\".jpg\"\n",
    "        masks_file = image_name+\"_segmentation.png\"\n",
    "        source_image = images_resources_path+images_file    # the full path of source of image : path + image file name\n",
    "        source_mask = masks_resources_path+masks_file       # the full path of source of mask : path + mask file name\n",
    "        copy_file_to_folder(source_image,dest_folder_images)\n",
    "        # masks should be preprocess to the form of output for network (Width*Height*Category)\n",
    "        image = Image.open(source_mask)\n",
    "        image_array = np.array(image)\n",
    "        image_array[image_array == 255] = 1\n",
    "        image = Image.fromarray(image_array)\n",
    "        image.save(os.path.join(dest_folder_masks, masks_file))\n",
    "        elements_count +=1\n",
    "    categories_dictionary[category] = category_id       # add the category id in the categories_dictionary\n",
    "    category_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------GPU init----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------GPU init----------#')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu_id\n",
    "set_seed(config.seed)\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Datasets----------#\n",
      "trian_dataset_list length: 1\n",
      "trian_dataset(nv) length: 10\n",
      "val_dataset length: 1341\n",
      "test_dataset length: 1341\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Datasets----------#')\n",
    "# create the dataset and dataloader\n",
    "batch_size = config.batch_size\n",
    "categories = config.categories\n",
    "num_categories = len(categories)\n",
    "train_dataset_list = []\n",
    "train_loader_list = []\n",
    "for i in range(num_categories):\n",
    "    train_dataset = HAMALL_datasets(config, train=True,categories = [categories[i]],num_eachcat=config.num_eachcat)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "    train_dataset_list.append(train_dataset)\n",
    "    train_loader_list.append(train_loader)\n",
    "val_dataset = HAMALL_datasets(config, train=False,val=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "test_dataset = HAMALL_datasets(config, train=False)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "print(\"trian_dataset_list length:\",len(train_loader_list))\n",
    "for i in range(num_categories):\n",
    "    print(\"trian_dataset(\"+categories[i]+\") length:\",len(train_dataset_list[i]))\n",
    "print(\"val_dataset length:\",len(val_dataset))\n",
    "print(\"test_dataset length:\",len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Model----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Model----------#')\n",
    "in_channels = config.in_channels\n",
    "out_channels = config.out_channels\n",
    "base_net = smp.Unet(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# base_net = smp.UnetPlusPlus(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# initialize_weights_he(base_net)\n",
    "\n",
    "weights_dict = torch.load(config.dicts_path)\n",
    "base_net.load_state_dict(weights_dict,strict=False)\n",
    "base_net = base_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing loss, opt, sch and amp----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing loss, opt, sch and amp----------#')\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "meta_optimizer = get_optimizer(config, base_net)\n",
    "meta_scheduler = get_scheduler(config, meta_optimizer)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Set other params----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Set other params----------#')\n",
    "min_loss = 999\n",
    "start_epoch = 1\n",
    "min_epoch = 1\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Start training----------#\n",
      "128-resizeh, 128-resizew, 0.000010-outer_lr\n",
      "#Train#  epoch: 1, loss: 0.5365145206451416, dice: 0.7130066156387329\n",
      "#Val#  epoch: 1, dice: 0.7813363075256348\n",
      "#Test#  epoch: 1, dice: 0.7901867628097534\n",
      "#Train#  epoch: 2, loss: 0.5317266583442688, dice: 0.7158656716346741\n",
      "#Val#  epoch: 2, dice: 0.7784127593040466\n",
      "#Test#  epoch: 2, dice: 0.7864535450935364\n",
      "#Train#  epoch: 3, loss: 0.5217871069908142, dice: 0.7217583060264587\n",
      "#Val#  epoch: 3, dice: 0.7752336859703064\n",
      "#Test#  epoch: 3, dice: 0.7814381122589111\n",
      "#Train#  epoch: 4, loss: 0.5096797347068787, dice: 0.7286249399185181\n",
      "#Val#  epoch: 4, dice: 0.7713302969932556\n",
      "#Test#  epoch: 4, dice: 0.7762153744697571\n",
      "#Train#  epoch: 5, loss: 0.4968333840370178, dice: 0.7364756464958191\n",
      "#Val#  epoch: 5, dice: 0.7662432193756104\n",
      "#Test#  epoch: 5, dice: 0.7711867690086365\n",
      "#Train#  epoch: 6, loss: 0.48381075263023376, dice: 0.7453732490539551\n",
      "#Val#  epoch: 6, dice: 0.7610517740249634\n",
      "#Test#  epoch: 6, dice: 0.7649699449539185\n",
      "#Train#  epoch: 7, loss: 0.4685900807380676, dice: 0.7554130554199219\n",
      "#Val#  epoch: 7, dice: 0.7542913556098938\n",
      "#Test#  epoch: 7, dice: 0.7584702968597412\n",
      "#Train#  epoch: 8, loss: 0.45052504539489746, dice: 0.7661117315292358\n",
      "#Val#  epoch: 8, dice: 0.7468124628067017\n",
      "#Test#  epoch: 8, dice: 0.7516446113586426\n",
      "#Train#  epoch: 9, loss: 0.4305517375469208, dice: 0.7810829877853394\n",
      "#Val#  epoch: 9, dice: 0.7398636937141418\n",
      "#Test#  epoch: 9, dice: 0.7441555857658386\n",
      "#Train#  epoch: 10, loss: 0.41099315881729126, dice: 0.800121545791626\n",
      "#Val#  epoch: 10, dice: 0.7334538102149963\n",
      "#Test#  epoch: 10, dice: 0.737217903137207\n",
      "#Train#  epoch: 11, loss: 0.39452725648880005, dice: 0.8118782043457031\n",
      "#Val#  epoch: 11, dice: 0.726861298084259\n",
      "#Test#  epoch: 11, dice: 0.7305217981338501\n",
      "#Train#  epoch: 12, loss: 0.37237435579299927, dice: 0.8277677893638611\n",
      "#Val#  epoch: 12, dice: 0.7210542559623718\n",
      "#Test#  epoch: 12, dice: 0.7242076992988586\n",
      "#Train#  epoch: 13, loss: 0.3508237302303314, dice: 0.8425877094268799\n",
      "#Val#  epoch: 13, dice: 0.7164345979690552\n",
      "#Test#  epoch: 13, dice: 0.7191557288169861\n",
      "#Train#  epoch: 14, loss: 0.33359789848327637, dice: 0.8544695377349854\n",
      "#Val#  epoch: 14, dice: 0.7127593159675598\n",
      "#Test#  epoch: 14, dice: 0.7144151926040649\n",
      "#Train#  epoch: 15, loss: 0.31641533970832825, dice: 0.8663904070854187\n",
      "#Val#  epoch: 15, dice: 0.709911584854126\n",
      "#Test#  epoch: 15, dice: 0.7104834914207458\n",
      "#Train#  epoch: 16, loss: 0.3001595437526703, dice: 0.879180908203125\n",
      "#Val#  epoch: 16, dice: 0.7070035338401794\n",
      "#Test#  epoch: 16, dice: 0.7067270874977112\n",
      "#Train#  epoch: 17, loss: 0.288612961769104, dice: 0.8880624771118164\n",
      "#Val#  epoch: 17, dice: 0.7052596807479858\n",
      "#Test#  epoch: 17, dice: 0.7050386667251587\n",
      "#Train#  epoch: 18, loss: 0.28149136900901794, dice: 0.8929556608200073\n",
      "#Val#  epoch: 18, dice: 0.7046681642532349\n",
      "#Test#  epoch: 18, dice: 0.704986572265625\n",
      "#Train#  epoch: 19, loss: 0.27554017305374146, dice: 0.8970178365707397\n",
      "#Val#  epoch: 19, dice: 0.7052639722824097\n",
      "#Test#  epoch: 19, dice: 0.7064717411994934\n",
      "#Train#  epoch: 20, loss: 0.27145716547966003, dice: 0.8994259834289551\n",
      "#Val#  epoch: 20, dice: 0.7066516280174255\n",
      "#Test#  epoch: 20, dice: 0.7084737420082092\n",
      "#Train#  epoch: 21, loss: 0.26756376028060913, dice: 0.9020332098007202\n",
      "#Val#  epoch: 21, dice: 0.7089299559593201\n",
      "#Test#  epoch: 21, dice: 0.7117140889167786\n",
      "#Train#  epoch: 22, loss: 0.2642938494682312, dice: 0.9044824242591858\n",
      "#Val#  epoch: 22, dice: 0.7117214202880859\n",
      "#Test#  epoch: 22, dice: 0.7145184874534607\n",
      "#Train#  epoch: 23, loss: 0.26106351613998413, dice: 0.9069512486457825\n",
      "#Val#  epoch: 23, dice: 0.7145781517028809\n",
      "#Test#  epoch: 23, dice: 0.7174854874610901\n",
      "#Train#  epoch: 24, loss: 0.2577941417694092, dice: 0.9093049764633179\n",
      "#Val#  epoch: 24, dice: 0.7180634140968323\n",
      "#Test#  epoch: 24, dice: 0.720963180065155\n",
      "#Train#  epoch: 25, loss: 0.25483009219169617, dice: 0.9114555716514587\n",
      "#Val#  epoch: 25, dice: 0.7212074995040894\n",
      "#Test#  epoch: 25, dice: 0.724739134311676\n",
      "#Train#  epoch: 26, loss: 0.25186461210250854, dice: 0.9138965010643005\n",
      "#Val#  epoch: 26, dice: 0.7237116694450378\n",
      "#Test#  epoch: 26, dice: 0.7277897596359253\n",
      "#Train#  epoch: 27, loss: 0.24950042366981506, dice: 0.9156119227409363\n",
      "#Val#  epoch: 27, dice: 0.725104808807373\n",
      "#Test#  epoch: 27, dice: 0.7300311326980591\n",
      "#Train#  epoch: 28, loss: 0.24718157947063446, dice: 0.9177014827728271\n",
      "#Val#  epoch: 28, dice: 0.7262126803398132\n",
      "#Test#  epoch: 28, dice: 0.7320656776428223\n",
      "#Train#  epoch: 29, loss: 0.24512794613838196, dice: 0.9193834066390991\n",
      "#Val#  epoch: 29, dice: 0.7273422479629517\n",
      "#Test#  epoch: 29, dice: 0.7332107424736023\n",
      "#Train#  epoch: 30, loss: 0.2433748096227646, dice: 0.9208515286445618\n",
      "#Val#  epoch: 30, dice: 0.7283142805099487\n",
      "#Test#  epoch: 30, dice: 0.7337745428085327\n",
      "#Train#  epoch: 31, loss: 0.2416587620973587, dice: 0.9226524829864502\n",
      "#Val#  epoch: 31, dice: 0.7290031909942627\n",
      "#Test#  epoch: 31, dice: 0.7346187829971313\n",
      "#Train#  epoch: 32, loss: 0.23996368050575256, dice: 0.9246308207511902\n",
      "#Val#  epoch: 32, dice: 0.7295656800270081\n",
      "#Test#  epoch: 32, dice: 0.7353482842445374\n",
      "#Train#  epoch: 33, loss: 0.23852503299713135, dice: 0.9263517260551453\n",
      "#Val#  epoch: 33, dice: 0.7299652695655823\n",
      "#Test#  epoch: 33, dice: 0.735949695110321\n",
      "#Train#  epoch: 34, loss: 0.23722533881664276, dice: 0.9277371168136597\n",
      "#Val#  epoch: 34, dice: 0.730099081993103\n",
      "#Test#  epoch: 34, dice: 0.7364353537559509\n",
      "#Train#  epoch: 35, loss: 0.23609982430934906, dice: 0.9289447069168091\n",
      "#Val#  epoch: 35, dice: 0.73018479347229\n",
      "#Test#  epoch: 35, dice: 0.7368088960647583\n",
      "#Train#  epoch: 36, loss: 0.23493066430091858, dice: 0.9299301505088806\n",
      "#Val#  epoch: 36, dice: 0.7301716208457947\n",
      "#Test#  epoch: 36, dice: 0.7368282079696655\n",
      "#Train#  epoch: 37, loss: 0.23388104140758514, dice: 0.9306482672691345\n",
      "#Val#  epoch: 37, dice: 0.7299340963363647\n",
      "#Test#  epoch: 37, dice: 0.7366371154785156\n",
      "#Train#  epoch: 38, loss: 0.23262476921081543, dice: 0.9319364428520203\n",
      "#Val#  epoch: 38, dice: 0.7296611070632935\n",
      "#Test#  epoch: 38, dice: 0.7363682985305786\n",
      "#Train#  epoch: 39, loss: 0.2314063310623169, dice: 0.9331089854240417\n",
      "#Val#  epoch: 39, dice: 0.729404628276825\n",
      "#Test#  epoch: 39, dice: 0.7359477877616882\n",
      "#Train#  epoch: 40, loss: 0.2302510291337967, dice: 0.9341112375259399\n",
      "#Val#  epoch: 40, dice: 0.7290298938751221\n",
      "#Test#  epoch: 40, dice: 0.735527515411377\n",
      "#Train#  epoch: 41, loss: 0.22974400222301483, dice: 0.9345616698265076\n",
      "#Val#  epoch: 41, dice: 0.7287007570266724\n",
      "#Test#  epoch: 41, dice: 0.735091507434845\n",
      "#Train#  epoch: 42, loss: 0.22921954095363617, dice: 0.9350427985191345\n",
      "#Val#  epoch: 42, dice: 0.728351354598999\n",
      "#Test#  epoch: 42, dice: 0.734659731388092\n",
      "#Train#  epoch: 43, loss: 0.2286205291748047, dice: 0.9357045292854309\n",
      "#Val#  epoch: 43, dice: 0.7279946804046631\n",
      "#Test#  epoch: 43, dice: 0.7343482375144958\n",
      "#Train#  epoch: 44, loss: 0.22816252708435059, dice: 0.9363436102867126\n",
      "#Val#  epoch: 44, dice: 0.7276349663734436\n",
      "#Test#  epoch: 44, dice: 0.7341045141220093\n",
      "#Train#  epoch: 45, loss: 0.2276879996061325, dice: 0.93671715259552\n",
      "#Val#  epoch: 45, dice: 0.7273002862930298\n",
      "#Test#  epoch: 45, dice: 0.7338495850563049\n",
      "#Train#  epoch: 46, loss: 0.2272445261478424, dice: 0.9371496438980103\n",
      "#Val#  epoch: 46, dice: 0.7270053625106812\n",
      "#Test#  epoch: 46, dice: 0.7336831092834473\n",
      "#Train#  epoch: 47, loss: 0.22677329182624817, dice: 0.9377363324165344\n",
      "#Val#  epoch: 47, dice: 0.7266936302185059\n",
      "#Test#  epoch: 47, dice: 0.7335442900657654\n",
      "#Train#  epoch: 48, loss: 0.22631631791591644, dice: 0.9380691051483154\n",
      "#Val#  epoch: 48, dice: 0.7264649271965027\n",
      "#Test#  epoch: 48, dice: 0.733392596244812\n",
      "#Train#  epoch: 49, loss: 0.22589372098445892, dice: 0.9384844303131104\n",
      "#Val#  epoch: 49, dice: 0.7262932062149048\n",
      "#Test#  epoch: 49, dice: 0.7332717776298523\n",
      "#Train#  epoch: 50, loss: 0.22544889152050018, dice: 0.9388253688812256\n",
      "#Val#  epoch: 50, dice: 0.7261519432067871\n",
      "#Test#  epoch: 50, dice: 0.7331251502037048\n",
      "#Train#  epoch: 51, loss: 0.22504375874996185, dice: 0.9390634298324585\n",
      "#Val#  epoch: 51, dice: 0.7259712815284729\n",
      "#Test#  epoch: 51, dice: 0.7330484986305237\n",
      "#Train#  epoch: 52, loss: 0.2246730625629425, dice: 0.9392945766448975\n",
      "#Val#  epoch: 52, dice: 0.7258709073066711\n",
      "#Test#  epoch: 52, dice: 0.7329999804496765\n",
      "#Train#  epoch: 53, loss: 0.2241925299167633, dice: 0.9400902390480042\n",
      "#Val#  epoch: 53, dice: 0.7257971167564392\n",
      "#Test#  epoch: 53, dice: 0.7329288721084595\n",
      "#Train#  epoch: 54, loss: 0.22388528287410736, dice: 0.9402456879615784\n",
      "#Val#  epoch: 54, dice: 0.7256978750228882\n",
      "#Test#  epoch: 54, dice: 0.7328877449035645\n",
      "#Train#  epoch: 55, loss: 0.22342859208583832, dice: 0.9407963156700134\n",
      "#Val#  epoch: 55, dice: 0.7256819009780884\n",
      "#Test#  epoch: 55, dice: 0.7328680753707886\n",
      "#Train#  epoch: 56, loss: 0.22313271462917328, dice: 0.9410465955734253\n",
      "#Val#  epoch: 56, dice: 0.7256926894187927\n",
      "#Test#  epoch: 56, dice: 0.732877790927887\n",
      "#Train#  epoch: 57, loss: 0.22279277443885803, dice: 0.9414385557174683\n",
      "#Val#  epoch: 57, dice: 0.7257096171379089\n",
      "#Test#  epoch: 57, dice: 0.7329040169715881\n",
      "#Train#  epoch: 58, loss: 0.22248540818691254, dice: 0.9418060183525085\n",
      "#Val#  epoch: 58, dice: 0.7257784605026245\n",
      "#Test#  epoch: 58, dice: 0.732940137386322\n",
      "#Train#  epoch: 59, loss: 0.22212891280651093, dice: 0.9421955943107605\n",
      "#Val#  epoch: 59, dice: 0.7258331775665283\n",
      "#Test#  epoch: 59, dice: 0.7330080270767212\n",
      "#Train#  epoch: 60, loss: 0.22183997929096222, dice: 0.9424123167991638\n",
      "#Val#  epoch: 60, dice: 0.7258961796760559\n",
      "#Test#  epoch: 60, dice: 0.7330381870269775\n",
      "#Train#  epoch: 61, loss: 0.22153761982917786, dice: 0.9427656531333923\n",
      "#Val#  epoch: 61, dice: 0.7260032296180725\n",
      "#Test#  epoch: 61, dice: 0.7331047654151917\n",
      "#Train#  epoch: 62, loss: 0.2211557924747467, dice: 0.9430254101753235\n",
      "#Val#  epoch: 62, dice: 0.7260655760765076\n",
      "#Test#  epoch: 62, dice: 0.7331916689872742\n",
      "#Train#  epoch: 63, loss: 0.2208515852689743, dice: 0.9433346390724182\n",
      "#Val#  epoch: 63, dice: 0.7262178063392639\n",
      "#Test#  epoch: 63, dice: 0.7332781553268433\n",
      "#Train#  epoch: 64, loss: 0.22058086097240448, dice: 0.9436237215995789\n",
      "#Val#  epoch: 64, dice: 0.7263268828392029\n",
      "#Test#  epoch: 64, dice: 0.7333486676216125\n",
      "#Train#  epoch: 65, loss: 0.22031144797801971, dice: 0.9438591003417969\n",
      "#Val#  epoch: 65, dice: 0.7264769673347473\n",
      "#Test#  epoch: 65, dice: 0.7333976626396179\n",
      "#Train#  epoch: 66, loss: 0.2200312614440918, dice: 0.9441017508506775\n",
      "#Val#  epoch: 66, dice: 0.726618230342865\n",
      "#Test#  epoch: 66, dice: 0.7334825396537781\n",
      "#Train#  epoch: 67, loss: 0.21969376504421234, dice: 0.9443797469139099\n",
      "#Val#  epoch: 67, dice: 0.7267292141914368\n",
      "#Test#  epoch: 67, dice: 0.7335629463195801\n",
      "#Train#  epoch: 68, loss: 0.21940627694129944, dice: 0.9447169899940491\n",
      "#Val#  epoch: 68, dice: 0.7267961502075195\n",
      "#Test#  epoch: 68, dice: 0.7335733771324158\n",
      "#Train#  epoch: 69, loss: 0.21918220818042755, dice: 0.9448657631874084\n",
      "#Val#  epoch: 69, dice: 0.7269001603126526\n",
      "#Test#  epoch: 69, dice: 0.7336227893829346\n",
      "#Train#  epoch: 70, loss: 0.21885915100574493, dice: 0.9451870918273926\n",
      "#Val#  epoch: 70, dice: 0.7269532084465027\n",
      "#Test#  epoch: 70, dice: 0.7336021065711975\n",
      "#Train#  epoch: 71, loss: 0.21863949298858643, dice: 0.9454049468040466\n",
      "#Val#  epoch: 71, dice: 0.7269746661186218\n",
      "#Test#  epoch: 71, dice: 0.7336176037788391\n",
      "#Train#  epoch: 72, loss: 0.21835508942604065, dice: 0.9456804394721985\n",
      "#Val#  epoch: 72, dice: 0.726969301700592\n",
      "#Test#  epoch: 72, dice: 0.7335965037345886\n",
      "#Train#  epoch: 73, loss: 0.21814297139644623, dice: 0.9458889365196228\n",
      "#Val#  epoch: 73, dice: 0.726999819278717\n",
      "#Test#  epoch: 73, dice: 0.7336122393608093\n",
      "#Train#  epoch: 74, loss: 0.21790654957294464, dice: 0.9461100697517395\n",
      "#Val#  epoch: 74, dice: 0.7269502282142639\n",
      "#Test#  epoch: 74, dice: 0.7335878014564514\n",
      "#Train#  epoch: 75, loss: 0.2176661342382431, dice: 0.9464001059532166\n",
      "#Val#  epoch: 75, dice: 0.7269522547721863\n",
      "#Test#  epoch: 75, dice: 0.7335973381996155\n",
      "#Train#  epoch: 76, loss: 0.2174491137266159, dice: 0.9465405941009521\n",
      "#Val#  epoch: 76, dice: 0.7269376516342163\n",
      "#Test#  epoch: 76, dice: 0.7335712313652039\n",
      "#Train#  epoch: 77, loss: 0.21719828248023987, dice: 0.9468360543251038\n",
      "#Val#  epoch: 77, dice: 0.7269256114959717\n",
      "#Test#  epoch: 77, dice: 0.7335355877876282\n",
      "#Train#  epoch: 78, loss: 0.21698470413684845, dice: 0.9471682906150818\n",
      "#Val#  epoch: 78, dice: 0.7268840670585632\n",
      "#Test#  epoch: 78, dice: 0.7335030436515808\n",
      "#Train#  epoch: 79, loss: 0.21678243577480316, dice: 0.947291910648346\n",
      "#Val#  epoch: 79, dice: 0.726855456829071\n",
      "#Test#  epoch: 79, dice: 0.7335021495819092\n",
      "#Train#  epoch: 80, loss: 0.21655766665935516, dice: 0.9475466012954712\n",
      "#Val#  epoch: 80, dice: 0.7268648743629456\n",
      "#Test#  epoch: 80, dice: 0.7334911823272705\n",
      "#Train#  epoch: 81, loss: 0.21643362939357758, dice: 0.9477237462997437\n",
      "#Val#  epoch: 81, dice: 0.726840078830719\n",
      "#Test#  epoch: 81, dice: 0.7334794998168945\n",
      "#Train#  epoch: 82, loss: 0.21639075875282288, dice: 0.9477415680885315\n",
      "#Val#  epoch: 82, dice: 0.7268494963645935\n",
      "#Test#  epoch: 82, dice: 0.733481228351593\n",
      "#Train#  epoch: 83, loss: 0.2162410020828247, dice: 0.9478285908699036\n",
      "#Val#  epoch: 83, dice: 0.7268900275230408\n",
      "#Test#  epoch: 83, dice: 0.7335138916969299\n",
      "#Train#  epoch: 84, loss: 0.21612834930419922, dice: 0.9480183124542236\n",
      "#Val#  epoch: 84, dice: 0.7269220352172852\n",
      "#Test#  epoch: 84, dice: 0.7335330247879028\n",
      "#Train#  epoch: 85, loss: 0.21604691445827484, dice: 0.9480236172676086\n",
      "#Val#  epoch: 85, dice: 0.7269045114517212\n",
      "#Test#  epoch: 85, dice: 0.7335588932037354\n",
      "#Train#  epoch: 86, loss: 0.21590638160705566, dice: 0.9480718374252319\n",
      "#Val#  epoch: 86, dice: 0.7269313335418701\n",
      "#Test#  epoch: 86, dice: 0.7335330843925476\n",
      "#Train#  epoch: 87, loss: 0.21585698425769806, dice: 0.9482166171073914\n",
      "#Val#  epoch: 87, dice: 0.7269551753997803\n",
      "#Test#  epoch: 87, dice: 0.7335723042488098\n",
      "#Train#  epoch: 88, loss: 0.215767964720726, dice: 0.948362410068512\n",
      "#Val#  epoch: 88, dice: 0.7269749641418457\n",
      "#Test#  epoch: 88, dice: 0.7335744500160217\n",
      "#Train#  epoch: 89, loss: 0.21565113961696625, dice: 0.9484850168228149\n",
      "#Val#  epoch: 89, dice: 0.7270280122756958\n",
      "#Test#  epoch: 89, dice: 0.7336678504943848\n",
      "#Train#  epoch: 90, loss: 0.2155400961637497, dice: 0.9485920071601868\n",
      "#Val#  epoch: 90, dice: 0.7270132303237915\n",
      "#Test#  epoch: 90, dice: 0.7336547374725342\n",
      "#Train#  epoch: 91, loss: 0.21546673774719238, dice: 0.9486791491508484\n",
      "#Val#  epoch: 91, dice: 0.7270501255989075\n",
      "#Test#  epoch: 91, dice: 0.7336703538894653\n",
      "#Train#  epoch: 92, loss: 0.2153586447238922, dice: 0.948682427406311\n",
      "#Val#  epoch: 92, dice: 0.7270544767379761\n",
      "#Test#  epoch: 92, dice: 0.7336987257003784\n",
      "#Train#  epoch: 93, loss: 0.21529631316661835, dice: 0.9488283395767212\n",
      "#Val#  epoch: 93, dice: 0.7270572781562805\n",
      "#Test#  epoch: 93, dice: 0.7336885929107666\n",
      "#Train#  epoch: 94, loss: 0.21518559753894806, dice: 0.9490475058555603\n",
      "#Val#  epoch: 94, dice: 0.7270832657814026\n",
      "#Test#  epoch: 94, dice: 0.7336857914924622\n",
      "#Train#  epoch: 95, loss: 0.21510744094848633, dice: 0.9490643739700317\n",
      "#Val#  epoch: 95, dice: 0.7270910739898682\n",
      "#Test#  epoch: 95, dice: 0.7336803674697876\n",
      "#Train#  epoch: 96, loss: 0.21502242982387543, dice: 0.9491525292396545\n",
      "#Val#  epoch: 96, dice: 0.7270962595939636\n",
      "#Test#  epoch: 96, dice: 0.7337138652801514\n",
      "#Train#  epoch: 97, loss: 0.21494336426258087, dice: 0.949196457862854\n",
      "#Val#  epoch: 97, dice: 0.7270824313163757\n",
      "#Test#  epoch: 97, dice: 0.7336878776550293\n",
      "#Train#  epoch: 98, loss: 0.21488097310066223, dice: 0.949238657951355\n",
      "#Val#  epoch: 98, dice: 0.7270887494087219\n",
      "#Test#  epoch: 98, dice: 0.733708918094635\n",
      "#Train#  epoch: 99, loss: 0.2147870510816574, dice: 0.9494096040725708\n",
      "#Val#  epoch: 99, dice: 0.7270839214324951\n",
      "#Test#  epoch: 99, dice: 0.7337290048599243\n",
      "#Train#  epoch: 100, loss: 0.21468296647071838, dice: 0.9494578838348389\n",
      "#Val#  epoch: 100, dice: 0.7270991802215576\n",
      "#Test#  epoch: 100, dice: 0.733747661113739\n",
      "#Train#  epoch: 101, loss: 0.21458640694618225, dice: 0.9495859742164612\n",
      "#Val#  epoch: 101, dice: 0.7270747423171997\n",
      "#Test#  epoch: 101, dice: 0.7337533235549927\n",
      "#Train#  epoch: 102, loss: 0.2145031988620758, dice: 0.9496268033981323\n",
      "#Val#  epoch: 102, dice: 0.7271156311035156\n",
      "#Test#  epoch: 102, dice: 0.733765721321106\n",
      "#Train#  epoch: 103, loss: 0.21445515751838684, dice: 0.9497613310813904\n",
      "#Val#  epoch: 103, dice: 0.727105975151062\n",
      "#Test#  epoch: 103, dice: 0.7337387204170227\n",
      "#Train#  epoch: 104, loss: 0.21436884999275208, dice: 0.9497936964035034\n",
      "#Val#  epoch: 104, dice: 0.7270961999893188\n",
      "#Test#  epoch: 104, dice: 0.7337633967399597\n",
      "#Train#  epoch: 105, loss: 0.214267298579216, dice: 0.9499062895774841\n",
      "#Val#  epoch: 105, dice: 0.7270832657814026\n",
      "#Test#  epoch: 105, dice: 0.7337538003921509\n",
      "#Train#  epoch: 106, loss: 0.21417538821697235, dice: 0.9500458240509033\n",
      "#Val#  epoch: 106, dice: 0.7270627617835999\n",
      "#Test#  epoch: 106, dice: 0.7337193489074707\n",
      "#Train#  epoch: 107, loss: 0.21407191455364227, dice: 0.950089693069458\n",
      "#Val#  epoch: 107, dice: 0.727069616317749\n",
      "#Test#  epoch: 107, dice: 0.7337127327919006\n",
      "#Train#  epoch: 108, loss: 0.21401701867580414, dice: 0.9501768946647644\n",
      "#Val#  epoch: 108, dice: 0.7270691394805908\n",
      "#Test#  epoch: 108, dice: 0.733717679977417\n",
      "#Train#  epoch: 109, loss: 0.2139044851064682, dice: 0.9503294229507446\n",
      "#Val#  epoch: 109, dice: 0.7270727753639221\n",
      "#Test#  epoch: 109, dice: 0.733698308467865\n",
      "#Train#  epoch: 110, loss: 0.21382680535316467, dice: 0.9504216313362122\n",
      "#Val#  epoch: 110, dice: 0.7270510196685791\n",
      "#Test#  epoch: 110, dice: 0.7336971759796143\n",
      "#Train#  epoch: 111, loss: 0.21377114951610565, dice: 0.9504291415214539\n",
      "#Val#  epoch: 111, dice: 0.7270463705062866\n",
      "#Test#  epoch: 111, dice: 0.7336686849594116\n",
      "#Train#  epoch: 112, loss: 0.21369695663452148, dice: 0.9505477547645569\n",
      "#Val#  epoch: 112, dice: 0.7270400524139404\n",
      "#Test#  epoch: 112, dice: 0.7336696982383728\n",
      "#Train#  epoch: 113, loss: 0.21363286674022675, dice: 0.9506291151046753\n",
      "#Val#  epoch: 113, dice: 0.7270374298095703\n",
      "#Test#  epoch: 113, dice: 0.7336671352386475\n",
      "#Train#  epoch: 114, loss: 0.21351809799671173, dice: 0.950762152671814\n",
      "#Val#  epoch: 114, dice: 0.7270134687423706\n",
      "#Test#  epoch: 114, dice: 0.7336621284484863\n",
      "#Train#  epoch: 115, loss: 0.2134924679994583, dice: 0.9507572650909424\n",
      "#Val#  epoch: 115, dice: 0.7269570827484131\n",
      "#Test#  epoch: 115, dice: 0.7336385250091553\n",
      "#Train#  epoch: 116, loss: 0.2133912593126297, dice: 0.9509092569351196\n",
      "#Val#  epoch: 116, dice: 0.7269607782363892\n",
      "#Test#  epoch: 116, dice: 0.7336158156394958\n",
      "#Train#  epoch: 117, loss: 0.2132895290851593, dice: 0.9509916305541992\n",
      "#Val#  epoch: 117, dice: 0.7269494533538818\n",
      "#Test#  epoch: 117, dice: 0.733627438545227\n",
      "#Train#  epoch: 118, loss: 0.213231161236763, dice: 0.9510838389396667\n",
      "#Val#  epoch: 118, dice: 0.726963222026825\n",
      "#Test#  epoch: 118, dice: 0.733654797077179\n",
      "#Train#  epoch: 119, loss: 0.21315863728523254, dice: 0.9511151909828186\n",
      "#Val#  epoch: 119, dice: 0.7269420623779297\n",
      "#Test#  epoch: 119, dice: 0.7336450219154358\n",
      "#Train#  epoch: 120, loss: 0.21305663883686066, dice: 0.9511721134185791\n",
      "#Val#  epoch: 120, dice: 0.7269469499588013\n",
      "#Test#  epoch: 120, dice: 0.7336593270301819\n",
      "#Train#  epoch: 121, loss: 0.21306124329566956, dice: 0.9512175917625427\n",
      "#Val#  epoch: 121, dice: 0.7269547581672668\n",
      "#Test#  epoch: 121, dice: 0.7336450815200806\n",
      "#Train#  epoch: 122, loss: 0.21301646530628204, dice: 0.9512953758239746\n",
      "#Val#  epoch: 122, dice: 0.7269243001937866\n",
      "#Test#  epoch: 122, dice: 0.7336360812187195\n",
      "#Train#  epoch: 123, loss: 0.21300558745861053, dice: 0.951221227645874\n",
      "#Val#  epoch: 123, dice: 0.7269310355186462\n",
      "#Test#  epoch: 123, dice: 0.7336522340774536\n",
      "#Train#  epoch: 124, loss: 0.21293771266937256, dice: 0.9513372182846069\n",
      "#Val#  epoch: 124, dice: 0.7269378304481506\n",
      "#Test#  epoch: 124, dice: 0.733658492565155\n",
      "#Train#  epoch: 125, loss: 0.2129230499267578, dice: 0.9513646960258484\n",
      "#Val#  epoch: 125, dice: 0.7269258499145508\n",
      "#Test#  epoch: 125, dice: 0.7336714267730713\n",
      "#Train#  epoch: 126, loss: 0.21289114654064178, dice: 0.9514111876487732\n",
      "#Val#  epoch: 126, dice: 0.7269517183303833\n",
      "#Test#  epoch: 126, dice: 0.7336647510528564\n",
      "#Train#  epoch: 127, loss: 0.21286554634571075, dice: 0.9514673352241516\n",
      "#Val#  epoch: 127, dice: 0.7269476056098938\n",
      "#Test#  epoch: 127, dice: 0.7336677312850952\n",
      "#Train#  epoch: 128, loss: 0.21281082928180695, dice: 0.9514559507369995\n",
      "#Val#  epoch: 128, dice: 0.7269431352615356\n",
      "#Test#  epoch: 128, dice: 0.7336798310279846\n",
      "#Train#  epoch: 129, loss: 0.2127983570098877, dice: 0.9515014290809631\n",
      "#Val#  epoch: 129, dice: 0.7269468307495117\n",
      "#Test#  epoch: 129, dice: 0.733668327331543\n",
      "#Train#  epoch: 130, loss: 0.21276497840881348, dice: 0.9515488743782043\n",
      "#Val#  epoch: 130, dice: 0.7269479632377625\n",
      "#Test#  epoch: 130, dice: 0.7336636781692505\n",
      "#Train#  epoch: 131, loss: 0.2127394676208496, dice: 0.9515688419342041\n",
      "#Val#  epoch: 131, dice: 0.7269589900970459\n",
      "#Test#  epoch: 131, dice: 0.7336928248405457\n",
      "#Train#  epoch: 132, loss: 0.21268542110919952, dice: 0.9516249895095825\n",
      "#Val#  epoch: 132, dice: 0.7269443273544312\n",
      "#Test#  epoch: 132, dice: 0.73370760679245\n",
      "#Train#  epoch: 133, loss: 0.21264925599098206, dice: 0.9515668749809265\n",
      "#Val#  epoch: 133, dice: 0.7269899249076843\n",
      "#Test#  epoch: 133, dice: 0.7336817383766174\n",
      "#Train#  epoch: 134, loss: 0.21262168884277344, dice: 0.9516714811325073\n",
      "#Val#  epoch: 134, dice: 0.7269477844238281\n",
      "#Test#  epoch: 134, dice: 0.7336850762367249\n",
      "#Train#  epoch: 135, loss: 0.21259453892707825, dice: 0.9516125917434692\n",
      "#Val#  epoch: 135, dice: 0.7269343733787537\n",
      "#Test#  epoch: 135, dice: 0.7336888313293457\n",
      "#Train#  epoch: 136, loss: 0.2125464230775833, dice: 0.9517483711242676\n",
      "#Val#  epoch: 136, dice: 0.7269434928894043\n",
      "#Test#  epoch: 136, dice: 0.7336567640304565\n",
      "#Train#  epoch: 137, loss: 0.21250580251216888, dice: 0.9517739415168762\n",
      "#Val#  epoch: 137, dice: 0.7269454598426819\n",
      "#Test#  epoch: 137, dice: 0.7336933016777039\n",
      "#Train#  epoch: 138, loss: 0.21247637271881104, dice: 0.9516904354095459\n",
      "#Val#  epoch: 138, dice: 0.7269582748413086\n",
      "#Test#  epoch: 138, dice: 0.7337179183959961\n",
      "#Train#  epoch: 139, loss: 0.212483212351799, dice: 0.9516876935958862\n",
      "#Val#  epoch: 139, dice: 0.72697514295578\n",
      "#Test#  epoch: 139, dice: 0.7337248921394348\n",
      "#Train#  epoch: 140, loss: 0.21242809295654297, dice: 0.9517731070518494\n",
      "#Val#  epoch: 140, dice: 0.7269876003265381\n",
      "#Test#  epoch: 140, dice: 0.7337294220924377\n",
      "#Train#  epoch: 141, loss: 0.21236513555049896, dice: 0.9518614411354065\n",
      "#Val#  epoch: 141, dice: 0.7269970774650574\n",
      "#Test#  epoch: 141, dice: 0.7337174415588379\n",
      "#Train#  epoch: 142, loss: 0.2123469114303589, dice: 0.9519241452217102\n",
      "#Val#  epoch: 142, dice: 0.7269619703292847\n",
      "#Test#  epoch: 142, dice: 0.7337307333946228\n",
      "#Train#  epoch: 143, loss: 0.21228793263435364, dice: 0.9519268870353699\n",
      "#Val#  epoch: 143, dice: 0.7269906997680664\n",
      "#Test#  epoch: 143, dice: 0.7337442636489868\n",
      "#Train#  epoch: 144, loss: 0.2122727930545807, dice: 0.9519003629684448\n",
      "#Val#  epoch: 144, dice: 0.7269873023033142\n",
      "#Test#  epoch: 144, dice: 0.7337736487388611\n",
      "#Train#  epoch: 145, loss: 0.21223555505275726, dice: 0.951888918876648\n",
      "#Val#  epoch: 145, dice: 0.7269914746284485\n",
      "#Test#  epoch: 145, dice: 0.7337818741798401\n",
      "#Train#  epoch: 146, loss: 0.2121920883655548, dice: 0.9519810080528259\n",
      "#Val#  epoch: 146, dice: 0.726983368396759\n",
      "#Test#  epoch: 146, dice: 0.7337887287139893\n",
      "#Train#  epoch: 147, loss: 0.2121930569410324, dice: 0.9519848227500916\n",
      "#Val#  epoch: 147, dice: 0.7269598841667175\n",
      "#Test#  epoch: 147, dice: 0.7337495684623718\n",
      "#Train#  epoch: 148, loss: 0.2121592015028, dice: 0.9520884156227112\n",
      "#Val#  epoch: 148, dice: 0.7269771695137024\n",
      "#Test#  epoch: 148, dice: 0.7337562441825867\n",
      "#Train#  epoch: 149, loss: 0.21211352944374084, dice: 0.9521368145942688\n",
      "#Val#  epoch: 149, dice: 0.7269850969314575\n",
      "#Test#  epoch: 149, dice: 0.7337633371353149\n",
      "#Train#  epoch: 150, loss: 0.21207252144813538, dice: 0.9522232413291931\n",
      "#Val#  epoch: 150, dice: 0.7269896268844604\n",
      "#Test#  epoch: 150, dice: 0.7337996363639832\n",
      "#Train#  epoch: 151, loss: 0.2120579034090042, dice: 0.95223468542099\n",
      "#Val#  epoch: 151, dice: 0.7269957065582275\n",
      "#Test#  epoch: 151, dice: 0.7337917685508728\n",
      "#Train#  epoch: 152, loss: 0.21201732754707336, dice: 0.9522337317466736\n",
      "#Val#  epoch: 152, dice: 0.7269973158836365\n",
      "#Test#  epoch: 152, dice: 0.7338049411773682\n",
      "#Train#  epoch: 153, loss: 0.21198217570781708, dice: 0.9522745609283447\n",
      "#Val#  epoch: 153, dice: 0.7270116806030273\n",
      "#Test#  epoch: 153, dice: 0.7337923645973206\n",
      "#Train#  epoch: 154, loss: 0.21194611489772797, dice: 0.9522897601127625\n",
      "#Val#  epoch: 154, dice: 0.7270209789276123\n",
      "#Test#  epoch: 154, dice: 0.7338149547576904\n",
      "#Train#  epoch: 155, loss: 0.21189279854297638, dice: 0.9524303674697876\n",
      "#Val#  epoch: 155, dice: 0.7270017266273499\n",
      "#Test#  epoch: 155, dice: 0.7338065505027771\n",
      "#Train#  epoch: 156, loss: 0.21188271045684814, dice: 0.952374279499054\n",
      "#Val#  epoch: 156, dice: 0.7270288467407227\n",
      "#Test#  epoch: 156, dice: 0.733825147151947\n",
      "#Train#  epoch: 157, loss: 0.21188412606716156, dice: 0.9523296356201172\n",
      "#Val#  epoch: 157, dice: 0.7270107865333557\n",
      "#Test#  epoch: 157, dice: 0.7338199019432068\n",
      "#Train#  epoch: 158, loss: 0.2118404656648636, dice: 0.9523648023605347\n",
      "#Val#  epoch: 158, dice: 0.7270146012306213\n",
      "#Test#  epoch: 158, dice: 0.7338294386863708\n",
      "#Train#  epoch: 159, loss: 0.21183548867702484, dice: 0.9523952007293701\n",
      "#Val#  epoch: 159, dice: 0.7270404696464539\n",
      "#Test#  epoch: 159, dice: 0.733802318572998\n",
      "#Train#  epoch: 160, loss: 0.21178801357746124, dice: 0.952403724193573\n",
      "#Val#  epoch: 160, dice: 0.7270315885543823\n",
      "#Test#  epoch: 160, dice: 0.7338325381278992\n",
      "#Train#  epoch: 161, loss: 0.2117946594953537, dice: 0.9524711966514587\n",
      "#Val#  epoch: 161, dice: 0.727037787437439\n",
      "#Test#  epoch: 161, dice: 0.7338172197341919\n",
      "#Train#  epoch: 162, loss: 0.2117474377155304, dice: 0.9525861144065857\n",
      "#Val#  epoch: 162, dice: 0.7270471453666687\n",
      "#Test#  epoch: 162, dice: 0.7338098883628845\n",
      "#Train#  epoch: 163, loss: 0.21174350380897522, dice: 0.9525481462478638\n",
      "#Val#  epoch: 163, dice: 0.7270196676254272\n",
      "#Test#  epoch: 163, dice: 0.7338048219680786\n",
      "#Train#  epoch: 164, loss: 0.21170423924922943, dice: 0.952570915222168\n",
      "#Val#  epoch: 164, dice: 0.7270404100418091\n",
      "#Test#  epoch: 164, dice: 0.7338138222694397\n",
      "#Train#  epoch: 165, loss: 0.2117173671722412, dice: 0.9525405168533325\n",
      "#Val#  epoch: 165, dice: 0.7270432710647583\n",
      "#Test#  epoch: 165, dice: 0.7338032126426697\n",
      "#Train#  epoch: 166, loss: 0.21167932450771332, dice: 0.9526032209396362\n",
      "#Val#  epoch: 166, dice: 0.7270549535751343\n",
      "#Test#  epoch: 166, dice: 0.7338033318519592\n",
      "#Train#  epoch: 167, loss: 0.2116728574037552, dice: 0.952605128288269\n",
      "#Val#  epoch: 167, dice: 0.7270452380180359\n",
      "#Test#  epoch: 167, dice: 0.733797013759613\n",
      "#Train#  epoch: 168, loss: 0.21167266368865967, dice: 0.9526041746139526\n",
      "#Val#  epoch: 168, dice: 0.7270547151565552\n",
      "#Test#  epoch: 168, dice: 0.7338019609451294\n",
      "#Train#  epoch: 169, loss: 0.2116241753101349, dice: 0.9528113007545471\n",
      "#Val#  epoch: 169, dice: 0.7270280718803406\n",
      "#Test#  epoch: 169, dice: 0.7337824702262878\n",
      "#Train#  epoch: 170, loss: 0.21163010597229004, dice: 0.9527134299278259\n",
      "#Val#  epoch: 170, dice: 0.7270262241363525\n",
      "#Test#  epoch: 170, dice: 0.7337877750396729\n",
      "#Train#  epoch: 171, loss: 0.21162155270576477, dice: 0.9527419209480286\n",
      "#Val#  epoch: 171, dice: 0.7270040512084961\n",
      "#Test#  epoch: 171, dice: 0.7337820529937744\n",
      "#Train#  epoch: 172, loss: 0.21159568428993225, dice: 0.9527542591094971\n",
      "#Val#  epoch: 172, dice: 0.7269987463951111\n",
      "#Test#  epoch: 172, dice: 0.7337602972984314\n",
      "#Train#  epoch: 173, loss: 0.2115708440542221, dice: 0.9527931809425354\n",
      "#Val#  epoch: 173, dice: 0.727003812789917\n",
      "#Test#  epoch: 173, dice: 0.7337605953216553\n",
      "#Train#  epoch: 174, loss: 0.21155095100402832, dice: 0.9527475833892822\n",
      "#Val#  epoch: 174, dice: 0.7269895076751709\n",
      "#Test#  epoch: 174, dice: 0.733773946762085\n",
      "#Train#  epoch: 175, loss: 0.2115577906370163, dice: 0.9527837038040161\n",
      "#Val#  epoch: 175, dice: 0.7270119786262512\n",
      "#Test#  epoch: 175, dice: 0.7337626814842224\n",
      "#Train#  epoch: 176, loss: 0.21151860058307648, dice: 0.9528046250343323\n",
      "#Val#  epoch: 176, dice: 0.7269940376281738\n",
      "#Test#  epoch: 176, dice: 0.7337505221366882\n",
      "#Train#  epoch: 177, loss: 0.2114884853363037, dice: 0.9528435468673706\n",
      "#Val#  epoch: 177, dice: 0.7269953489303589\n",
      "#Test#  epoch: 177, dice: 0.7337464690208435\n",
      "#Train#  epoch: 178, loss: 0.21147672832012177, dice: 0.9528274536132812\n",
      "#Val#  epoch: 178, dice: 0.7269682884216309\n",
      "#Test#  epoch: 178, dice: 0.7337426543235779\n",
      "#Train#  epoch: 179, loss: 0.21150031685829163, dice: 0.9528027176856995\n",
      "#Val#  epoch: 179, dice: 0.7269858717918396\n",
      "#Test#  epoch: 179, dice: 0.7337455153465271\n",
      "#Train#  epoch: 180, loss: 0.2114466428756714, dice: 0.9528996348381042\n",
      "#Val#  epoch: 180, dice: 0.7269725203514099\n",
      "#Test#  epoch: 180, dice: 0.733741044998169\n",
      "#Train#  epoch: 181, loss: 0.21144652366638184, dice: 0.9528435468673706\n",
      "#Val#  epoch: 181, dice: 0.726979672908783\n",
      "#Test#  epoch: 181, dice: 0.7337356805801392\n",
      "#Train#  epoch: 182, loss: 0.2114713191986084, dice: 0.9528312087059021\n",
      "#Val#  epoch: 182, dice: 0.7269464731216431\n",
      "#Test#  epoch: 182, dice: 0.7337296009063721\n",
      "#Train#  epoch: 183, loss: 0.21142278611660004, dice: 0.9528882503509521\n",
      "#Val#  epoch: 183, dice: 0.7269484400749207\n",
      "#Test#  epoch: 183, dice: 0.7337110638618469\n",
      "#Train#  epoch: 184, loss: 0.21138504147529602, dice: 0.9529186487197876\n",
      "#Val#  epoch: 184, dice: 0.726952075958252\n",
      "#Test#  epoch: 184, dice: 0.7337086200714111\n",
      "#Train#  epoch: 185, loss: 0.21137629449367523, dice: 0.9529063105583191\n",
      "#Val#  epoch: 185, dice: 0.726942777633667\n",
      "#Test#  epoch: 185, dice: 0.7337047457695007\n",
      "#Train#  epoch: 186, loss: 0.21137022972106934, dice: 0.9529585242271423\n",
      "#Val#  epoch: 186, dice: 0.7269183397293091\n",
      "#Test#  epoch: 186, dice: 0.7336974740028381\n",
      "#Train#  epoch: 187, loss: 0.21132412552833557, dice: 0.953096330165863\n",
      "#Val#  epoch: 187, dice: 0.7269263863563538\n",
      "#Test#  epoch: 187, dice: 0.7336969375610352\n",
      "#Train#  epoch: 188, loss: 0.2113255113363266, dice: 0.9530659317970276\n",
      "#Val#  epoch: 188, dice: 0.7269401550292969\n",
      "#Test#  epoch: 188, dice: 0.7336986064910889\n",
      "#Train#  epoch: 189, loss: 0.21131621301174164, dice: 0.9530487656593323\n",
      "#Val#  epoch: 189, dice: 0.7269197106361389\n",
      "#Test#  epoch: 189, dice: 0.7337009906768799\n",
      "#Train#  epoch: 190, loss: 0.21130727231502533, dice: 0.9530251026153564\n",
      "#Val#  epoch: 190, dice: 0.726909875869751\n",
      "#Test#  epoch: 190, dice: 0.7336984276771545\n",
      "#Train#  epoch: 191, loss: 0.21127894520759583, dice: 0.9530745148658752\n",
      "#Val#  epoch: 191, dice: 0.7268965840339661\n",
      "#Test#  epoch: 191, dice: 0.7336778044700623\n",
      "#Train#  epoch: 192, loss: 0.21128526329994202, dice: 0.95302414894104\n",
      "#Val#  epoch: 192, dice: 0.7268850207328796\n",
      "#Test#  epoch: 192, dice: 0.7336680293083191\n",
      "#Train#  epoch: 193, loss: 0.21126194298267365, dice: 0.9529851675033569\n",
      "#Val#  epoch: 193, dice: 0.7268989682197571\n",
      "#Test#  epoch: 193, dice: 0.7336691617965698\n",
      "#Train#  epoch: 194, loss: 0.21123743057250977, dice: 0.9530174732208252\n",
      "#Val#  epoch: 194, dice: 0.7268940210342407\n",
      "#Test#  epoch: 194, dice: 0.7336587905883789\n",
      "#Train#  epoch: 195, loss: 0.21122507750988007, dice: 0.9531362056732178\n",
      "#Val#  epoch: 195, dice: 0.7268774509429932\n",
      "#Test#  epoch: 195, dice: 0.7336655259132385\n",
      "#Train#  epoch: 196, loss: 0.21124009788036346, dice: 0.9530563950538635\n",
      "#Val#  epoch: 196, dice: 0.7268841862678528\n",
      "#Test#  epoch: 196, dice: 0.7336633801460266\n",
      "#Train#  epoch: 197, loss: 0.21119670569896698, dice: 0.9530726075172424\n",
      "#Val#  epoch: 197, dice: 0.7268802523612976\n",
      "#Test#  epoch: 197, dice: 0.7336684465408325\n",
      "#Train#  epoch: 198, loss: 0.21119685471057892, dice: 0.9530944228172302\n",
      "#Val#  epoch: 198, dice: 0.7268993854522705\n",
      "#Test#  epoch: 198, dice: 0.7336723208427429\n",
      "#Train#  epoch: 199, loss: 0.21117953956127167, dice: 0.9531960487365723\n",
      "#Val#  epoch: 199, dice: 0.72689288854599\n",
      "#Test#  epoch: 199, dice: 0.7336751818656921\n",
      "#Train#  epoch: 200, loss: 0.2111571580171585, dice: 0.9531276226043701\n",
      "#Val#  epoch: 200, dice: 0.7268834710121155\n",
      "#Test#  epoch: 200, dice: 0.7336525917053223\n"
     ]
    }
   ],
   "source": [
    "print('#----------Start training----------#')\n",
    "torch.cuda.empty_cache()\n",
    "info = \"%d-resizeh, %d-resizew, %f-outer_lr\"%(config.resize_h,config.resize_w,config.outer_lr)\n",
    "print(info)\n",
    "logger.info(info)\n",
    "best_dice_val = 0.0\n",
    "best_dice_test = 0.0\n",
    "train_csv = os.path.join(csv_save,\"train.csv\")\n",
    "val_csv = os.path.join(csv_save,\"val.csv\")\n",
    "test_csv = os.path.join(csv_save,\"test.csv\")\n",
    "train_columns = ['Epoch','Loss',\"Mdice\"]\n",
    "train_df = pd.DataFrame(columns=train_columns)\n",
    "val_columns = ['Epoch','Mdice']\n",
    "val_df = pd.DataFrame(columns=val_columns)\n",
    "test_columns = ['Epoch','Mdice']\n",
    "test_df = pd.DataFrame(columns=test_columns)\n",
    "for epoch in range(start_epoch, config.epoch_num+1):\n",
    "    meta_scheduler.step()\n",
    "    # train part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    loss_list = []    \n",
    "    base_net.train()\n",
    "    meta_optimizer.zero_grad()\n",
    "    for category_index in range(num_categories):\n",
    "        for image,mask in train_loader_list[category_index]:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)     # torch.Size([bs,out_channels=1,512,512])\n",
    "            predicted = predicted.squeeze(1)    # torch.Size([bs,512,512])\n",
    "            loss = criterion(predicted,mask)\n",
    "            loss = loss/num_categories\n",
    "            loss.backward()\n",
    "            predicted = (predicted > threshold).long()\n",
    "            temp_predicted = predicted.cpu().detach()       # threshold alternative\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach())\n",
    "    meta_optimizer.step()\n",
    "    loss_list.append(loss.cpu().detach().numpy())\n",
    "    \n",
    "    # train_dice,train_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "    train_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "    train_mloss = np.mean(loss_list)\n",
    "    log_train = f'epoch: {epoch}, loss: {train_mloss}, dice: {train_dice}'\n",
    "    print(\"#Train# \",log_train)\n",
    "    temp_result = pd.Series([epoch,train_mloss,train_dice.item()],index=train_columns)\n",
    "    train_df = train_df.append(temp_result, ignore_index=True)\n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    \n",
    "    # validation part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in val_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach())\n",
    "        # val_dice,val_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        val_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_val = f'epoch: {epoch}, dice: {val_dice}'\n",
    "        print(\"#Val# \",log_val)\n",
    "        temp_result = pd.Series([epoch,val_dice.item()],index=val_columns)\n",
    "        val_df = val_df.append(temp_result, ignore_index=True)\n",
    "        val_df.to_csv(val_csv, index=False)\n",
    "        # logger.info(log_val)\n",
    "\n",
    "    if val_dice > best_dice_val:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_val.pth'))\n",
    "        best_dice_val = val_dice\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # test part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in test_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach())\n",
    "        # test_dice,test_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        test_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_test = f'epoch: {epoch}, dice: {test_dice}'\n",
    "        print(\"#Test# \",log_test)\n",
    "        temp_result = pd.Series([epoch,test_dice.item()],index=test_columns)\n",
    "        test_df = test_df.append(temp_result, ignore_index=True)\n",
    "        test_df.to_csv(test_csv, index=False)\n",
    "        logger.info(log_test)\n",
    "\n",
    "    if test_dice > best_dice_test:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_test.pth'))\n",
    "        best_dice_test = test_dice\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best dice in testset:tensor(0.7902)\n"
     ]
    }
   ],
   "source": [
    "best_result_test = \"Best dice in testset:\" + str(best_dice_test)\n",
    "print(best_result_test)\n",
    "logger.info(best_result_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
