{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import *\n",
    "from models.meta import Meta\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from models.basenet import *\n",
    "from utils import *\n",
    "from configs.config_setting_test import setting_config\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics as metrics\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.init as init\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = setting_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    support_images = batch['support_images'].squeeze(0)\n",
    "    support_masks = batch['support_masks'].squeeze(0)\n",
    "    query_images = batch['query_images'].squeeze(0)\n",
    "    query_masks = batch['query_masks'].squeeze(0)\n",
    "    return support_images, support_masks, query_images, query_masks\n",
    "\n",
    "# the function of copying the images\n",
    "def copy_file_to_folder(source_file, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    dest_path = os.path.join(dest_folder, os.path.basename(source_file))\n",
    "    shutil.copy(source_file, dest_path)\n",
    "\n",
    "def evaluation_api(predicted_list,groudtruth_list):\n",
    "    pre = np.array([item for sublist in predicted_list for item in sublist]).reshape(-1)\n",
    "    gts = np.array([item for sublist in groudtruth_list for item in sublist]).reshape(-1)\n",
    "    # confusion_matrix = metrics.confusion_matrix(gts,pre)\n",
    "    # TN, FP, FN, TP = confusion[0,0], confusion[0,1], confusion[1,0], confusion[1,1] \n",
    "    dice = metrics.f1_score(gts,pre)\n",
    "\n",
    "    return dice\n",
    "\n",
    "def evaluation_epoch(predicted_list,groundtruth_list):\n",
    "    TP = [0]*config.num_classes\n",
    "    FP = [0]*config.num_classes\n",
    "    FN = [0]*config.num_classes\n",
    "    dice = [0.0]*config.num_classes\n",
    "    \n",
    "    for i in range(len(predicted_list)):\n",
    "        preds = np.array(predicted_list[i]).reshape(-1)\n",
    "        gts = np.array(groundtruth_list[i]).reshape(-1)\n",
    "        for j in range(len(preds)):\n",
    "            if preds[j] == gts[j]:\n",
    "                TP[gts[j]] += 1\n",
    "            else:\n",
    "                FP[preds[j]] += 1\n",
    "                FN[gts[j]] += 1        \n",
    "    \n",
    "    for i in range(config.num_classes):\n",
    "        dice[i] = (2 * TP[i])/(FP[i]+FN[i]+2*TP[i]+1)\n",
    "\n",
    "    mdice = (2*np.sum(TP))/(np.sum(FP)+np.sum(FN)+2*np.sum(TP)+1)    \n",
    "    return dice,mdice\n",
    "\n",
    "def evaluation_basenet(base_net,query_images,query_masks,criterion):\n",
    "    predicted = base_net(query_images)\n",
    "    loss = criterion(predicted,query_masks)\n",
    "    predicted = torch.argmax(predicted,dim=1).long()\n",
    "    predict_numpy = predicted.detach().cpu().numpy().reshape(-1)\n",
    "    masks_numpy = query_masks.long().detach().cpu().numpy().reshape(-1)\n",
    "    accuracy = metrics.accuracy_score(masks_numpy,predict_numpy)\n",
    "    f1_score = metrics.f1_score(masks_numpy,predict_numpy,average=None)\n",
    "    return accuracy,f1_score,loss\n",
    "\n",
    "def initialize_weights_he(model):\n",
    "    for param in model.parameters():\n",
    "        init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "def initialize_weights_xavier(model):\n",
    "    for param in model.parameters():\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "def initialize_weights_normal(model):\n",
    "    for param in model.parameters():\n",
    "        init.normal_(param, mean=0, std=1)\n",
    "\n",
    "def remove_exsits_folder(folderpath):\n",
    "    if os.path.exists(folderpath):\n",
    "        shutil.rmtree(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Creating logger----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Creating logger----------#')\n",
    "sys.path.append(config.work_dir + '/')\n",
    "log_dir = os.path.join(config.work_dir, 'log')\n",
    "checkpoint_dir = os.path.join(config.work_dir, 'checkpoints')\n",
    "resume_model = os.path.join(checkpoint_dir, 'latest.pth')\n",
    "outputs = os.path.join(config.work_dir, 'outputs')\n",
    "csv_save = os.path.join(config.work_dir, 'csv')\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "if not os.path.exists(csv_save):\n",
    "    os.makedirs(csv_save)\n",
    "\n",
    "global logger\n",
    "logger = get_logger('test', log_dir)\n",
    "global writer\n",
    "writer = SummaryWriter(config.work_dir + 'summary')\n",
    "\n",
    "log_config_info(config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Generating data----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Generating data----------#')\n",
    "images_resources_path = \"./data/HAM10000/origin/images/\"         # the resource folder of images\n",
    "masks_resources_path = \"./data/HAM10000/origin/masks/\"           # the resource folder of masks\n",
    "ratio = [0.6,0.2]     # the ratio point of train dataset and validation set and testset\n",
    "categories = config.categories\n",
    "categories_dictionary = {}\n",
    "category_id = 1\n",
    "# prepare the csv for groundtruth\n",
    "origin_groundtruth_csv = \"./data/HAM10000/origin/groundtruth/HAM10000_groundtruth.csv\"   # read the csv file\n",
    "origin_groundtruth = pd.read_csv(origin_groundtruth_csv)    # read the csv file of groundtruth\n",
    "\n",
    "# generating the folders for each category in train folder and test folder\n",
    "# create folders for each categories\n",
    "trainset_images_path = \"./data/HAM10000/train/images/\"     # the images path for train dataset\n",
    "trainset_masks_path = \"./data/HAM10000/train/masks/\"     # the masks path for train dataset\n",
    "valset_images_path = \"./data/HAM10000/val/images/\"     # the images path for validation dataset\n",
    "valset_masks_path = \"./data/HAM10000/val/masks/\"      # the masks path for validation dataset\n",
    "testset_images_path = \"./data/HAM10000/test/images/\"     # the images path for test dataset\n",
    "testset_masks_path = \"./data/HAM10000/test/masks/\"      # the masks path for test dataset\n",
    "\n",
    "for category in categories:\n",
    "    # prepare the address for folders\n",
    "    category_images_train_path = os.path.join(trainset_images_path,category)\n",
    "    category_masks_train_path = os.path.join(trainset_masks_path,category)\n",
    "    category_images_val_path = os.path.join(valset_images_path,category)\n",
    "    category_masks_val_path = os.path.join(valset_masks_path,category)\n",
    "    category_images_test_path = os.path.join(testset_images_path,category)\n",
    "    category_masks_test_path = os.path.join(testset_masks_path,category)\n",
    "    #delete the previously exsited folders\n",
    "    remove_exsits_folder(category_images_train_path)\n",
    "    remove_exsits_folder(category_masks_train_path)\n",
    "    remove_exsits_folder(category_images_val_path)\n",
    "    remove_exsits_folder(category_masks_val_path)\n",
    "    remove_exsits_folder(category_images_test_path)\n",
    "    remove_exsits_folder(category_masks_test_path)\n",
    "    # create corresponding folder for each categories\n",
    "    os.makedirs(category_images_train_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_train_path, exist_ok=True)\n",
    "    os.makedirs(category_images_val_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_val_path, exist_ok=True)\n",
    "    os.makedirs(category_images_test_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_test_path, exist_ok=True)\n",
    "\n",
    "    # generate the data in trainset and testset for each categories\n",
    "    dest_folder_images = \"./data/HAM10000/train/images/\"+category    # the destination train set folder of copying the images\n",
    "    dest_folder_masks = \"./data/HAM10000/train/masks/\"+category    # the destination trian set folder of copying the masks\n",
    "    dest_folder_images_change_val = \"./data/HAM10000/val/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_val = \"./data/HAM10000/val/masks/\"+category      # the destination folder of test set masks\n",
    "    dest_folder_images_change_test = \"./data/HAM10000/test/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_test = \"./data/HAM10000/test/masks/\"+category      # the destination folder of test set masks\n",
    "    data_categories = origin_groundtruth[origin_groundtruth['dx'] == category]      # extract each categories \n",
    "    data_categories = data_categories.sample(frac=1,random_state=config.seed)       # random sample the datagenerating\n",
    "    length_categories = len(data_categories)\n",
    "    change_folder_point_valset = math.floor(length_categories * ratio[0])     # get the point to change directory name\n",
    "    change_folder_point_testset = math.floor(length_categories * (ratio[0]+ratio[1]))     # get the point to change directory name \n",
    "    elements_count = 0\n",
    "    for image_name in data_categories['image_id']:      # each image_id in each categories\n",
    "        if elements_count == change_folder_point_valset:\n",
    "            dest_folder_images = dest_folder_images_change_val\n",
    "            dest_folder_masks = dest_folder_masks_change_val\n",
    "        elif elements_count == change_folder_point_testset:\n",
    "            dest_folder_images = dest_folder_images_change_test\n",
    "            dest_folder_masks = dest_folder_masks_change_test\n",
    "        images_file = image_name+\".jpg\"\n",
    "        masks_file = image_name+\"_segmentation.png\"\n",
    "        source_image = images_resources_path+images_file    # the full path of source of image : path + image file name\n",
    "        source_mask = masks_resources_path+masks_file       # the full path of source of mask : path + mask file name\n",
    "        copy_file_to_folder(source_image,dest_folder_images)\n",
    "        # masks should be preprocess to the form of output for network (Width*Height*Category)\n",
    "        image = Image.open(source_mask)\n",
    "        image_array = np.array(image)\n",
    "        image_array[image_array == 255] = 1\n",
    "        image = Image.fromarray(image_array)\n",
    "        image.save(os.path.join(dest_folder_masks, masks_file))\n",
    "        elements_count +=1\n",
    "    categories_dictionary[category] = category_id       # add the category id in the categories_dictionary\n",
    "    category_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------GPU init----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------GPU init----------#')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu_id\n",
    "set_seed(config.seed)\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Datasets----------#\n",
      "trian_dataset_list length: 1\n",
      "trian_dataset(df) length: 10\n",
      "val_dataset length: 23\n",
      "test_dataset length: 23\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Datasets----------#')\n",
    "# create the dataset and dataloader\n",
    "batch_size = config.batch_size\n",
    "categories = config.categories\n",
    "num_categories = len(categories)\n",
    "train_dataset_list = []\n",
    "train_loader_list = []\n",
    "for i in range(num_categories):\n",
    "    train_dataset = HAMALL_datasets(config, train=True,categories = [categories[i]],num_eachcat=10)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "    train_dataset_list.append(train_dataset)\n",
    "    train_loader_list.append(train_loader)\n",
    "val_dataset = HAMALL_datasets(config, train=False,val=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "test_dataset = HAMALL_datasets(config, train=False)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "print(\"trian_dataset_list length:\",len(train_loader_list))\n",
    "for i in range(num_categories):\n",
    "    print(\"trian_dataset(\"+categories[i]+\") length:\",len(train_dataset_list[i]))\n",
    "print(\"val_dataset length:\",len(val_dataset))\n",
    "print(\"test_dataset length:\",len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Model----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Model----------#')\n",
    "in_channels = config.in_channels\n",
    "out_channels = config.out_channels\n",
    "base_net = smp.Unet(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# base_net = smp.UnetPlusPlus(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# initialize_weights_he(base_net)\n",
    "\n",
    "weights_dict = torch.load(\"./results/baseline_mel+bkl+bcc_Monday_11_September_2023_14h_42m_30s/checkpoints/best_test.pth\")\n",
    "base_net.load_state_dict(weights_dict,strict=False)\n",
    "base_net = base_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing loss, opt, sch and amp----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing loss, opt, sch and amp----------#')\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "meta_optimizer = get_optimizer(config, base_net)\n",
    "meta_scheduler = get_scheduler(config, meta_optimizer)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Set other params----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Set other params----------#')\n",
    "min_loss = 999\n",
    "start_epoch = 1\n",
    "min_epoch = 1\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Start training----------#\n",
      "128-resizeh, 128-resizew, 0.000100-outer_lr\n",
      "#Train#  epoch: 1, loss: 0.48310747742652893, dice: 0.7420745026270735\n",
      "#Val#  epoch: 1, dice: 0.805464896385209\n",
      "#Test#  epoch: 1, dice: 0.7815168530587485\n",
      "#Train#  epoch: 2, loss: 0.3269525170326233, dice: 0.857643940450804\n",
      "#Val#  epoch: 2, dice: 0.8067149025097096\n",
      "#Test#  epoch: 2, dice: 0.750679134367182\n",
      "#Train#  epoch: 3, loss: 0.21581681072711945, dice: 0.9447085666040145\n",
      "#Val#  epoch: 3, dice: 0.8126568574381182\n",
      "#Test#  epoch: 3, dice: 0.726532437049929\n",
      "#Train#  epoch: 4, loss: 0.2071935385465622, dice: 0.9538821961243676\n",
      "#Val#  epoch: 4, dice: 0.8163454200822194\n",
      "#Test#  epoch: 4, dice: 0.7182545559340215\n",
      "#Train#  epoch: 5, loss: 0.20144639909267426, dice: 0.9632520063559749\n",
      "#Val#  epoch: 5, dice: 0.8082610228926493\n",
      "#Test#  epoch: 5, dice: 0.6938199842656416\n",
      "#Train#  epoch: 6, loss: 0.19803202152252197, dice: 0.9677354849675555\n",
      "#Val#  epoch: 6, dice: 0.7988457376457857\n",
      "#Test#  epoch: 6, dice: 0.6738605637243738\n",
      "#Train#  epoch: 7, loss: 0.19494228065013885, dice: 0.971218725741924\n",
      "#Val#  epoch: 7, dice: 0.7845301060354332\n",
      "#Test#  epoch: 7, dice: 0.6478711064827751\n",
      "#Train#  epoch: 8, loss: 0.19284003973007202, dice: 0.9736907396564216\n",
      "#Val#  epoch: 8, dice: 0.7601823676422917\n",
      "#Test#  epoch: 8, dice: 0.6202396262281169\n",
      "#Train#  epoch: 9, loss: 0.19092701375484467, dice: 0.9753460464563655\n",
      "#Val#  epoch: 9, dice: 0.7465836655509838\n",
      "#Test#  epoch: 9, dice: 0.599623066896819\n",
      "#Train#  epoch: 10, loss: 0.18929915130138397, dice: 0.9762413452027695\n",
      "#Val#  epoch: 10, dice: 0.7413492388191469\n",
      "#Test#  epoch: 10, dice: 0.5900318755918325\n",
      "#Train#  epoch: 11, loss: 0.1875724047422409, dice: 0.9775061657471696\n",
      "#Val#  epoch: 11, dice: 0.7342979443693952\n",
      "#Test#  epoch: 11, dice: 0.5795027289266221\n",
      "#Train#  epoch: 12, loss: 0.18593788146972656, dice: 0.9788348243508619\n",
      "#Val#  epoch: 12, dice: 0.7244688963939426\n",
      "#Test#  epoch: 12, dice: 0.5707715868449873\n",
      "#Train#  epoch: 13, loss: 0.18438102304935455, dice: 0.9799041352823842\n",
      "#Val#  epoch: 13, dice: 0.7225348038921421\n",
      "#Test#  epoch: 13, dice: 0.5703205555200701\n",
      "#Train#  epoch: 14, loss: 0.18281744420528412, dice: 0.9810979847116053\n",
      "#Val#  epoch: 14, dice: 0.7186631676443347\n",
      "#Test#  epoch: 14, dice: 0.5760048737684869\n",
      "#Train#  epoch: 15, loss: 0.18130257725715637, dice: 0.9821607616173449\n",
      "#Val#  epoch: 15, dice: 0.7166486696015727\n",
      "#Test#  epoch: 15, dice: 0.5846123145023765\n",
      "#Train#  epoch: 16, loss: 0.17988811433315277, dice: 0.9830279825022566\n",
      "#Val#  epoch: 16, dice: 0.7206480854274401\n",
      "#Test#  epoch: 16, dice: 0.5977609622370572\n",
      "#Train#  epoch: 17, loss: 0.17851637303829193, dice: 0.9836289763155287\n",
      "#Val#  epoch: 17, dice: 0.7291151700754676\n",
      "#Test#  epoch: 17, dice: 0.6063778212701777\n",
      "#Train#  epoch: 18, loss: 0.17723187804222107, dice: 0.9843306112348429\n",
      "#Val#  epoch: 18, dice: 0.7355926841109056\n",
      "#Test#  epoch: 18, dice: 0.6073980210832817\n",
      "#Train#  epoch: 19, loss: 0.1760687381029129, dice: 0.9845788614669371\n",
      "#Val#  epoch: 19, dice: 0.7397706341548986\n",
      "#Test#  epoch: 19, dice: 0.6089238845144358\n",
      "#Train#  epoch: 20, loss: 0.17486971616744995, dice: 0.9848667682142787\n",
      "#Val#  epoch: 20, dice: 0.7440601668862539\n",
      "#Test#  epoch: 20, dice: 0.6060452831892368\n",
      "#Train#  epoch: 21, loss: 0.17371074855327606, dice: 0.9853971269144012\n",
      "#Val#  epoch: 21, dice: 0.7446190158437792\n",
      "#Test#  epoch: 21, dice: 0.6049717872600784\n",
      "#Train#  epoch: 22, loss: 0.17258334159851074, dice: 0.9858508301505947\n",
      "#Val#  epoch: 22, dice: 0.7425982544888543\n",
      "#Test#  epoch: 22, dice: 0.6020264961418457\n",
      "#Train#  epoch: 23, loss: 0.17147712409496307, dice: 0.986288622031264\n",
      "#Val#  epoch: 23, dice: 0.7406164908219691\n",
      "#Test#  epoch: 23, dice: 0.6005349004339243\n",
      "#Train#  epoch: 24, loss: 0.17039911448955536, dice: 0.9867218520095452\n",
      "#Val#  epoch: 24, dice: 0.7358554298260429\n",
      "#Test#  epoch: 24, dice: 0.60173347089596\n",
      "#Train#  epoch: 25, loss: 0.16932281851768494, dice: 0.9871690790646099\n",
      "#Val#  epoch: 25, dice: 0.7361836422453946\n",
      "#Test#  epoch: 25, dice: 0.6031532738027683\n",
      "#Train#  epoch: 26, loss: 0.1682802140712738, dice: 0.9873761126347785\n",
      "#Val#  epoch: 26, dice: 0.7390543697867874\n",
      "#Test#  epoch: 26, dice: 0.6055753074118526\n",
      "#Train#  epoch: 27, loss: 0.16726833581924438, dice: 0.9876545654347633\n",
      "#Val#  epoch: 27, dice: 0.7397466095041205\n",
      "#Test#  epoch: 27, dice: 0.6092838435834914\n",
      "#Train#  epoch: 28, loss: 0.1662791669368744, dice: 0.9881587147704453\n",
      "#Val#  epoch: 28, dice: 0.73854779546829\n",
      "#Test#  epoch: 28, dice: 0.6114101378330213\n",
      "#Train#  epoch: 29, loss: 0.16532154381275177, dice: 0.9883032262529785\n",
      "#Val#  epoch: 29, dice: 0.7404831418877028\n",
      "#Test#  epoch: 29, dice: 0.6144028841820639\n",
      "#Train#  epoch: 30, loss: 0.1643650382757187, dice: 0.9885948859983185\n",
      "#Val#  epoch: 30, dice: 0.740438878521483\n",
      "#Test#  epoch: 30, dice: 0.6176017117145464\n",
      "#Train#  epoch: 31, loss: 0.1634349524974823, dice: 0.9889605507854232\n",
      "#Val#  epoch: 31, dice: 0.7383518580891434\n",
      "#Test#  epoch: 31, dice: 0.6216013811968878\n",
      "#Train#  epoch: 32, loss: 0.16251029074192047, dice: 0.9892394421916725\n",
      "#Val#  epoch: 32, dice: 0.7393032211906612\n",
      "#Test#  epoch: 32, dice: 0.6269386296105985\n",
      "#Train#  epoch: 33, loss: 0.16160115599632263, dice: 0.9895917842372915\n",
      "#Val#  epoch: 33, dice: 0.7419234640817303\n",
      "#Test#  epoch: 33, dice: 0.6330132341292797\n",
      "#Train#  epoch: 34, loss: 0.16070525348186493, dice: 0.9897672393318027\n",
      "#Val#  epoch: 34, dice: 0.7448697569054041\n",
      "#Test#  epoch: 34, dice: 0.6382443028940988\n",
      "#Train#  epoch: 35, loss: 0.15982189774513245, dice: 0.9899453724962394\n",
      "#Val#  epoch: 35, dice: 0.748280787280859\n",
      "#Test#  epoch: 35, dice: 0.6434970051416152\n",
      "#Train#  epoch: 36, loss: 0.15895111858844757, dice: 0.9901452487434202\n",
      "#Val#  epoch: 36, dice: 0.7506865868395035\n",
      "#Test#  epoch: 36, dice: 0.6488926034266611\n",
      "#Train#  epoch: 37, loss: 0.15809223055839539, dice: 0.9904337933422367\n",
      "#Val#  epoch: 37, dice: 0.7525109056775203\n",
      "#Test#  epoch: 37, dice: 0.6531692841770294\n",
      "#Train#  epoch: 38, loss: 0.15724848210811615, dice: 0.9907532857976402\n",
      "#Val#  epoch: 38, dice: 0.7536472710377435\n",
      "#Test#  epoch: 38, dice: 0.6553712860455958\n",
      "#Train#  epoch: 39, loss: 0.15641430020332336, dice: 0.9908429255171869\n",
      "#Val#  epoch: 39, dice: 0.754103194103194\n",
      "#Test#  epoch: 39, dice: 0.6575374766930557\n",
      "#Train#  epoch: 40, loss: 0.15559010207653046, dice: 0.9909895653033974\n",
      "#Val#  epoch: 40, dice: 0.7549271496446124\n",
      "#Test#  epoch: 40, dice: 0.6592750198379825\n",
      "#Train#  epoch: 41, loss: 0.15477882325649261, dice: 0.9911674233207719\n",
      "#Val#  epoch: 41, dice: 0.7556105376742563\n",
      "#Test#  epoch: 41, dice: 0.6602523879244231\n",
      "#Train#  epoch: 42, loss: 0.15397293865680695, dice: 0.9913155291790307\n",
      "#Val#  epoch: 42, dice: 0.756195174543019\n",
      "#Test#  epoch: 42, dice: 0.6611393909836315\n",
      "#Train#  epoch: 43, loss: 0.1531773954629898, dice: 0.9913549229460524\n",
      "#Val#  epoch: 43, dice: 0.7569058369145406\n",
      "#Test#  epoch: 43, dice: 0.662347319033104\n",
      "#Train#  epoch: 44, loss: 0.15238605439662933, dice: 0.9915333030009298\n",
      "#Val#  epoch: 44, dice: 0.757657471539323\n",
      "#Test#  epoch: 44, dice: 0.6621654522372745\n",
      "#Train#  epoch: 45, loss: 0.1516062319278717, dice: 0.9916732594936709\n",
      "#Val#  epoch: 45, dice: 0.7573469409959851\n",
      "#Test#  epoch: 45, dice: 0.6622132593899672\n",
      "#Train#  epoch: 46, loss: 0.15083374083042145, dice: 0.991752699655868\n",
      "#Val#  epoch: 46, dice: 0.7571797590885607\n",
      "#Test#  epoch: 46, dice: 0.662666452472853\n",
      "#Train#  epoch: 47, loss: 0.15006721019744873, dice: 0.9918398433249918\n",
      "#Val#  epoch: 47, dice: 0.7569051761635494\n",
      "#Test#  epoch: 47, dice: 0.6631610915874875\n",
      "#Train#  epoch: 48, loss: 0.1493091583251953, dice: 0.9919780013254597\n",
      "#Val#  epoch: 48, dice: 0.7567591077379755\n",
      "#Test#  epoch: 48, dice: 0.6628663647248686\n",
      "#Train#  epoch: 49, loss: 0.1485583484172821, dice: 0.9919990505671872\n",
      "#Val#  epoch: 49, dice: 0.7571772087999175\n",
      "#Test#  epoch: 49, dice: 0.6641406814963648\n",
      "#Train#  epoch: 50, loss: 0.14781928062438965, dice: 0.9920850070245563\n",
      "#Val#  epoch: 50, dice: 0.7572420306453101\n",
      "#Test#  epoch: 50, dice: 0.6638943396880266\n",
      "#Train#  epoch: 51, loss: 0.14708733558654785, dice: 0.9922267494758495\n",
      "#Val#  epoch: 51, dice: 0.7580799740098004\n",
      "#Test#  epoch: 51, dice: 0.6667932999481956\n",
      "#Train#  epoch: 52, loss: 0.14636261761188507, dice: 0.9922729116579107\n",
      "#Val#  epoch: 52, dice: 0.757317978996221\n",
      "#Test#  epoch: 52, dice: 0.6648267031198629\n",
      "#Train#  epoch: 53, loss: 0.14565737545490265, dice: 0.9921298768068656\n",
      "#Val#  epoch: 53, dice: 0.7579997079707754\n",
      "#Test#  epoch: 53, dice: 0.6680085165806101\n",
      "#Train#  epoch: 54, loss: 0.1449703723192215, dice: 0.992143125729779\n",
      "#Val#  epoch: 54, dice: 0.7573301278406784\n",
      "#Test#  epoch: 54, dice: 0.6666925710535746\n",
      "#Train#  epoch: 55, loss: 0.1443333625793457, dice: 0.9922077408381622\n",
      "#Val#  epoch: 55, dice: 0.7585489098488403\n",
      "#Test#  epoch: 55, dice: 0.6702019767941555\n",
      "#Train#  epoch: 56, loss: 0.14361992478370667, dice: 0.9922902584099524\n",
      "#Val#  epoch: 56, dice: 0.7573585497665712\n",
      "#Test#  epoch: 56, dice: 0.6666148679564546\n",
      "#Train#  epoch: 57, loss: 0.1428096741437912, dice: 0.9926031406985483\n",
      "#Val#  epoch: 57, dice: 0.7583902038700759\n",
      "#Test#  epoch: 57, dice: 0.6686213725996729\n",
      "#Train#  epoch: 58, loss: 0.14208467304706573, dice: 0.9927767113257209\n",
      "#Val#  epoch: 58, dice: 0.7580554595715272\n",
      "#Test#  epoch: 58, dice: 0.6681913917639001\n",
      "#Train#  epoch: 59, loss: 0.14143550395965576, dice: 0.9927173418297679\n",
      "#Val#  epoch: 59, dice: 0.757326636755768\n",
      "#Test#  epoch: 59, dice: 0.6656185074962098\n",
      "#Train#  epoch: 60, loss: 0.1406809687614441, dice: 0.9929174827388372\n",
      "#Val#  epoch: 60, dice: 0.7574257157854293\n",
      "#Test#  epoch: 60, dice: 0.6662090521335198\n",
      "#Train#  epoch: 61, loss: 0.13999108970165253, dice: 0.9929646451153264\n",
      "#Val#  epoch: 61, dice: 0.7566320146047878\n",
      "#Test#  epoch: 61, dice: 0.6659295570864016\n",
      "#Train#  epoch: 62, loss: 0.13936184346675873, dice: 0.9929449947062723\n",
      "#Val#  epoch: 62, dice: 0.7558203313800989\n",
      "#Test#  epoch: 62, dice: 0.6635574320666883\n",
      "#Train#  epoch: 63, loss: 0.13861219584941864, dice: 0.9932717234282548\n",
      "#Val#  epoch: 63, dice: 0.7558183132189686\n",
      "#Test#  epoch: 63, dice: 0.6632910295837485\n",
      "#Train#  epoch: 64, loss: 0.13795362412929535, dice: 0.9933099776339489\n",
      "#Val#  epoch: 64, dice: 0.7552263624951772\n",
      "#Test#  epoch: 64, dice: 0.6629891233695887\n",
      "#Train#  epoch: 65, loss: 0.137314110994339, dice: 0.9932328149115518\n",
      "#Val#  epoch: 65, dice: 0.7555654569461576\n",
      "#Test#  epoch: 65, dice: 0.6634068170990515\n",
      "#Train#  epoch: 66, loss: 0.1366032212972641, dice: 0.9935465990973157\n",
      "#Val#  epoch: 66, dice: 0.7542595769010864\n",
      "#Test#  epoch: 66, dice: 0.6610012723254027\n",
      "#Train#  epoch: 67, loss: 0.1359563022851944, dice: 0.9934212478854011\n",
      "#Val#  epoch: 67, dice: 0.7550907312832772\n",
      "#Test#  epoch: 67, dice: 0.6634390116100312\n",
      "#Train#  epoch: 68, loss: 0.13527745008468628, dice: 0.9934782823834454\n",
      "#Val#  epoch: 68, dice: 0.7544463474974852\n",
      "#Test#  epoch: 68, dice: 0.6625286080865525\n",
      "#Train#  epoch: 69, loss: 0.1346011459827423, dice: 0.9937449276509829\n",
      "#Val#  epoch: 69, dice: 0.7535067084857988\n",
      "#Test#  epoch: 69, dice: 0.661606561645619\n",
      "#Train#  epoch: 70, loss: 0.1339711993932724, dice: 0.9937767752020817\n",
      "#Val#  epoch: 70, dice: 0.7545540456870988\n",
      "#Test#  epoch: 70, dice: 0.6642673922164883\n",
      "#Train#  epoch: 71, loss: 0.1333082914352417, dice: 0.9938340640742683\n",
      "#Val#  epoch: 71, dice: 0.7533202699760505\n",
      "#Test#  epoch: 71, dice: 0.6616704398587872\n",
      "#Train#  epoch: 72, loss: 0.13265740871429443, dice: 0.9940539203561713\n",
      "#Val#  epoch: 72, dice: 0.753603958780826\n",
      "#Test#  epoch: 72, dice: 0.6634335596508244\n",
      "#Train#  epoch: 73, loss: 0.1320214718580246, dice: 0.994003087519297\n",
      "#Val#  epoch: 73, dice: 0.7534198145277529\n",
      "#Test#  epoch: 73, dice: 0.6626057119090532\n",
      "#Train#  epoch: 74, loss: 0.13136474788188934, dice: 0.9940642250845849\n",
      "#Val#  epoch: 74, dice: 0.7538035886090743\n",
      "#Test#  epoch: 74, dice: 0.663324197829127\n",
      "#Train#  epoch: 75, loss: 0.1307147592306137, dice: 0.9941806377545972\n",
      "#Val#  epoch: 75, dice: 0.7530547708853801\n",
      "#Test#  epoch: 75, dice: 0.66216427097602\n",
      "#Train#  epoch: 76, loss: 0.1300741285085678, dice: 0.9942607215658336\n",
      "#Val#  epoch: 76, dice: 0.7536608575079525\n",
      "#Test#  epoch: 76, dice: 0.6630292637723333\n",
      "#Train#  epoch: 77, loss: 0.1294250786304474, dice: 0.9944182732275049\n",
      "#Val#  epoch: 77, dice: 0.753632800395762\n",
      "#Test#  epoch: 77, dice: 0.6632470197127496\n",
      "#Train#  epoch: 78, loss: 0.12878523766994476, dice: 0.9944588470443886\n",
      "#Val#  epoch: 78, dice: 0.7532252801044272\n",
      "#Test#  epoch: 78, dice: 0.662751416246557\n",
      "#Train#  epoch: 79, loss: 0.12815654277801514, dice: 0.9944390572124043\n",
      "#Val#  epoch: 79, dice: 0.7533980582524272\n",
      "#Test#  epoch: 79, dice: 0.6623686103240006\n",
      "#Train#  epoch: 80, loss: 0.12752529978752136, dice: 0.9944987533146001\n",
      "#Val#  epoch: 80, dice: 0.7530513674042165\n",
      "#Test#  epoch: 80, dice: 0.662396105386711\n",
      "#Train#  epoch: 81, loss: 0.12689730525016785, dice: 0.9945969481663269\n",
      "#Val#  epoch: 81, dice: 0.7528789140981036\n",
      "#Test#  epoch: 81, dice: 0.661976288011791\n",
      "#Train#  epoch: 82, loss: 0.12629230320453644, dice: 0.9945776933428322\n",
      "#Val#  epoch: 82, dice: 0.753202391118702\n",
      "#Test#  epoch: 82, dice: 0.6629587468673849\n",
      "#Train#  epoch: 83, loss: 0.12570010125637054, dice: 0.9944677018695011\n",
      "#Val#  epoch: 83, dice: 0.7526023084423189\n",
      "#Test#  epoch: 83, dice: 0.6616309742806566\n",
      "#Train#  epoch: 84, loss: 0.1251544952392578, dice: 0.9944595049171895\n",
      "#Val#  epoch: 84, dice: 0.7542124840487632\n",
      "#Test#  epoch: 84, dice: 0.663772865425272\n",
      "#Train#  epoch: 85, loss: 0.1246350035071373, dice: 0.9941320245010241\n",
      "#Val#  epoch: 85, dice: 0.7544124679389644\n",
      "#Test#  epoch: 85, dice: 0.6632267120706014\n",
      "#Train#  epoch: 86, loss: 0.12405722588300705, dice: 0.9942115314209949\n",
      "#Val#  epoch: 86, dice: 0.7547460542235678\n",
      "#Test#  epoch: 86, dice: 0.6636692515405387\n",
      "#Train#  epoch: 87, loss: 0.12336180359125137, dice: 0.9943503942850923\n",
      "#Val#  epoch: 87, dice: 0.7569761597206834\n",
      "#Test#  epoch: 87, dice: 0.6681691257584115\n",
      "#Train#  epoch: 88, loss: 0.12273689359426498, dice: 0.9942674970050395\n",
      "#Val#  epoch: 88, dice: 0.7540940823383573\n",
      "#Test#  epoch: 88, dice: 0.660239477251399\n",
      "#Train#  epoch: 89, loss: 0.12248826026916504, dice: 0.993592152364377\n",
      "#Val#  epoch: 89, dice: 0.7602472872460315\n",
      "#Test#  epoch: 89, dice: 0.6741882741677296\n",
      "#Train#  epoch: 90, loss: 0.12224608659744263, dice: 0.9928164478573199\n",
      "#Val#  epoch: 90, dice: 0.755973500463146\n",
      "#Test#  epoch: 90, dice: 0.6592618665832323\n",
      "#Train#  epoch: 91, loss: 0.1213393434882164, dice: 0.9935240204462988\n",
      "#Val#  epoch: 91, dice: 0.7602422208598196\n",
      "#Test#  epoch: 91, dice: 0.6669253921847645\n",
      "#Train#  epoch: 92, loss: 0.12023194134235382, dice: 0.9947427304139481\n",
      "#Val#  epoch: 92, dice: 0.7623677560286118\n",
      "#Test#  epoch: 92, dice: 0.6711964803090461\n",
      "#Train#  epoch: 93, loss: 0.1197536364197731, dice: 0.9940394859304144\n",
      "#Val#  epoch: 93, dice: 0.7592515726999768\n",
      "#Test#  epoch: 93, dice: 0.6600949726975197\n",
      "#Train#  epoch: 94, loss: 0.11916754394769669, dice: 0.9944541653073935\n",
      "#Val#  epoch: 94, dice: 0.761595621965287\n",
      "#Test#  epoch: 94, dice: 0.6693543529330775\n",
      "#Train#  epoch: 95, loss: 0.11841311305761337, dice: 0.9945362763535582\n",
      "#Val#  epoch: 95, dice: 0.7604981269180949\n",
      "#Test#  epoch: 95, dice: 0.6670580718689022\n",
      "#Train#  epoch: 96, loss: 0.11778747290372849, dice: 0.9946146078761359\n",
      "#Val#  epoch: 96, dice: 0.757852350442344\n",
      "#Test#  epoch: 96, dice: 0.6628566971984159\n",
      "#Train#  epoch: 97, loss: 0.11714816093444824, dice: 0.9947959950928015\n",
      "#Val#  epoch: 97, dice: 0.7578127528289877\n",
      "#Test#  epoch: 97, dice: 0.667765599378614\n",
      "#Train#  epoch: 98, loss: 0.11648744344711304, dice: 0.9950032157522387\n",
      "#Val#  epoch: 98, dice: 0.7561033599550422\n",
      "#Test#  epoch: 98, dice: 0.6658505778946638\n",
      "#Train#  epoch: 99, loss: 0.115885891020298, dice: 0.9950520524086608\n",
      "#Val#  epoch: 99, dice: 0.7553382515198059\n",
      "#Test#  epoch: 99, dice: 0.6654783793722555\n",
      "#Train#  epoch: 100, loss: 0.11525366455316544, dice: 0.9949337027508411\n",
      "#Val#  epoch: 100, dice: 0.7551012673989898\n",
      "#Test#  epoch: 100, dice: 0.6666061352876321\n",
      "#Train#  epoch: 101, loss: 0.11463669687509537, dice: 0.994951994457092\n",
      "#Val#  epoch: 101, dice: 0.755407312102324\n",
      "#Test#  epoch: 101, dice: 0.6675161656782241\n",
      "#Train#  epoch: 102, loss: 0.11397133022546768, dice: 0.9953687210545067\n",
      "#Val#  epoch: 102, dice: 0.7551215610831609\n",
      "#Test#  epoch: 102, dice: 0.666773277549909\n",
      "#Train#  epoch: 103, loss: 0.11335023492574692, dice: 0.9952601007352286\n",
      "#Val#  epoch: 103, dice: 0.7549306438093177\n",
      "#Test#  epoch: 103, dice: 0.666591739252599\n",
      "#Train#  epoch: 104, loss: 0.11275718361139297, dice: 0.9952889944576405\n",
      "#Val#  epoch: 104, dice: 0.7563365236250633\n",
      "#Test#  epoch: 104, dice: 0.668813838479216\n",
      "#Train#  epoch: 105, loss: 0.11212482303380966, dice: 0.9952590686395804\n",
      "#Val#  epoch: 105, dice: 0.7561249258320297\n",
      "#Test#  epoch: 105, dice: 0.667516352858834\n",
      "#Train#  epoch: 106, loss: 0.11150956153869629, dice: 0.9956076134699854\n",
      "#Val#  epoch: 106, dice: 0.7566050037989213\n",
      "#Test#  epoch: 106, dice: 0.669321713194633\n",
      "#Train#  epoch: 107, loss: 0.11087670177221298, dice: 0.9954872038477525\n",
      "#Val#  epoch: 107, dice: 0.7566783655997457\n",
      "#Test#  epoch: 107, dice: 0.6695794177083199\n",
      "#Train#  epoch: 108, loss: 0.11026477813720703, dice: 0.9955162276924905\n",
      "#Val#  epoch: 108, dice: 0.756831926522428\n",
      "#Test#  epoch: 108, dice: 0.6688178908224982\n",
      "#Train#  epoch: 109, loss: 0.10965120792388916, dice: 0.9956963503071916\n",
      "#Val#  epoch: 109, dice: 0.7573643410852713\n",
      "#Test#  epoch: 109, dice: 0.6697835557528149\n",
      "#Train#  epoch: 110, loss: 0.10904323309659958, dice: 0.9955866054464851\n",
      "#Val#  epoch: 110, dice: 0.7574076667061598\n",
      "#Test#  epoch: 110, dice: 0.6712233250406742\n",
      "#Train#  epoch: 111, loss: 0.10842552036046982, dice: 0.9957250578898411\n",
      "#Val#  epoch: 111, dice: 0.7571223037089327\n",
      "#Test#  epoch: 111, dice: 0.6704993712641896\n",
      "#Train#  epoch: 112, loss: 0.10781951248645782, dice: 0.9956558309831282\n",
      "#Val#  epoch: 112, dice: 0.7562491905193627\n",
      "#Test#  epoch: 112, dice: 0.6689705457259592\n",
      "#Train#  epoch: 113, loss: 0.10719732195138931, dice: 0.9960220075997466\n",
      "#Val#  epoch: 113, dice: 0.756685111449954\n",
      "#Test#  epoch: 113, dice: 0.6726064607079615\n",
      "#Train#  epoch: 114, loss: 0.10659628361463547, dice: 0.9958340342578941\n",
      "#Val#  epoch: 114, dice: 0.7564590178084926\n",
      "#Test#  epoch: 114, dice: 0.670612561385371\n",
      "#Train#  epoch: 115, loss: 0.10596533864736557, dice: 0.9959922021117631\n",
      "#Val#  epoch: 115, dice: 0.7563996786005103\n",
      "#Test#  epoch: 115, dice: 0.6711077618688772\n",
      "#Train#  epoch: 116, loss: 0.10535772889852524, dice: 0.9960719126915809\n",
      "#Val#  epoch: 116, dice: 0.7562475411337999\n",
      "#Test#  epoch: 116, dice: 0.6721870391628294\n",
      "#Train#  epoch: 117, loss: 0.10476652532815933, dice: 0.9960123093972948\n",
      "#Val#  epoch: 117, dice: 0.7560962463077553\n",
      "#Test#  epoch: 117, dice: 0.6712148341999241\n",
      "#Train#  epoch: 118, loss: 0.1041366383433342, dice: 0.9960513424446049\n",
      "#Val#  epoch: 118, dice: 0.7555811934939538\n",
      "#Test#  epoch: 118, dice: 0.6717522437634992\n",
      "#Train#  epoch: 119, loss: 0.10354476422071457, dice: 0.9961214232002217\n",
      "#Val#  epoch: 119, dice: 0.7560962480486624\n",
      "#Test#  epoch: 119, dice: 0.6731347386143036\n",
      "#Train#  epoch: 120, loss: 0.10294010490179062, dice: 0.9961404481038714\n",
      "#Val#  epoch: 120, dice: 0.7550229798973045\n",
      "#Test#  epoch: 120, dice: 0.6716205343120593\n",
      "#Train#  epoch: 121, loss: 0.10237386077642441, dice: 0.9960710574496512\n",
      "#Val#  epoch: 121, dice: 0.7566343355443302\n",
      "#Test#  epoch: 121, dice: 0.6738682774479184\n",
      "#Train#  epoch: 122, loss: 0.10186797380447388, dice: 0.9956939646212174\n",
      "#Val#  epoch: 122, dice: 0.7538025069577786\n",
      "#Test#  epoch: 122, dice: 0.6717427141215411\n",
      "#Train#  epoch: 123, loss: 0.10153251886367798, dice: 0.9951422211229285\n",
      "#Val#  epoch: 123, dice: 0.7591780733817114\n",
      "#Test#  epoch: 123, dice: 0.6776865146246239\n",
      "#Train#  epoch: 124, loss: 0.10169990360736847, dice: 0.9936309517913566\n",
      "#Val#  epoch: 124, dice: 0.7506057983556902\n",
      "#Test#  epoch: 124, dice: 0.6695948105344078\n",
      "#Train#  epoch: 125, loss: 0.10221250355243683, dice: 0.9918186045131229\n",
      "#Val#  epoch: 125, dice: 0.760843328455927\n",
      "#Test#  epoch: 125, dice: 0.6833721274704811\n",
      "#Train#  epoch: 126, loss: 0.10168690979480743, dice: 0.9915126517014357\n",
      "#Val#  epoch: 126, dice: 0.7574371570308344\n",
      "#Test#  epoch: 126, dice: 0.6741346207536392\n",
      "#Train#  epoch: 127, loss: 0.09955379366874695, dice: 0.9944966841532218\n",
      "#Val#  epoch: 127, dice: 0.7597144783450873\n",
      "#Test#  epoch: 127, dice: 0.6806895757735981\n",
      "#Train#  epoch: 128, loss: 0.09903272986412048, dice: 0.994676535196216\n",
      "#Val#  epoch: 128, dice: 0.7640565017285628\n",
      "#Test#  epoch: 128, dice: 0.6913500336247479\n",
      "#Train#  epoch: 129, loss: 0.09886392205953598, dice: 0.993476862162831\n",
      "#Val#  epoch: 129, dice: 0.7606613235042001\n",
      "#Test#  epoch: 129, dice: 0.6803737200345025\n",
      "#Train#  epoch: 130, loss: 0.09764563292264938, dice: 0.9951621041384292\n",
      "#Val#  epoch: 130, dice: 0.7585098001382792\n",
      "#Test#  epoch: 130, dice: 0.6827746935540908\n",
      "#Train#  epoch: 131, loss: 0.09724708646535873, dice: 0.9946240285134399\n",
      "#Val#  epoch: 131, dice: 0.7599891216825131\n",
      "#Test#  epoch: 131, dice: 0.6882357916102841\n",
      "#Train#  epoch: 132, loss: 0.09650050848722458, dice: 0.9946903356183382\n",
      "#Val#  epoch: 132, dice: 0.7606870942751047\n",
      "#Test#  epoch: 132, dice: 0.6827541251805366\n",
      "#Train#  epoch: 133, loss: 0.09589164704084396, dice: 0.9954265576431922\n",
      "#Val#  epoch: 133, dice: 0.7600363015161222\n",
      "#Test#  epoch: 133, dice: 0.6827819824739542\n",
      "#Train#  epoch: 134, loss: 0.09533210843801498, dice: 0.9956595248217834\n",
      "#Val#  epoch: 134, dice: 0.7602526683568034\n",
      "#Test#  epoch: 134, dice: 0.6858931612859382\n",
      "#Train#  epoch: 135, loss: 0.09469309449195862, dice: 0.9957157981181174\n",
      "#Val#  epoch: 135, dice: 0.7596241123391532\n",
      "#Test#  epoch: 135, dice: 0.6805829301797767\n",
      "#Train#  epoch: 136, loss: 0.0941680520772934, dice: 0.9954638195035953\n",
      "#Val#  epoch: 136, dice: 0.7583692942721596\n",
      "#Test#  epoch: 136, dice: 0.6751656440662662\n",
      "#Train#  epoch: 137, loss: 0.09354247152805328, dice: 0.9958216166976911\n",
      "#Val#  epoch: 137, dice: 0.7593605182560172\n",
      "#Test#  epoch: 137, dice: 0.6789461952607935\n",
      "#Train#  epoch: 138, loss: 0.09304565191268921, dice: 0.996091856219885\n",
      "#Val#  epoch: 138, dice: 0.7608278421086303\n",
      "#Test#  epoch: 138, dice: 0.681175822439366\n",
      "#Train#  epoch: 139, loss: 0.09244678169488907, dice: 0.9961601646774736\n",
      "#Val#  epoch: 139, dice: 0.7603509690098422\n",
      "#Test#  epoch: 139, dice: 0.6778548506647358\n",
      "#Train#  epoch: 140, loss: 0.09197956323623657, dice: 0.9960314711267257\n",
      "#Val#  epoch: 140, dice: 0.7593782117163411\n",
      "#Test#  epoch: 140, dice: 0.6750833422948704\n",
      "#Train#  epoch: 141, loss: 0.09137316793203354, dice: 0.9964774796168764\n",
      "#Val#  epoch: 141, dice: 0.7599402860490875\n",
      "#Test#  epoch: 141, dice: 0.6755811702974129\n",
      "#Train#  epoch: 142, loss: 0.0909290462732315, dice: 0.9963384463137062\n",
      "#Val#  epoch: 142, dice: 0.7602016785133169\n",
      "#Test#  epoch: 142, dice: 0.6751889786125229\n",
      "#Train#  epoch: 143, loss: 0.09038499742746353, dice: 0.9964560069691929\n",
      "#Val#  epoch: 143, dice: 0.7603857804990313\n",
      "#Test#  epoch: 143, dice: 0.6741427981272377\n",
      "#Train#  epoch: 144, loss: 0.08988805115222931, dice: 0.9964366314289108\n",
      "#Val#  epoch: 144, dice: 0.7608053748716194\n",
      "#Test#  epoch: 144, dice: 0.6748950664006055\n",
      "#Train#  epoch: 145, loss: 0.08941275626420975, dice: 0.9965278121259483\n",
      "#Val#  epoch: 145, dice: 0.7612925308318449\n",
      "#Test#  epoch: 145, dice: 0.6748653029983789\n",
      "#Train#  epoch: 146, loss: 0.08890505880117416, dice: 0.9966959480848371\n",
      "#Val#  epoch: 146, dice: 0.7610899194239671\n",
      "#Test#  epoch: 146, dice: 0.6721115057063062\n",
      "#Train#  epoch: 147, loss: 0.08844320476055145, dice: 0.9965750712701933\n",
      "#Val#  epoch: 147, dice: 0.7604131455399061\n",
      "#Test#  epoch: 147, dice: 0.6719895152528929\n",
      "#Train#  epoch: 148, loss: 0.08794788271188736, dice: 0.9965943965943966\n",
      "#Val#  epoch: 148, dice: 0.7608955624078295\n",
      "#Test#  epoch: 148, dice: 0.6730326093042689\n",
      "#Train#  epoch: 149, loss: 0.08749031275510788, dice: 0.9966943784639746\n",
      "#Val#  epoch: 149, dice: 0.7610169764088489\n",
      "#Test#  epoch: 149, dice: 0.6721106610359391\n",
      "#Train#  epoch: 150, loss: 0.08701515197753906, dice: 0.9968635909410216\n",
      "#Val#  epoch: 150, dice: 0.7603198454438124\n",
      "#Test#  epoch: 150, dice: 0.6703755335632312\n",
      "#Train#  epoch: 151, loss: 0.0865616723895073, dice: 0.9968531053319084\n",
      "#Val#  epoch: 151, dice: 0.7605975533165498\n",
      "#Test#  epoch: 151, dice: 0.6711136040039695\n",
      "#Train#  epoch: 152, loss: 0.08610501140356064, dice: 0.9968526692927413\n",
      "#Val#  epoch: 152, dice: 0.7607392258847147\n",
      "#Test#  epoch: 152, dice: 0.6712820380099553\n",
      "#Train#  epoch: 153, loss: 0.0856521874666214, dice: 0.9968035309602273\n",
      "#Val#  epoch: 153, dice: 0.7609120381304076\n",
      "#Test#  epoch: 153, dice: 0.6697236614853195\n",
      "#Train#  epoch: 154, loss: 0.08520778268575668, dice: 0.9969119917653113\n",
      "#Val#  epoch: 154, dice: 0.7610529197962022\n",
      "#Test#  epoch: 154, dice: 0.6688245462402765\n",
      "#Train#  epoch: 155, loss: 0.08476786315441132, dice: 0.9969319081551862\n",
      "#Val#  epoch: 155, dice: 0.7612800017178349\n",
      "#Test#  epoch: 155, dice: 0.6688157917480511\n",
      "#Train#  epoch: 156, loss: 0.08432809263467789, dice: 0.9971500949968334\n",
      "#Val#  epoch: 156, dice: 0.7617096583900895\n",
      "#Test#  epoch: 156, dice: 0.668964296048682\n",
      "#Train#  epoch: 157, loss: 0.08390005677938461, dice: 0.9970711628275152\n",
      "#Val#  epoch: 157, dice: 0.761596976545682\n",
      "#Test#  epoch: 157, dice: 0.6670301378161442\n",
      "#Train#  epoch: 158, loss: 0.08346149325370789, dice: 0.9970404537311068\n",
      "#Val#  epoch: 158, dice: 0.7621603632811241\n",
      "#Test#  epoch: 158, dice: 0.6664242203836713\n",
      "#Train#  epoch: 159, loss: 0.08304551988840103, dice: 0.9970008017658645\n",
      "#Val#  epoch: 159, dice: 0.7627981774323237\n",
      "#Test#  epoch: 159, dice: 0.666456055012918\n",
      "#Train#  epoch: 160, loss: 0.08261772245168686, dice: 0.9971498129564752\n",
      "#Val#  epoch: 160, dice: 0.7629989657630043\n",
      "#Test#  epoch: 160, dice: 0.6657834924345737\n",
      "#Train#  epoch: 161, loss: 0.08219971507787704, dice: 0.9972689491391252\n",
      "#Val#  epoch: 161, dice: 0.7636388952856309\n",
      "#Test#  epoch: 161, dice: 0.6661646977368125\n",
      "#Train#  epoch: 162, loss: 0.08179519325494766, dice: 0.9970704671417261\n",
      "#Val#  epoch: 162, dice: 0.7635872333352992\n",
      "#Test#  epoch: 162, dice: 0.6633789621610369\n",
      "#Train#  epoch: 163, loss: 0.08137208223342896, dice: 0.9971494180061762\n",
      "#Val#  epoch: 163, dice: 0.7632960609229614\n",
      "#Test#  epoch: 163, dice: 0.6627492166546598\n",
      "#Train#  epoch: 164, loss: 0.08097203075885773, dice: 0.9972191158569774\n",
      "#Val#  epoch: 164, dice: 0.7644166198464296\n",
      "#Test#  epoch: 164, dice: 0.6641220381867573\n",
      "#Train#  epoch: 165, loss: 0.08055903762578964, dice: 0.997278494166081\n",
      "#Val#  epoch: 165, dice: 0.764074894819668\n",
      "#Test#  epoch: 165, dice: 0.6619190827702629\n",
      "#Train#  epoch: 166, loss: 0.08017163723707199, dice: 0.9971802558546792\n",
      "#Val#  epoch: 166, dice: 0.7642151117675705\n",
      "#Test#  epoch: 166, dice: 0.6617196517995851\n",
      "#Train#  epoch: 167, loss: 0.07976438850164413, dice: 0.9971791394890778\n",
      "#Val#  epoch: 167, dice: 0.763339052112374\n",
      "#Test#  epoch: 167, dice: 0.6593343484881444\n",
      "#Train#  epoch: 168, loss: 0.07939155399799347, dice: 0.9971103414151411\n",
      "#Val#  epoch: 168, dice: 0.7646458548157012\n",
      "#Test#  epoch: 168, dice: 0.6609747204666991\n",
      "#Train#  epoch: 169, loss: 0.07904677838087082, dice: 0.9971591752699773\n",
      "#Val#  epoch: 169, dice: 0.7628277976713769\n",
      "#Test#  epoch: 169, dice: 0.6582692935669968\n",
      "#Train#  epoch: 170, loss: 0.07869239151477814, dice: 0.9969928976991711\n",
      "#Val#  epoch: 170, dice: 0.7649917579339888\n",
      "#Test#  epoch: 170, dice: 0.6625122962719004\n",
      "#Train#  epoch: 171, loss: 0.07841099053621292, dice: 0.9968126385809313\n",
      "#Val#  epoch: 171, dice: 0.7614720776744911\n",
      "#Test#  epoch: 171, dice: 0.6550264873764614\n",
      "#Train#  epoch: 172, loss: 0.07810410112142563, dice: 0.9967344838505382\n",
      "#Val#  epoch: 172, dice: 0.7645664246048697\n",
      "#Test#  epoch: 172, dice: 0.6609834016251128\n",
      "#Train#  epoch: 173, loss: 0.07776329666376114, dice: 0.9964154156929534\n",
      "#Val#  epoch: 173, dice: 0.7622267466780969\n",
      "#Test#  epoch: 173, dice: 0.6568004777618427\n",
      "#Train#  epoch: 174, loss: 0.07726644724607468, dice: 0.9969130305728703\n",
      "#Val#  epoch: 174, dice: 0.7642409463304027\n",
      "#Test#  epoch: 174, dice: 0.6587719565283571\n",
      "#Train#  epoch: 175, loss: 0.07672169059515, dice: 0.9972781170508646\n",
      "#Val#  epoch: 175, dice: 0.7647775225682388\n",
      "#Test#  epoch: 175, dice: 0.659091699714743\n",
      "#Train#  epoch: 176, loss: 0.07634687423706055, dice: 0.9972283265031379\n",
      "#Val#  epoch: 176, dice: 0.7626404042354608\n",
      "#Test#  epoch: 176, dice: 0.6541191475607466\n",
      "#Train#  epoch: 177, loss: 0.07606901228427887, dice: 0.9970019887797203\n",
      "#Val#  epoch: 177, dice: 0.7656709644697152\n",
      "#Test#  epoch: 177, dice: 0.6596071035948153\n",
      "#Train#  epoch: 178, loss: 0.0757032036781311, dice: 0.9972282716293803\n",
      "#Val#  epoch: 178, dice: 0.7636238942557557\n",
      "#Test#  epoch: 178, dice: 0.653486715920361\n",
      "#Train#  epoch: 179, loss: 0.07527114450931549, dice: 0.9973085295863844\n",
      "#Val#  epoch: 179, dice: 0.7640246186780841\n",
      "#Test#  epoch: 179, dice: 0.6549941768408379\n",
      "#Train#  epoch: 180, loss: 0.07488714903593063, dice: 0.997575913484847\n",
      "#Val#  epoch: 180, dice: 0.7650619467135386\n",
      "#Test#  epoch: 180, dice: 0.6566862529020006\n",
      "#Train#  epoch: 181, loss: 0.07458531856536865, dice: 0.9973178673581489\n",
      "#Val#  epoch: 181, dice: 0.7629366990832873\n",
      "#Test#  epoch: 181, dice: 0.6493924356928688\n",
      "#Train#  epoch: 182, loss: 0.07424720376729965, dice: 0.9972289848187954\n",
      "#Val#  epoch: 182, dice: 0.7643078567610903\n",
      "#Test#  epoch: 182, dice: 0.6543479209389589\n",
      "#Train#  epoch: 183, loss: 0.07386761158704758, dice: 0.9974071728287547\n",
      "#Val#  epoch: 183, dice: 0.7635590861400767\n",
      "#Test#  epoch: 183, dice: 0.6518804917839195\n",
      "#Train#  epoch: 184, loss: 0.0735011026263237, dice: 0.9975754337004819\n",
      "#Val#  epoch: 184, dice: 0.762945291768301\n",
      "#Test#  epoch: 184, dice: 0.6486043197017871\n",
      "#Train#  epoch: 185, loss: 0.07319038361310959, dice: 0.9974268635445944\n",
      "#Val#  epoch: 185, dice: 0.7642949159971562\n",
      "#Test#  epoch: 185, dice: 0.6527712274450208\n",
      "#Train#  epoch: 186, loss: 0.07287087291479111, dice: 0.9974665505502336\n",
      "#Val#  epoch: 186, dice: 0.763364910382941\n",
      "#Test#  epoch: 186, dice: 0.6494464621329279\n",
      "#Train#  epoch: 187, loss: 0.07250650972127914, dice: 0.9974864923704158\n",
      "#Val#  epoch: 187, dice: 0.7631012203876526\n",
      "#Test#  epoch: 187, dice: 0.6473991989436233\n",
      "#Train#  epoch: 188, loss: 0.07216718047857285, dice: 0.9975159090684165\n",
      "#Val#  epoch: 188, dice: 0.7646238587005881\n",
      "#Test#  epoch: 188, dice: 0.651584343167288\n",
      "#Train#  epoch: 189, loss: 0.07185903936624527, dice: 0.9975458179946959\n",
      "#Val#  epoch: 189, dice: 0.7637310250998962\n",
      "#Test#  epoch: 189, dice: 0.6465350707737697\n",
      "#Train#  epoch: 190, loss: 0.07154654711484909, dice: 0.9974768713204373\n",
      "#Val#  epoch: 190, dice: 0.7649670604452851\n",
      "#Test#  epoch: 190, dice: 0.6489031370848717\n",
      "#Train#  epoch: 191, loss: 0.07120891660451889, dice: 0.9975651278802755\n",
      "#Val#  epoch: 191, dice: 0.7638455569528804\n",
      "#Test#  epoch: 191, dice: 0.6464514373730148\n",
      "#Train#  epoch: 192, loss: 0.07088517397642136, dice: 0.9975754337004819\n",
      "#Val#  epoch: 192, dice: 0.7646857485132418\n",
      "#Test#  epoch: 192, dice: 0.6463891010279234\n",
      "#Train#  epoch: 193, loss: 0.07056303322315216, dice: 0.9977039705474842\n",
      "#Val#  epoch: 193, dice: 0.7655588252572887\n",
      "#Test#  epoch: 193, dice: 0.647945949735357\n",
      "#Train#  epoch: 194, loss: 0.07026230543851852, dice: 0.9977239891543135\n",
      "#Val#  epoch: 194, dice: 0.7646470427763722\n",
      "#Test#  epoch: 194, dice: 0.6447427981278429\n",
      "#Train#  epoch: 195, loss: 0.06998394429683685, dice: 0.9973974053219598\n",
      "#Val#  epoch: 195, dice: 0.7656029430636949\n",
      "#Test#  epoch: 195, dice: 0.6452406041447137\n",
      "#Train#  epoch: 196, loss: 0.06975453346967697, dice: 0.9972581587100479\n",
      "#Val#  epoch: 196, dice: 0.7653481334146054\n",
      "#Test#  epoch: 196, dice: 0.6461414169798728\n",
      "#Train#  epoch: 197, loss: 0.06963987648487091, dice: 0.9968423657510518\n",
      "#Val#  epoch: 197, dice: 0.7657989780357956\n",
      "#Test#  epoch: 197, dice: 0.6432220453885992\n",
      "#Train#  epoch: 198, loss: 0.06971973925828934, dice: 0.9962788488183366\n",
      "#Val#  epoch: 198, dice: 0.7663224374839975\n",
      "#Test#  epoch: 198, dice: 0.6501664748887616\n",
      "#Train#  epoch: 199, loss: 0.07015570998191833, dice: 0.9947600416026943\n",
      "#Val#  epoch: 199, dice: 0.7638545938633973\n",
      "#Test#  epoch: 199, dice: 0.6415355214837385\n",
      "#Train#  epoch: 200, loss: 0.0701868087053299, dice: 0.9946240285134399\n",
      "#Val#  epoch: 200, dice: 0.7686060522418562\n",
      "#Test#  epoch: 200, dice: 0.6551949352538033\n"
     ]
    }
   ],
   "source": [
    "print('#----------Start training----------#')\n",
    "torch.cuda.empty_cache()\n",
    "info = \"%d-resizeh, %d-resizew, %f-outer_lr\"%(config.resize_h,config.resize_w,config.outer_lr)\n",
    "print(info)\n",
    "logger.info(info)\n",
    "best_dice_val = 0.0\n",
    "best_dice_test = 0.0\n",
    "train_csv = os.path.join(csv_save,\"train.csv\")\n",
    "val_csv = os.path.join(csv_save,\"val.csv\")\n",
    "test_csv = os.path.join(csv_save,\"test.csv\")\n",
    "train_columns = ['Epoch','Loss',\"Mdice\"]\n",
    "train_df = pd.DataFrame(columns=train_columns)\n",
    "val_columns = ['Epoch','Mdice']\n",
    "val_df = pd.DataFrame(columns=val_columns)\n",
    "test_columns = ['Epoch','Mdice']\n",
    "test_df = pd.DataFrame(columns=test_columns)\n",
    "for epoch in range(start_epoch, config.epoch_num+1):\n",
    "    \n",
    "    # train part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    loss_list = []    \n",
    "    base_net.train()\n",
    "    meta_optimizer.zero_grad()\n",
    "    for category_index in range(num_categories):\n",
    "        for image,mask in train_loader_list[category_index]:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)     # torch.Size([bs,out_channels=1,512,512])\n",
    "            predicted = predicted.squeeze(1)    # torch.Size([bs,512,512])\n",
    "            loss = criterion(predicted,mask)\n",
    "            loss = loss/num_categories\n",
    "            loss.backward()\n",
    "            predicted = (predicted > threshold).long()\n",
    "            temp_predicted = predicted.cpu().detach().numpy()       # threshold alternative\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "    meta_optimizer.step()\n",
    "    loss_list.append(loss.cpu().detach().numpy())\n",
    "    \n",
    "    # train_dice,train_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "    train_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "    train_mloss = np.mean(loss_list)\n",
    "    log_train = f'epoch: {epoch}, loss: {train_mloss}, dice: {train_dice}'\n",
    "    print(\"#Train# \",log_train)\n",
    "    temp_result = pd.Series([epoch,train_mloss,train_dice],index=train_columns)\n",
    "    train_df = train_df.append(temp_result, ignore_index=True)\n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    \n",
    "    # validation part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in val_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "        # val_dice,val_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        val_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_val = f'epoch: {epoch}, dice: {val_dice}'\n",
    "        print(\"#Val# \",log_val)\n",
    "        temp_result = pd.Series([epoch,val_dice],index=val_columns)\n",
    "        val_df = val_df.append(temp_result, ignore_index=True)\n",
    "        val_df.to_csv(val_csv, index=False)\n",
    "        # logger.info(log_val)\n",
    "\n",
    "    if val_dice > best_dice_val:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_val.pth'))\n",
    "        best_dice_val = val_dice\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # test part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in test_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "        # test_dice,test_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        test_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_test = f'epoch: {epoch}, dice: {test_dice}'\n",
    "        print(\"#Test# \",log_test)\n",
    "        temp_result = pd.Series([epoch,test_dice],index=test_columns)\n",
    "        test_df = test_df.append(temp_result, ignore_index=True)\n",
    "        test_df.to_csv(test_csv, index=False)\n",
    "        logger.info(log_test)\n",
    "\n",
    "    if test_dice > best_dice_test:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_test.pth'))\n",
    "        best_dice_test = test_dice\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best dice in testset:0.7815168530587485\n"
     ]
    }
   ],
   "source": [
    "best_result_test = \"Best dice in testset:\" + str(best_dice_test)\n",
    "print(best_result_test)\n",
    "logger.info(best_result_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
