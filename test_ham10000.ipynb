{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import *\n",
    "from models.meta import Meta\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from models.basenet import *\n",
    "from utils import *\n",
    "from configs.config_setting_test import setting_config\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics as metrics\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.init as init\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = setting_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    support_images = batch['support_images'].squeeze(0)\n",
    "    support_masks = batch['support_masks'].squeeze(0)\n",
    "    query_images = batch['query_images'].squeeze(0)\n",
    "    query_masks = batch['query_masks'].squeeze(0)\n",
    "    return support_images, support_masks, query_images, query_masks\n",
    "\n",
    "# the function of copying the images\n",
    "def copy_file_to_folder(source_file, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    dest_path = os.path.join(dest_folder, os.path.basename(source_file))\n",
    "    shutil.copy(source_file, dest_path)\n",
    "\n",
    "def evaluation_api(predicted_list,groudtruth_list):\n",
    "    pre = np.array([item for sublist in predicted_list for item in sublist]).reshape(-1)\n",
    "    gts = np.array([item for sublist in groudtruth_list for item in sublist]).reshape(-1)\n",
    "    # confusion_matrix = metrics.confusion_matrix(gts,pre)\n",
    "    # TN, FP, FN, TP = confusion[0,0], confusion[0,1], confusion[1,0], confusion[1,1] \n",
    "    dice = metrics.f1_score(gts,pre)\n",
    "\n",
    "    return dice\n",
    "\n",
    "def evaluation_epoch(predicted_list,groundtruth_list):\n",
    "    TP = [0]*config.num_classes\n",
    "    FP = [0]*config.num_classes\n",
    "    FN = [0]*config.num_classes\n",
    "    dice = [0.0]*config.num_classes\n",
    "    \n",
    "    for i in range(len(predicted_list)):\n",
    "        preds = np.array(predicted_list[i]).reshape(-1)\n",
    "        gts = np.array(groundtruth_list[i]).reshape(-1)\n",
    "        for j in range(len(preds)):\n",
    "            if preds[j] == gts[j]:\n",
    "                TP[gts[j]] += 1\n",
    "            else:\n",
    "                FP[preds[j]] += 1\n",
    "                FN[gts[j]] += 1        \n",
    "    \n",
    "    for i in range(config.num_classes):\n",
    "        dice[i] = (2 * TP[i])/(FP[i]+FN[i]+2*TP[i]+1)\n",
    "\n",
    "    mdice = (2*np.sum(TP))/(np.sum(FP)+np.sum(FN)+2*np.sum(TP)+1)    \n",
    "    return dice,mdice\n",
    "\n",
    "def evaluation_basenet(base_net,query_images,query_masks,criterion):\n",
    "    predicted = base_net(query_images)\n",
    "    loss = criterion(predicted,query_masks)\n",
    "    predicted = torch.argmax(predicted,dim=1).long()\n",
    "    predict_numpy = predicted.detach().cpu().numpy().reshape(-1)\n",
    "    masks_numpy = query_masks.long().detach().cpu().numpy().reshape(-1)\n",
    "    accuracy = metrics.accuracy_score(masks_numpy,predict_numpy)\n",
    "    f1_score = metrics.f1_score(masks_numpy,predict_numpy,average=None)\n",
    "    return accuracy,f1_score,loss\n",
    "\n",
    "def initialize_weights_he(model):\n",
    "    for param in model.parameters():\n",
    "        init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "def initialize_weights_xavier(model):\n",
    "    for param in model.parameters():\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "def initialize_weights_normal(model):\n",
    "    for param in model.parameters():\n",
    "        init.normal_(param, mean=0, std=1)\n",
    "\n",
    "def remove_exsits_folder(folderpath):\n",
    "    if os.path.exists(folderpath):\n",
    "        shutil.rmtree(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Creating logger----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Creating logger----------#')\n",
    "sys.path.append(config.work_dir + '/')\n",
    "log_dir = os.path.join(config.work_dir, 'log')\n",
    "checkpoint_dir = os.path.join(config.work_dir, 'checkpoints')\n",
    "resume_model = os.path.join(checkpoint_dir, 'latest.pth')\n",
    "outputs = os.path.join(config.work_dir, 'outputs')\n",
    "csv_save = os.path.join(config.work_dir, 'csv')\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "if not os.path.exists(csv_save):\n",
    "    os.makedirs(csv_save)\n",
    "\n",
    "global logger\n",
    "logger = get_logger('test', log_dir)\n",
    "global writer\n",
    "writer = SummaryWriter(config.work_dir + 'summary')\n",
    "\n",
    "log_config_info(config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Generating data----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Generating data----------#')\n",
    "images_resources_path = \"./data/HAM10000/origin/images/\"         # the resource folder of images\n",
    "masks_resources_path = \"./data/HAM10000/origin/masks/\"           # the resource folder of masks\n",
    "ratio = [0.6,0.2]     # the ratio point of train dataset and validation set and testset\n",
    "categories = config.categories\n",
    "categories_dictionary = {}\n",
    "category_id = 1\n",
    "# prepare the csv for groundtruth\n",
    "origin_groundtruth_csv = \"./data/HAM10000/origin/groundtruth/HAM10000_groundtruth.csv\"   # read the csv file\n",
    "origin_groundtruth = pd.read_csv(origin_groundtruth_csv)    # read the csv file of groundtruth\n",
    "\n",
    "# generating the folders for each category in train folder and test folder\n",
    "# create folders for each categories\n",
    "trainset_images_path = \"./data/HAM10000/train/images/\"     # the images path for train dataset\n",
    "trainset_masks_path = \"./data/HAM10000/train/masks/\"     # the masks path for train dataset\n",
    "valset_images_path = \"./data/HAM10000/val/images/\"     # the images path for validation dataset\n",
    "valset_masks_path = \"./data/HAM10000/val/masks/\"      # the masks path for validation dataset\n",
    "testset_images_path = \"./data/HAM10000/test/images/\"     # the images path for test dataset\n",
    "testset_masks_path = \"./data/HAM10000/test/masks/\"      # the masks path for test dataset\n",
    "\n",
    "for category in categories:\n",
    "    # prepare the address for folders\n",
    "    category_images_train_path = os.path.join(trainset_images_path,category)\n",
    "    category_masks_train_path = os.path.join(trainset_masks_path,category)\n",
    "    category_images_val_path = os.path.join(valset_images_path,category)\n",
    "    category_masks_val_path = os.path.join(valset_masks_path,category)\n",
    "    category_images_test_path = os.path.join(testset_images_path,category)\n",
    "    category_masks_test_path = os.path.join(testset_masks_path,category)\n",
    "    #delete the previously exsited folders\n",
    "    remove_exsits_folder(category_images_train_path)\n",
    "    remove_exsits_folder(category_masks_train_path)\n",
    "    remove_exsits_folder(category_images_val_path)\n",
    "    remove_exsits_folder(category_masks_val_path)\n",
    "    remove_exsits_folder(category_images_test_path)\n",
    "    remove_exsits_folder(category_masks_test_path)\n",
    "    # create corresponding folder for each categories\n",
    "    os.makedirs(category_images_train_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_train_path, exist_ok=True)\n",
    "    os.makedirs(category_images_val_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_val_path, exist_ok=True)\n",
    "    os.makedirs(category_images_test_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_test_path, exist_ok=True)\n",
    "\n",
    "    # generate the data in trainset and testset for each categories\n",
    "    dest_folder_images = \"./data/HAM10000/train/images/\"+category    # the destination train set folder of copying the images\n",
    "    dest_folder_masks = \"./data/HAM10000/train/masks/\"+category    # the destination trian set folder of copying the masks\n",
    "    dest_folder_images_change_val = \"./data/HAM10000/val/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_val = \"./data/HAM10000/val/masks/\"+category      # the destination folder of test set masks\n",
    "    dest_folder_images_change_test = \"./data/HAM10000/test/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_test = \"./data/HAM10000/test/masks/\"+category      # the destination folder of test set masks\n",
    "    data_categories = origin_groundtruth[origin_groundtruth['dx'] == category]      # extract each categories \n",
    "    data_categories = data_categories.sample(frac=1,random_state=config.seed)       # random sample the datagenerating\n",
    "    length_categories = len(data_categories)\n",
    "    change_folder_point_valset = math.floor(length_categories * ratio[0])     # get the point to change directory name\n",
    "    change_folder_point_testset = math.floor(length_categories * (ratio[0]+ratio[1]))     # get the point to change directory name \n",
    "    elements_count = 0\n",
    "    for image_name in data_categories['image_id']:      # each image_id in each categories\n",
    "        if elements_count == change_folder_point_valset:\n",
    "            dest_folder_images = dest_folder_images_change_val\n",
    "            dest_folder_masks = dest_folder_masks_change_val\n",
    "        elif elements_count == change_folder_point_testset:\n",
    "            dest_folder_images = dest_folder_images_change_test\n",
    "            dest_folder_masks = dest_folder_masks_change_test\n",
    "        images_file = image_name+\".jpg\"\n",
    "        masks_file = image_name+\"_segmentation.png\"\n",
    "        source_image = images_resources_path+images_file    # the full path of source of image : path + image file name\n",
    "        source_mask = masks_resources_path+masks_file       # the full path of source of mask : path + mask file name\n",
    "        copy_file_to_folder(source_image,dest_folder_images)\n",
    "        # masks should be preprocess to the form of output for network (Width*Height*Category)\n",
    "        image = Image.open(source_mask)\n",
    "        image_array = np.array(image)\n",
    "        image_array[image_array == 255] = 1\n",
    "        image = Image.fromarray(image_array)\n",
    "        image.save(os.path.join(dest_folder_masks, masks_file))\n",
    "        elements_count +=1\n",
    "    categories_dictionary[category] = category_id       # add the category id in the categories_dictionary\n",
    "    category_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------GPU init----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------GPU init----------#')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu_id\n",
    "set_seed(config.seed)\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Datasets----------#\n",
      "trian_dataset_list length: 1\n",
      "trian_dataset(df) length: 10\n",
      "val_dataset length: 23\n",
      "test_dataset length: 23\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Datasets----------#')\n",
    "# create the dataset and dataloader\n",
    "batch_size = config.batch_size\n",
    "categories = config.categories\n",
    "num_categories = len(categories)\n",
    "train_dataset_list = []\n",
    "train_loader_list = []\n",
    "for i in range(num_categories):\n",
    "    train_dataset = HAMALL_datasets(config, train=True,categories = [categories[i]],num_eachcat=10)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "    train_dataset_list.append(train_dataset)\n",
    "    train_loader_list.append(train_loader)\n",
    "val_dataset = HAMALL_datasets(config, train=False,val=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "test_dataset = HAMALL_datasets(config, train=False)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "print(\"trian_dataset_list length:\",len(train_loader_list))\n",
    "for i in range(num_categories):\n",
    "    print(\"trian_dataset(\"+categories[i]+\") length:\",len(train_dataset_list[i]))\n",
    "print(\"val_dataset length:\",len(val_dataset))\n",
    "print(\"test_dataset length:\",len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Model----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Model----------#')\n",
    "in_channels = config.in_channels\n",
    "out_channels = config.out_channels\n",
    "base_net = smp.Unet(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# base_net = smp.UnetPlusPlus(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# initialize_weights_he(base_net)\n",
    "\n",
    "weights_dict = torch.load(\"./results/baseline_mel+bkl+bcc_Monday_11_September_2023_14h_42m_30s/checkpoints/best_test.pth\")\n",
    "base_net.load_state_dict(weights_dict,strict=False)\n",
    "base_net = base_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing loss, opt, sch and amp----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing loss, opt, sch and amp----------#')\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "meta_optimizer = get_optimizer(config, base_net)\n",
    "meta_scheduler = get_scheduler(config, meta_optimizer)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Set other params----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Set other params----------#')\n",
    "min_loss = 999\n",
    "start_epoch = 1\n",
    "min_epoch = 1\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Start training----------#\n",
      "128-resizeh, 128-resizew, 0.000100-outer_lr\n",
      "#Train#  epoch: 1, loss: 1.0896244049072266, dice: 0.7523424672349547\n",
      "#Val#  epoch: 1, dice: 0.8628144107448065\n",
      "#Test#  epoch: 1, dice: 0.8441860068550382\n",
      "#Train#  epoch: 2, loss: 0.6339432001113892, dice: 0.8187179695761815\n",
      "#Val#  epoch: 2, dice: 0.8645912822823099\n",
      "#Test#  epoch: 2, dice: 0.843534087001528\n",
      "#Train#  epoch: 3, loss: 0.12217684835195541, dice: 0.9434573181700078\n",
      "#Val#  epoch: 3, dice: 0.8732322101570954\n",
      "#Test#  epoch: 3, dice: 0.8375222468203325\n",
      "#Train#  epoch: 4, loss: 0.053245335817337036, dice: 0.9690467185540538\n",
      "#Val#  epoch: 4, dice: 0.876610060575133\n",
      "#Test#  epoch: 4, dice: 0.831999881962811\n",
      "#Train#  epoch: 5, loss: 0.042261261492967606, dice: 0.9727770956245695\n",
      "#Val#  epoch: 5, dice: 0.8750877628706938\n",
      "#Test#  epoch: 5, dice: 0.826872766060969\n",
      "#Train#  epoch: 6, loss: 0.03353222459554672, dice: 0.9767158697366188\n",
      "#Val#  epoch: 6, dice: 0.8751778865867484\n",
      "#Test#  epoch: 6, dice: 0.8211341749508256\n",
      "#Train#  epoch: 7, loss: 0.027040598914027214, dice: 0.9799158339815314\n",
      "#Val#  epoch: 7, dice: 0.8744738314800846\n",
      "#Test#  epoch: 7, dice: 0.8155644285342757\n",
      "#Train#  epoch: 8, loss: 0.022960811853408813, dice: 0.9827541571243651\n",
      "#Val#  epoch: 8, dice: 0.8727494299866343\n",
      "#Test#  epoch: 8, dice: 0.8107263172079234\n",
      "#Train#  epoch: 9, loss: 0.021037358790636063, dice: 0.984476157326836\n",
      "#Val#  epoch: 9, dice: 0.8707877971206912\n",
      "#Test#  epoch: 9, dice: 0.8080207285946324\n",
      "#Train#  epoch: 10, loss: 0.02018180675804615, dice: 0.9854102317081649\n",
      "#Val#  epoch: 10, dice: 0.8702506103333167\n",
      "#Test#  epoch: 10, dice: 0.805565792178875\n",
      "#Train#  epoch: 11, loss: 0.01940712332725525, dice: 0.9862853286757702\n",
      "#Val#  epoch: 11, dice: 0.8695713112948762\n",
      "#Test#  epoch: 11, dice: 0.803620113643877\n",
      "#Train#  epoch: 12, loss: 0.01842297613620758, dice: 0.9872686678243612\n",
      "#Val#  epoch: 12, dice: 0.8681239128467579\n",
      "#Test#  epoch: 12, dice: 0.801354208108087\n",
      "#Train#  epoch: 13, loss: 0.017338952049613, dice: 0.9882317920222266\n",
      "#Val#  epoch: 13, dice: 0.8665359978985228\n",
      "#Test#  epoch: 13, dice: 0.7980952977663607\n",
      "#Train#  epoch: 14, loss: 0.016442760825157166, dice: 0.989242830207403\n",
      "#Val#  epoch: 14, dice: 0.8652246256239601\n",
      "#Test#  epoch: 14, dice: 0.7952467432407997\n",
      "#Train#  epoch: 15, loss: 0.015815667808055878, dice: 0.9896182781825039\n",
      "#Val#  epoch: 15, dice: 0.86317099671994\n",
      "#Test#  epoch: 15, dice: 0.7918410868019905\n",
      "#Train#  epoch: 16, loss: 0.015416569076478481, dice: 0.9898223629990767\n",
      "#Val#  epoch: 16, dice: 0.8601456293267334\n",
      "#Test#  epoch: 16, dice: 0.7893779065848892\n",
      "#Train#  epoch: 17, loss: 0.015146289952099323, dice: 0.9900577070152263\n",
      "#Val#  epoch: 17, dice: 0.858060273522189\n",
      "#Test#  epoch: 17, dice: 0.7873117860593458\n",
      "#Train#  epoch: 18, loss: 0.01490388996899128, dice: 0.99031440917896\n",
      "#Val#  epoch: 18, dice: 0.8567032062168698\n",
      "#Test#  epoch: 18, dice: 0.7854927567429661\n",
      "#Train#  epoch: 19, loss: 0.014653339050710201, dice: 0.9903908260709708\n",
      "#Val#  epoch: 19, dice: 0.8543629216149567\n",
      "#Test#  epoch: 19, dice: 0.7839556250024976\n",
      "#Train#  epoch: 20, loss: 0.014395068399608135, dice: 0.9904381361323155\n",
      "#Val#  epoch: 20, dice: 0.8515590666797646\n",
      "#Test#  epoch: 20, dice: 0.7820489711884706\n",
      "#Train#  epoch: 21, loss: 0.014156150631606579, dice: 0.9904655856357436\n",
      "#Val#  epoch: 21, dice: 0.849218559787817\n",
      "#Test#  epoch: 21, dice: 0.7809926302536508\n",
      "#Train#  epoch: 22, loss: 0.01394835114479065, dice: 0.9906356243911167\n",
      "#Val#  epoch: 22, dice: 0.8468748215036791\n",
      "#Test#  epoch: 22, dice: 0.7799234928369867\n",
      "#Train#  epoch: 23, loss: 0.013769743032753468, dice: 0.9909343936381709\n",
      "#Val#  epoch: 23, dice: 0.8439884378010991\n",
      "#Test#  epoch: 23, dice: 0.7790682259172514\n",
      "#Train#  epoch: 24, loss: 0.013608060777187347, dice: 0.9911434052662446\n",
      "#Val#  epoch: 24, dice: 0.8412909691664447\n",
      "#Test#  epoch: 24, dice: 0.7784250113567383\n",
      "#Train#  epoch: 25, loss: 0.013452241197228432, dice: 0.991403214104692\n",
      "#Val#  epoch: 25, dice: 0.838201059861789\n",
      "#Test#  epoch: 25, dice: 0.7772956349525818\n",
      "#Train#  epoch: 26, loss: 0.013294455595314503, dice: 0.9916026513758732\n",
      "#Val#  epoch: 26, dice: 0.8347170681594229\n",
      "#Test#  epoch: 26, dice: 0.775870133221509\n",
      "#Train#  epoch: 27, loss: 0.013134456239640713, dice: 0.9919020696918812\n",
      "#Val#  epoch: 27, dice: 0.8317998834823045\n",
      "#Test#  epoch: 27, dice: 0.7743069018999613\n",
      "#Train#  epoch: 28, loss: 0.012979382649064064, dice: 0.992002702192551\n",
      "#Val#  epoch: 28, dice: 0.8291494745241319\n",
      "#Test#  epoch: 28, dice: 0.7725831243426908\n",
      "#Train#  epoch: 29, loss: 0.012841987423598766, dice: 0.9920723226703755\n",
      "#Val#  epoch: 29, dice: 0.8258966341732574\n",
      "#Test#  epoch: 29, dice: 0.7710017660115682\n",
      "#Train#  epoch: 30, loss: 0.012715034186840057, dice: 0.9922110952153871\n",
      "#Val#  epoch: 30, dice: 0.8223216165017891\n",
      "#Test#  epoch: 30, dice: 0.7697310798974926\n",
      "#Train#  epoch: 31, loss: 0.012594424188137054, dice: 0.9923712650985378\n",
      "#Val#  epoch: 31, dice: 0.8200732330549775\n",
      "#Test#  epoch: 31, dice: 0.7685389245374147\n",
      "#Train#  epoch: 32, loss: 0.012477753683924675, dice: 0.9926699906636738\n",
      "#Val#  epoch: 32, dice: 0.8185265867385422\n",
      "#Test#  epoch: 32, dice: 0.7677859434000569\n",
      "#Train#  epoch: 33, loss: 0.012356184422969818, dice: 0.9928391947321898\n",
      "#Val#  epoch: 33, dice: 0.8169376979936642\n",
      "#Test#  epoch: 33, dice: 0.7674287361501889\n",
      "#Train#  epoch: 34, loss: 0.012231781147420406, dice: 0.9929292126797489\n",
      "#Val#  epoch: 34, dice: 0.8152260111022998\n",
      "#Test#  epoch: 34, dice: 0.7668593292417921\n",
      "#Train#  epoch: 35, loss: 0.012105194851756096, dice: 0.9929596345762375\n",
      "#Val#  epoch: 35, dice: 0.8138201872542221\n",
      "#Test#  epoch: 35, dice: 0.7666437858190192\n",
      "#Train#  epoch: 36, loss: 0.01197880320250988, dice: 0.9930690709774795\n",
      "#Val#  epoch: 36, dice: 0.8127698118004757\n",
      "#Test#  epoch: 36, dice: 0.766453447050462\n",
      "#Train#  epoch: 37, loss: 0.011857411824166775, dice: 0.993149188824242\n",
      "#Val#  epoch: 37, dice: 0.8118255336073181\n",
      "#Test#  epoch: 37, dice: 0.7665782816490776\n",
      "#Train#  epoch: 38, loss: 0.0117459362372756, dice: 0.9932291563250799\n",
      "#Val#  epoch: 38, dice: 0.8107382550335571\n",
      "#Test#  epoch: 38, dice: 0.7665696458944787\n",
      "#Train#  epoch: 39, loss: 0.011642459779977798, dice: 0.9933686739333293\n",
      "#Val#  epoch: 39, dice: 0.8095215344024886\n",
      "#Test#  epoch: 39, dice: 0.7666045707467339\n",
      "#Train#  epoch: 40, loss: 0.011542766354978085, dice: 0.9932985852568876\n",
      "#Val#  epoch: 40, dice: 0.8086848911998555\n",
      "#Test#  epoch: 40, dice: 0.7663200110410222\n",
      "#Train#  epoch: 41, loss: 0.01144278235733509, dice: 0.9933386941457942\n",
      "#Val#  epoch: 41, dice: 0.808228056567889\n",
      "#Test#  epoch: 41, dice: 0.7659249634562286\n",
      "#Train#  epoch: 42, loss: 0.011342880316078663, dice: 0.9933686739333293\n",
      "#Val#  epoch: 42, dice: 0.8078723506001498\n",
      "#Test#  epoch: 42, dice: 0.7657270951524282\n",
      "#Train#  epoch: 43, loss: 0.011244704015552998, dice: 0.9935084271335834\n",
      "#Val#  epoch: 43, dice: 0.8077530006216428\n",
      "#Test#  epoch: 43, dice: 0.7656640230011086\n",
      "#Train#  epoch: 44, loss: 0.011147846467792988, dice: 0.9935784824574464\n",
      "#Val#  epoch: 44, dice: 0.807696189621193\n",
      "#Test#  epoch: 44, dice: 0.7657746541776798\n",
      "#Train#  epoch: 45, loss: 0.011052146553993225, dice: 0.9936280445441371\n",
      "#Val#  epoch: 45, dice: 0.8077364262044352\n",
      "#Test#  epoch: 45, dice: 0.7657859163848779\n",
      "#Train#  epoch: 46, loss: 0.01096039917320013, dice: 0.993697708347807\n",
      "#Val#  epoch: 46, dice: 0.8075495739428208\n",
      "#Test#  epoch: 46, dice: 0.7657772852555905\n",
      "#Train#  epoch: 47, loss: 0.01087143737822771, dice: 0.9937374078227815\n",
      "#Val#  epoch: 47, dice: 0.8074683201588372\n",
      "#Test#  epoch: 47, dice: 0.7659705708094245\n",
      "#Train#  epoch: 48, loss: 0.010786699131131172, dice: 0.9938365341670388\n",
      "#Val#  epoch: 48, dice: 0.8072892890129839\n",
      "#Test#  epoch: 48, dice: 0.7662065300724887\n",
      "#Train#  epoch: 49, loss: 0.010703898966312408, dice: 0.9939061910716767\n",
      "#Val#  epoch: 49, dice: 0.8071173772719552\n",
      "#Test#  epoch: 49, dice: 0.7663800794873874\n",
      "#Train#  epoch: 50, loss: 0.010623408481478691, dice: 0.9939857086145296\n",
      "#Val#  epoch: 50, dice: 0.8067459748698104\n",
      "#Test#  epoch: 50, dice: 0.7665682680766861\n",
      "#Train#  epoch: 51, loss: 0.01054378878325224, dice: 0.9940252883145755\n",
      "#Val#  epoch: 51, dice: 0.8062724946649821\n",
      "#Test#  epoch: 51, dice: 0.7668361018556802\n",
      "#Train#  epoch: 52, loss: 0.010465462692081928, dice: 0.9940654585872218\n",
      "#Val#  epoch: 52, dice: 0.8060824796985299\n",
      "#Test#  epoch: 52, dice: 0.7669882847799396\n",
      "#Train#  epoch: 53, loss: 0.010388839989900589, dice: 0.9940958750508548\n",
      "#Val#  epoch: 53, dice: 0.805629436153891\n",
      "#Test#  epoch: 53, dice: 0.767333049766057\n",
      "#Train#  epoch: 54, loss: 0.010315023362636566, dice: 0.9941058564369207\n",
      "#Val#  epoch: 54, dice: 0.8056301833897909\n",
      "#Test#  epoch: 54, dice: 0.7674685179859612\n",
      "#Train#  epoch: 55, loss: 0.010243008844554424, dice: 0.9942352532618941\n",
      "#Val#  epoch: 55, dice: 0.8053968523670963\n",
      "#Test#  epoch: 55, dice: 0.7676297301127736\n",
      "#Train#  epoch: 56, loss: 0.010172917507588863, dice: 0.9943049905744616\n",
      "#Val#  epoch: 56, dice: 0.805185287463755\n",
      "#Test#  epoch: 56, dice: 0.7677688660720432\n",
      "#Train#  epoch: 57, loss: 0.010103888809680939, dice: 0.9943349240522655\n",
      "#Val#  epoch: 57, dice: 0.8049878914050219\n",
      "#Test#  epoch: 57, dice: 0.7677520961623325\n",
      "#Train#  epoch: 58, loss: 0.010037033818662167, dice: 0.9943250590312915\n",
      "#Val#  epoch: 58, dice: 0.804741773066219\n",
      "#Test#  epoch: 58, dice: 0.7678606848366846\n",
      "#Train#  epoch: 59, loss: 0.00997109990566969, dice: 0.994374832584303\n",
      "#Val#  epoch: 59, dice: 0.8045112382530905\n",
      "#Test#  epoch: 59, dice: 0.7679610785956561\n",
      "#Train#  epoch: 60, loss: 0.009906508959829807, dice: 0.9944048729191881\n",
      "#Val#  epoch: 60, dice: 0.8043712711643797\n",
      "#Test#  epoch: 60, dice: 0.7679285610194466\n",
      "#Train#  epoch: 61, loss: 0.00984346866607666, dice: 0.9944646152014761\n",
      "#Val#  epoch: 61, dice: 0.8041231635716373\n",
      "#Test#  epoch: 61, dice: 0.7680327669804677\n",
      "#Train#  epoch: 62, loss: 0.009782539680600166, dice: 0.9945538415753186\n",
      "#Val#  epoch: 62, dice: 0.8040954470827644\n",
      "#Test#  epoch: 62, dice: 0.768086440986625\n",
      "#Train#  epoch: 63, loss: 0.00972286332398653, dice: 0.9946034958236613\n",
      "#Val#  epoch: 63, dice: 0.8040573210841484\n",
      "#Test#  epoch: 63, dice: 0.7682048459932344\n",
      "#Train#  epoch: 64, loss: 0.009663998149335384, dice: 0.9947032217108396\n",
      "#Val#  epoch: 64, dice: 0.8040339849416316\n",
      "#Test#  epoch: 64, dice: 0.7681724746289432\n",
      "#Train#  epoch: 65, loss: 0.009607291780412197, dice: 0.9946935658245802\n",
      "#Val#  epoch: 65, dice: 0.8039571976579851\n",
      "#Test#  epoch: 65, dice: 0.7682802485919596\n",
      "#Train#  epoch: 66, loss: 0.00955136027187109, dice: 0.9947731217455987\n",
      "#Val#  epoch: 66, dice: 0.8039865697649708\n",
      "#Test#  epoch: 66, dice: 0.7682472892053731\n",
      "#Train#  epoch: 67, loss: 0.009497319348156452, dice: 0.9948427024239298\n",
      "#Val#  epoch: 67, dice: 0.8039493740805065\n",
      "#Test#  epoch: 67, dice: 0.7683308657556855\n",
      "#Train#  epoch: 68, loss: 0.009443718940019608, dice: 0.9949224483319449\n",
      "#Val#  epoch: 68, dice: 0.8039258381972586\n",
      "#Test#  epoch: 68, dice: 0.7684317817793525\n",
      "#Train#  epoch: 69, loss: 0.009391341358423233, dice: 0.9948627419866709\n",
      "#Val#  epoch: 69, dice: 0.8038572232665329\n",
      "#Test#  epoch: 69, dice: 0.7685545018905311\n",
      "#Train#  epoch: 70, loss: 0.00934073980897665, dice: 0.9948923424808339\n",
      "#Val#  epoch: 70, dice: 0.8039495686794956\n",
      "#Test#  epoch: 70, dice: 0.7686659496526794\n",
      "#Train#  epoch: 71, loss: 0.009291160851716995, dice: 0.9949419815531092\n",
      "#Val#  epoch: 71, dice: 0.8037346468646164\n",
      "#Test#  epoch: 71, dice: 0.7687238472578787\n",
      "#Train#  epoch: 72, loss: 0.009243185631930828, dice: 0.9949517490354766\n",
      "#Val#  epoch: 72, dice: 0.803743079919958\n",
      "#Test#  epoch: 72, dice: 0.7688147049192918\n",
      "#Train#  epoch: 73, loss: 0.009195922873914242, dice: 0.9950014876524843\n",
      "#Val#  epoch: 73, dice: 0.8037087554864425\n",
      "#Test#  epoch: 73, dice: 0.7689304062766529\n",
      "#Train#  epoch: 74, loss: 0.009148969314992428, dice: 0.9950711558486637\n",
      "#Val#  epoch: 74, dice: 0.8035955914737362\n",
      "#Test#  epoch: 74, dice: 0.7690286910588492\n",
      "#Train#  epoch: 75, loss: 0.009102878160774708, dice: 0.9951207901939784\n",
      "#Val#  epoch: 75, dice: 0.8034450187321567\n",
      "#Test#  epoch: 75, dice: 0.7691138851732263\n",
      "#Train#  epoch: 76, loss: 0.009057629853487015, dice: 0.9951705193427146\n",
      "#Val#  epoch: 76, dice: 0.8033663744614014\n",
      "#Test#  epoch: 76, dice: 0.7692344990605492\n",
      "#Train#  epoch: 77, loss: 0.009013039059937, dice: 0.9952104715156925\n",
      "#Val#  epoch: 77, dice: 0.8032784276279145\n",
      "#Test#  epoch: 77, dice: 0.7693252426007772\n",
      "#Train#  epoch: 78, loss: 0.008969685062766075, dice: 0.9952503247429324\n",
      "#Val#  epoch: 78, dice: 0.8034409240854079\n",
      "#Test#  epoch: 78, dice: 0.7694873907494467\n",
      "#Train#  epoch: 79, loss: 0.008926848880946636, dice: 0.9952801189885968\n",
      "#Val#  epoch: 79, dice: 0.8033132003033211\n",
      "#Test#  epoch: 79, dice: 0.7694942225130149\n",
      "#Train#  epoch: 80, loss: 0.008885042741894722, dice: 0.9952801189885968\n",
      "#Val#  epoch: 80, dice: 0.8033317957445907\n",
      "#Test#  epoch: 80, dice: 0.7694855153529586\n",
      "#Train#  epoch: 81, loss: 0.00884398352354765, dice: 0.9953197818542389\n",
      "#Val#  epoch: 81, dice: 0.8032909419579195\n",
      "#Test#  epoch: 81, dice: 0.76954513148543\n",
      "#Train#  epoch: 82, loss: 0.008803268894553185, dice: 0.9953199674777401\n",
      "#Val#  epoch: 82, dice: 0.8032288155356272\n",
      "#Test#  epoch: 82, dice: 0.7696177590432469\n",
      "#Train#  epoch: 83, loss: 0.008763588033616543, dice: 0.9953994725257292\n",
      "#Val#  epoch: 83, dice: 0.8031627926696131\n",
      "#Test#  epoch: 83, dice: 0.7697313707600263\n",
      "#Train#  epoch: 84, loss: 0.008724361658096313, dice: 0.995439132245335\n",
      "#Val#  epoch: 84, dice: 0.803169135377196\n",
      "#Test#  epoch: 84, dice: 0.7697816170831148\n",
      "#Train#  epoch: 85, loss: 0.008685959503054619, dice: 0.9954292626339741\n",
      "#Val#  epoch: 85, dice: 0.8031558645246067\n",
      "#Test#  epoch: 85, dice: 0.7698827518011018\n",
      "#Train#  epoch: 86, loss: 0.0086483433842659, dice: 0.9954691016527368\n",
      "#Val#  epoch: 86, dice: 0.803142348603636\n",
      "#Test#  epoch: 86, dice: 0.7698659326999912\n",
      "#Train#  epoch: 87, loss: 0.0086105577647686, dice: 0.9954790609137055\n",
      "#Val#  epoch: 87, dice: 0.8030929746047719\n",
      "#Test#  epoch: 87, dice: 0.7699322511267942\n",
      "#Train#  epoch: 88, loss: 0.008573892526328564, dice: 0.995518807130252\n",
      "#Val#  epoch: 88, dice: 0.8031687027064237\n",
      "#Test#  epoch: 88, dice: 0.7700134754577218\n",
      "#Train#  epoch: 89, loss: 0.008537796325981617, dice: 0.9955486819538213\n",
      "#Val#  epoch: 89, dice: 0.8031303445391055\n",
      "#Test#  epoch: 89, dice: 0.7699768028240039\n",
      "#Train#  epoch: 90, loss: 0.008502027951180935, dice: 0.9955586398334489\n",
      "#Val#  epoch: 90, dice: 0.8031996273101214\n",
      "#Test#  epoch: 90, dice: 0.7701081739495188\n",
      "#Train#  epoch: 91, loss: 0.008466722443699837, dice: 0.9955884248198194\n",
      "#Val#  epoch: 91, dice: 0.8030280571731075\n",
      "#Test#  epoch: 91, dice: 0.7701279688325516\n",
      "#Train#  epoch: 92, loss: 0.008432307280600071, dice: 0.9956381228066697\n",
      "#Val#  epoch: 92, dice: 0.8031291019181098\n",
      "#Test#  epoch: 92, dice: 0.7702017146958955\n",
      "#Train#  epoch: 93, loss: 0.008398327976465225, dice: 0.9956879033297318\n",
      "#Val#  epoch: 93, dice: 0.802932380574302\n",
      "#Test#  epoch: 93, dice: 0.7701352904409541\n",
      "#Train#  epoch: 94, loss: 0.008365016430616379, dice: 0.9957871155123362\n",
      "#Val#  epoch: 94, dice: 0.8029955014554115\n",
      "#Test#  epoch: 94, dice: 0.7701891402605466\n",
      "#Train#  epoch: 95, loss: 0.008331822231411934, dice: 0.9957769935366192\n",
      "#Val#  epoch: 95, dice: 0.8030855347043294\n",
      "#Test#  epoch: 95, dice: 0.7702522383787728\n",
      "#Train#  epoch: 96, loss: 0.008299480192363262, dice: 0.9957970698439761\n",
      "#Val#  epoch: 96, dice: 0.8030873732991939\n",
      "#Test#  epoch: 96, dice: 0.7702980514193116\n",
      "#Train#  epoch: 97, loss: 0.008267475292086601, dice: 0.9958168949862215\n",
      "#Val#  epoch: 97, dice: 0.8030524985324528\n",
      "#Test#  epoch: 97, dice: 0.7703146600889125\n",
      "#Train#  epoch: 98, loss: 0.008236073888838291, dice: 0.9957574195594854\n",
      "#Val#  epoch: 98, dice: 0.8031518548877549\n",
      "#Test#  epoch: 98, dice: 0.7703944902737535\n",
      "#Train#  epoch: 99, loss: 0.008204469457268715, dice: 0.9957970698439761\n",
      "#Val#  epoch: 99, dice: 0.8031768357489198\n",
      "#Test#  epoch: 99, dice: 0.7704030850939511\n",
      "#Train#  epoch: 100, loss: 0.008173611015081406, dice: 0.995846756207563\n",
      "#Val#  epoch: 100, dice: 0.803083495474156\n",
      "#Test#  epoch: 100, dice: 0.7704277960665488\n",
      "#Train#  epoch: 101, loss: 0.008143211714923382, dice: 0.9958964396162081\n",
      "#Val#  epoch: 101, dice: 0.8030979884221935\n",
      "#Test#  epoch: 101, dice: 0.7704346004142122\n",
      "#Train#  epoch: 102, loss: 0.008113180287182331, dice: 0.9959559916741006\n",
      "#Val#  epoch: 102, dice: 0.8031125607261232\n",
      "#Test#  epoch: 102, dice: 0.7704939828449641\n",
      "#Train#  epoch: 103, loss: 0.00808330625295639, dice: 0.9959659434439146\n",
      "#Val#  epoch: 103, dice: 0.8030085997748307\n",
      "#Test#  epoch: 103, dice: 0.7705013798521444\n",
      "#Train#  epoch: 104, loss: 0.008053681813180447, dice: 0.9959558313343775\n",
      "#Val#  epoch: 104, dice: 0.802944938321195\n",
      "#Test#  epoch: 104, dice: 0.7704709342142367\n",
      "#Train#  epoch: 105, loss: 0.00802487414330244, dice: 0.9959757354690348\n",
      "#Val#  epoch: 105, dice: 0.8029568883980703\n",
      "#Test#  epoch: 105, dice: 0.7705413929358312\n",
      "#Train#  epoch: 106, loss: 0.007996032945811749, dice: 0.9959559916741006\n",
      "#Val#  epoch: 106, dice: 0.8029801062059126\n",
      "#Test#  epoch: 106, dice: 0.7705438346343153\n",
      "#Train#  epoch: 107, loss: 0.007967478595674038, dice: 0.9960355217253409\n",
      "#Val#  epoch: 107, dice: 0.8029416892523734\n",
      "#Test#  epoch: 107, dice: 0.7705351173262661\n",
      "#Train#  epoch: 108, loss: 0.0079394755885005, dice: 0.9960157783107693\n",
      "#Val#  epoch: 108, dice: 0.8030323040756492\n",
      "#Test#  epoch: 108, dice: 0.7705313523244902\n",
      "#Train#  epoch: 109, loss: 0.007911483757197857, dice: 0.9960555786803036\n",
      "#Val#  epoch: 109, dice: 0.8029810069084993\n",
      "#Test#  epoch: 109, dice: 0.7706513641397362\n",
      "#Train#  epoch: 110, loss: 0.007883833721280098, dice: 0.9960258862471878\n",
      "#Val#  epoch: 110, dice: 0.8029993399339934\n",
      "#Test#  epoch: 110, dice: 0.7706198125782769\n",
      "#Train#  epoch: 111, loss: 0.007856613025069237, dice: 0.9960853492958583\n",
      "#Val#  epoch: 111, dice: 0.8030329431270361\n",
      "#Test#  epoch: 111, dice: 0.7707429031608616\n",
      "#Train#  epoch: 112, loss: 0.00782963540405035, dice: 0.9961052475100342\n",
      "#Val#  epoch: 112, dice: 0.8030662182779974\n",
      "#Test#  epoch: 112, dice: 0.7708114419147695\n",
      "#Train#  epoch: 113, loss: 0.007802601438015699, dice: 0.9961549895946884\n",
      "#Val#  epoch: 113, dice: 0.8029856734129371\n",
      "#Test#  epoch: 113, dice: 0.7708106889527628\n",
      "#Train#  epoch: 114, loss: 0.007775889243930578, dice: 0.9961452707724323\n",
      "#Val#  epoch: 114, dice: 0.8031389684889361\n",
      "#Test#  epoch: 114, dice: 0.7708452416413741\n",
      "#Train#  epoch: 115, loss: 0.0077498010359704494, dice: 0.9961850593049871\n",
      "#Val#  epoch: 115, dice: 0.8030941815246124\n",
      "#Test#  epoch: 115, dice: 0.7708712383467242\n",
      "#Train#  epoch: 116, loss: 0.007723551243543625, dice: 0.9961949305376643\n",
      "#Val#  epoch: 116, dice: 0.8031461172039438\n",
      "#Test#  epoch: 116, dice: 0.7708649468892261\n",
      "#Train#  epoch: 117, loss: 0.007697747554630041, dice: 0.9962147486077806\n",
      "#Val#  epoch: 117, dice: 0.8030844857959639\n",
      "#Test#  epoch: 117, dice: 0.7710509795083946\n",
      "#Train#  epoch: 118, loss: 0.007672030013054609, dice: 0.9962444384989645\n",
      "#Val#  epoch: 118, dice: 0.8030359770666639\n",
      "#Test#  epoch: 118, dice: 0.7710076340178597\n",
      "#Train#  epoch: 119, loss: 0.007646654732525349, dice: 0.9962445129262081\n",
      "#Val#  epoch: 119, dice: 0.803130421942486\n",
      "#Test#  epoch: 119, dice: 0.7709253051418361\n",
      "#Train#  epoch: 120, loss: 0.00762128783389926, dice: 0.996234566677897\n",
      "#Val#  epoch: 120, dice: 0.8029972263528122\n",
      "#Test#  epoch: 120, dice: 0.7709463483733882\n",
      "#Train#  epoch: 121, loss: 0.007596175651997328, dice: 0.9962347905354524\n",
      "#Val#  epoch: 121, dice: 0.802986680165786\n",
      "#Test#  epoch: 121, dice: 0.7709962980846612\n",
      "#Train#  epoch: 122, loss: 0.007571094669401646, dice: 0.9962644048315019\n",
      "#Val#  epoch: 122, dice: 0.8029397963864123\n",
      "#Test#  epoch: 122, dice: 0.7709986320109439\n",
      "#Train#  epoch: 123, loss: 0.007546614855527878, dice: 0.9962842959483963\n",
      "#Val#  epoch: 123, dice: 0.8029476414124642\n",
      "#Test#  epoch: 123, dice: 0.7709973726880258\n",
      "#Train#  epoch: 124, loss: 0.0075219497084617615, dice: 0.9963240029725043\n",
      "#Val#  epoch: 124, dice: 0.8029388667232374\n",
      "#Test#  epoch: 124, dice: 0.7710282065827428\n",
      "#Train#  epoch: 125, loss: 0.007497585844248533, dice: 0.9963438196680705\n",
      "#Val#  epoch: 125, dice: 0.8029511738821111\n",
      "#Test#  epoch: 125, dice: 0.771034898923866\n",
      "#Train#  epoch: 126, loss: 0.007473381701856852, dice: 0.9963437472132219\n",
      "#Val#  epoch: 126, dice: 0.802851858292363\n",
      "#Test#  epoch: 126, dice: 0.7710312144216341\n",
      "#Train#  epoch: 127, loss: 0.007449742406606674, dice: 0.9963239301249468\n",
      "#Val#  epoch: 127, dice: 0.8027967164399297\n",
      "#Test#  epoch: 127, dice: 0.771084240420277\n",
      "#Train#  epoch: 128, loss: 0.007425896357744932, dice: 0.9964232990855139\n",
      "#Val#  epoch: 128, dice: 0.8026694196593173\n",
      "#Test#  epoch: 128, dice: 0.7710187136949491\n",
      "#Train#  epoch: 129, loss: 0.007402562536299229, dice: 0.9964531277864744\n",
      "#Val#  epoch: 129, dice: 0.8027091222212274\n",
      "#Test#  epoch: 129, dice: 0.7710088259194001\n",
      "#Train#  epoch: 130, loss: 0.007379274349659681, dice: 0.9964531980661013\n",
      "#Val#  epoch: 130, dice: 0.8026583951677033\n",
      "#Test#  epoch: 130, dice: 0.7710347102384946\n",
      "#Train#  epoch: 131, loss: 0.007356311660259962, dice: 0.9965325936199723\n",
      "#Val#  epoch: 131, dice: 0.8026013691416535\n",
      "#Test#  epoch: 131, dice: 0.7710050483718498\n",
      "#Train#  epoch: 132, loss: 0.0073334090411663055, dice: 0.9965425347480211\n",
      "#Val#  epoch: 132, dice: 0.8025443497217118\n",
      "#Test#  epoch: 132, dice: 0.770917224150901\n",
      "#Train#  epoch: 133, loss: 0.0073104011826217175, dice: 0.9965424662419877\n",
      "#Val#  epoch: 133, dice: 0.8023317044401382\n",
      "#Test#  epoch: 133, dice: 0.7708973595713527\n",
      "#Train#  epoch: 134, loss: 0.00728800892829895, dice: 0.9965723569503884\n",
      "#Val#  epoch: 134, dice: 0.8023836722661206\n",
      "#Test#  epoch: 134, dice: 0.7708756531498011\n",
      "#Train#  epoch: 135, loss: 0.007265438325703144, dice: 0.9965624164132233\n",
      "#Val#  epoch: 135, dice: 0.8022950992261937\n",
      "#Test#  epoch: 135, dice: 0.7707941105479121\n",
      "#Train#  epoch: 136, loss: 0.007243006024509668, dice: 0.9965822295751068\n",
      "#Val#  epoch: 136, dice: 0.8021390374331552\n",
      "#Test#  epoch: 136, dice: 0.7708707090047546\n",
      "#Train#  epoch: 137, loss: 0.0072208973579108715, dice: 0.9966219897570012\n",
      "#Val#  epoch: 137, dice: 0.8021116789742672\n",
      "#Test#  epoch: 137, dice: 0.7707686366635023\n",
      "#Train#  epoch: 138, loss: 0.007198733277618885, dice: 0.9966518741580157\n",
      "#Val#  epoch: 138, dice: 0.8020838266635093\n",
      "#Test#  epoch: 138, dice: 0.7708242827951279\n",
      "#Train#  epoch: 139, loss: 0.00717685092240572, dice: 0.9966220566820869\n",
      "#Val#  epoch: 139, dice: 0.8018776081545447\n",
      "#Test#  epoch: 139, dice: 0.7707680487226006\n",
      "#Train#  epoch: 140, loss: 0.007154969032853842, dice: 0.9966021773802094\n",
      "#Val#  epoch: 140, dice: 0.8019384678526892\n",
      "#Test#  epoch: 140, dice: 0.7707543906226115\n",
      "#Train#  epoch: 141, loss: 0.007133285980671644, dice: 0.9966518741580157\n",
      "#Val#  epoch: 141, dice: 0.8018077265050796\n",
      "#Test#  epoch: 141, dice: 0.7706987408986684\n",
      "#Train#  epoch: 142, loss: 0.007111708167940378, dice: 0.9967015660132532\n",
      "#Val#  epoch: 142, dice: 0.8017697625235424\n",
      "#Test#  epoch: 142, dice: 0.7706548236827496\n",
      "#Train#  epoch: 143, loss: 0.007090132683515549, dice: 0.9967214413771928\n",
      "#Val#  epoch: 143, dice: 0.8017253169217822\n",
      "#Test#  epoch: 143, dice: 0.7705199637936235\n",
      "#Train#  epoch: 144, loss: 0.007069084327667952, dice: 0.9967014353213871\n",
      "#Val#  epoch: 144, dice: 0.8015486830407634\n",
      "#Test#  epoch: 144, dice: 0.7704494617080511\n",
      "#Train#  epoch: 145, loss: 0.007047660648822784, dice: 0.9967708065059334\n",
      "#Val#  epoch: 145, dice: 0.8016199868507562\n",
      "#Test#  epoch: 145, dice: 0.7705138314478365\n",
      "#Train#  epoch: 146, loss: 0.007027012296020985, dice: 0.9967211815633327\n",
      "#Val#  epoch: 146, dice: 0.8014893035192157\n",
      "#Test#  epoch: 146, dice: 0.7704883739641163\n",
      "#Train#  epoch: 147, loss: 0.007006052415817976, dice: 0.9968005547025902\n",
      "#Val#  epoch: 147, dice: 0.8014261599381577\n",
      "#Test#  epoch: 147, dice: 0.7704630486382106\n",
      "#Train#  epoch: 148, loss: 0.006985108833760023, dice: 0.996741057719929\n",
      "#Val#  epoch: 148, dice: 0.8014049404267402\n",
      "#Test#  epoch: 148, dice: 0.7703653041519151\n",
      "#Train#  epoch: 149, loss: 0.006964472588151693, dice: 0.9967708704782282\n",
      "#Val#  epoch: 149, dice: 0.8013079317015729\n",
      "#Test#  epoch: 149, dice: 0.7703405104438222\n",
      "#Train#  epoch: 150, loss: 0.006943840067833662, dice: 0.9968006814647529\n",
      "#Val#  epoch: 150, dice: 0.8012910144135241\n",
      "#Test#  epoch: 150, dice: 0.7704319912467366\n",
      "#Train#  epoch: 151, loss: 0.0069231935776770115, dice: 0.9968204914866431\n",
      "#Val#  epoch: 151, dice: 0.8010576336760655\n",
      "#Test#  epoch: 151, dice: 0.770494968265077\n",
      "#Train#  epoch: 152, loss: 0.006902861874550581, dice: 0.9968501753204303\n",
      "#Val#  epoch: 152, dice: 0.801114352545402\n",
      "#Test#  epoch: 152, dice: 0.7703830636240401\n",
      "#Train#  epoch: 153, loss: 0.006882792804390192, dice: 0.9968303023099172\n",
      "#Val#  epoch: 153, dice: 0.8010405444464882\n",
      "#Test#  epoch: 153, dice: 0.7704547465630555\n",
      "#Train#  epoch: 154, loss: 0.006862515117973089, dice: 0.9968700475435817\n",
      "#Val#  epoch: 154, dice: 0.801204439399672\n",
      "#Test#  epoch: 154, dice: 0.7704621324860235\n",
      "#Train#  epoch: 155, loss: 0.006842324044555426, dice: 0.9968599249155548\n",
      "#Val#  epoch: 155, dice: 0.8011601269414262\n",
      "#Test#  epoch: 155, dice: 0.7703501701377996\n",
      "#Train#  epoch: 156, loss: 0.006822172552347183, dice: 0.9968997315742034\n",
      "#Val#  epoch: 156, dice: 0.8009897973122064\n",
      "#Test#  epoch: 156, dice: 0.7704509258216566\n",
      "#Train#  epoch: 157, loss: 0.006802363786846399, dice: 0.9969492264109828\n",
      "#Val#  epoch: 157, dice: 0.8011092961326954\n",
      "#Test#  epoch: 157, dice: 0.7704014736520347\n",
      "#Train#  epoch: 158, loss: 0.006782382261008024, dice: 0.9969095447521693\n",
      "#Val#  epoch: 158, dice: 0.801006313091524\n",
      "#Test#  epoch: 158, dice: 0.7703915220495083\n",
      "#Train#  epoch: 159, loss: 0.006762815173715353, dice: 0.9969095447521693\n",
      "#Val#  epoch: 159, dice: 0.8010166572142752\n",
      "#Test#  epoch: 159, dice: 0.7704544906182393\n",
      "#Train#  epoch: 160, loss: 0.006743088364601135, dice: 0.9969492264109828\n",
      "#Val#  epoch: 160, dice: 0.8010249624565494\n",
      "#Test#  epoch: 160, dice: 0.7704952310488475\n",
      "#Train#  epoch: 161, loss: 0.006723527796566486, dice: 0.9969293553627323\n",
      "#Val#  epoch: 161, dice: 0.8009199216596394\n",
      "#Test#  epoch: 161, dice: 0.7704463844109263\n",
      "#Train#  epoch: 162, loss: 0.006703669670969248, dice: 0.9969393516179836\n",
      "#Val#  epoch: 162, dice: 0.8008799378373271\n",
      "#Test#  epoch: 162, dice: 0.7704254181193777\n",
      "#Train#  epoch: 163, loss: 0.0066842809319496155, dice: 0.9968995473140967\n",
      "#Val#  epoch: 163, dice: 0.8009134817303654\n",
      "#Test#  epoch: 163, dice: 0.7703740042704282\n",
      "#Train#  epoch: 164, loss: 0.006664902903139591, dice: 0.9969889064976228\n",
      "#Val#  epoch: 164, dice: 0.8007622007233559\n",
      "#Test#  epoch: 164, dice: 0.7703987261351392\n",
      "#Train#  epoch: 165, loss: 0.0066454666666686535, dice: 0.9969690366290934\n",
      "#Val#  epoch: 165, dice: 0.8007957044556301\n",
      "#Test#  epoch: 165, dice: 0.770372753226909\n",
      "#Train#  epoch: 166, loss: 0.006626062095165253, dice: 0.9970087755789308\n",
      "#Val#  epoch: 166, dice: 0.8007263490464045\n",
      "#Test#  epoch: 166, dice: 0.7704079581185515\n",
      "#Train#  epoch: 167, loss: 0.00660682562738657, dice: 0.9969987816836537\n",
      "#Val#  epoch: 167, dice: 0.8006067349680887\n",
      "#Test#  epoch: 167, dice: 0.7704388733640256\n",
      "#Train#  epoch: 168, loss: 0.006587689276784658, dice: 0.9970087755789308\n",
      "#Val#  epoch: 168, dice: 0.8006801257392956\n",
      "#Test#  epoch: 168, dice: 0.7703554769181278\n",
      "#Train#  epoch: 169, loss: 0.006568461190909147, dice: 0.9969988411366765\n",
      "#Val#  epoch: 169, dice: 0.8007072996683877\n",
      "#Test#  epoch: 169, dice: 0.7704123072963998\n",
      "#Train#  epoch: 170, loss: 0.0065495530143380165, dice: 0.997018768880305\n",
      "#Val#  epoch: 170, dice: 0.8005938485266576\n",
      "#Test#  epoch: 170, dice: 0.7703881816500332\n",
      "#Train#  epoch: 171, loss: 0.006530697923153639, dice: 0.9970088348322174\n",
      "#Val#  epoch: 171, dice: 0.8006190163934427\n",
      "#Test#  epoch: 171, dice: 0.7704548926897129\n",
      "#Train#  epoch: 172, loss: 0.006511782296001911, dice: 0.9969989005873439\n",
      "#Val#  epoch: 172, dice: 0.800578989600214\n",
      "#Test#  epoch: 172, dice: 0.7704548926897129\n",
      "#Train#  epoch: 173, loss: 0.006492944899946451, dice: 0.9970285850121827\n",
      "#Val#  epoch: 173, dice: 0.800547465350792\n",
      "#Test#  epoch: 173, dice: 0.7704616819649326\n",
      "#Train#  epoch: 174, loss: 0.006474329624325037, dice: 0.9970285850121827\n",
      "#Val#  epoch: 174, dice: 0.8005264206541458\n",
      "#Test#  epoch: 174, dice: 0.77040479904791\n",
      "#Train#  epoch: 175, loss: 0.006455850787460804, dice: 0.9970585031049134\n",
      "#Val#  epoch: 175, dice: 0.8004383320312705\n",
      "#Test#  epoch: 175, dice: 0.7703738847587379\n",
      "#Train#  epoch: 176, loss: 0.006437213160097599, dice: 0.9970287027316126\n",
      "#Val#  epoch: 176, dice: 0.8004151792032963\n",
      "#Test#  epoch: 176, dice: 0.7704616176316869\n",
      "#Train#  epoch: 177, loss: 0.006418881006538868, dice: 0.9970684361691592\n",
      "#Val#  epoch: 177, dice: 0.8001886940797232\n",
      "#Test#  epoch: 177, dice: 0.7704751299481815\n",
      "#Train#  epoch: 178, loss: 0.006400194019079208, dice: 0.9970782532906792\n",
      "#Val#  epoch: 178, dice: 0.8003081777158161\n",
      "#Test#  epoch: 178, dice: 0.7704775687409551\n",
      "#Train#  epoch: 179, loss: 0.006382094230502844, dice: 0.9970881863560732\n",
      "#Val#  epoch: 179, dice: 0.8001760701765418\n",
      "#Test#  epoch: 179, dice: 0.7704380266289317\n",
      "#Train#  epoch: 180, loss: 0.006363607943058014, dice: 0.9970782532906792\n",
      "#Val#  epoch: 180, dice: 0.8001907286989054\n",
      "#Test#  epoch: 180, dice: 0.7704392149926436\n",
      "#Train#  epoch: 181, loss: 0.006345141213387251, dice: 0.9971080518966028\n",
      "#Val#  epoch: 181, dice: 0.8001802396558679\n",
      "#Test#  epoch: 181, dice: 0.7705022812694712\n",
      "#Train#  epoch: 182, loss: 0.006327077746391296, dice: 0.9971180985392424\n",
      "#Val#  epoch: 182, dice: 0.8000586706897997\n",
      "#Test#  epoch: 182, dice: 0.7704941755299907\n",
      "#Train#  epoch: 183, loss: 0.006308667361736298, dice: 0.997187506189467\n",
      "#Val#  epoch: 183, dice: 0.8000251422106289\n",
      "#Test#  epoch: 183, dice: 0.7704558884417948\n",
      "#Train#  epoch: 184, loss: 0.006290588062256575, dice: 0.997187506189467\n",
      "#Val#  epoch: 184, dice: 0.7999287760478039\n",
      "#Test#  epoch: 184, dice: 0.7704965473998987\n",
      "#Train#  epoch: 185, loss: 0.006272431463003159, dice: 0.9972272286150007\n",
      "#Val#  epoch: 185, dice: 0.7998638600900618\n",
      "#Test#  epoch: 185, dice: 0.7704118751230963\n",
      "#Train#  epoch: 186, loss: 0.006254679057747126, dice: 0.997207367795603\n",
      "#Val#  epoch: 186, dice: 0.7997947364562715\n",
      "#Test#  epoch: 186, dice: 0.770374181515618\n",
      "#Train#  epoch: 187, loss: 0.006236843764781952, dice: 0.9971876175952151\n",
      "#Val#  epoch: 187, dice: 0.7997424002848258\n",
      "#Test#  epoch: 187, dice: 0.7703673334860708\n",
      "#Train#  epoch: 188, loss: 0.006218716036528349, dice: 0.9972272286150007\n",
      "#Val#  epoch: 188, dice: 0.7996942856544591\n",
      "#Test#  epoch: 188, dice: 0.7704575415581493\n",
      "#Train#  epoch: 189, loss: 0.006201048381626606, dice: 0.9972669478937674\n",
      "#Val#  epoch: 189, dice: 0.7995645210254694\n",
      "#Test#  epoch: 189, dice: 0.7703931742095724\n",
      "#Train#  epoch: 190, loss: 0.006183152087032795, dice: 0.9972371587296871\n",
      "#Val#  epoch: 190, dice: 0.7995247964160858\n",
      "#Test#  epoch: 190, dice: 0.7703869819108362\n",
      "#Train#  epoch: 191, loss: 0.0061655412428081036, dice: 0.9972470886477065\n",
      "#Val#  epoch: 191, dice: 0.7994285534867657\n",
      "#Test#  epoch: 191, dice: 0.7703739425723872\n",
      "#Train#  epoch: 192, loss: 0.0061479490250349045, dice: 0.9972669478937674\n",
      "#Val#  epoch: 192, dice: 0.7994097362127881\n",
      "#Test#  epoch: 192, dice: 0.7704177583463263\n",
      "#Train#  epoch: 193, loss: 0.006130433175712824, dice: 0.9972967352880017\n",
      "#Val#  epoch: 193, dice: 0.799405615261456\n",
      "#Test#  epoch: 193, dice: 0.7704689465077126\n",
      "#Train#  epoch: 194, loss: 0.006113084498792887, dice: 0.9973364490608261\n",
      "#Val#  epoch: 194, dice: 0.799296806328743\n",
      "#Test#  epoch: 194, dice: 0.7704398977804209\n",
      "#Train#  epoch: 195, loss: 0.006095544435083866, dice: 0.9972767693572187\n",
      "#Val#  epoch: 195, dice: 0.7992131545492118\n",
      "#Test#  epoch: 195, dice: 0.7703837050907527\n",
      "#Train#  epoch: 196, loss: 0.006078062113374472, dice: 0.9972668937653489\n",
      "#Val#  epoch: 196, dice: 0.7990666917780986\n",
      "#Test#  epoch: 196, dice: 0.7704608461569369\n",
      "#Train#  epoch: 197, loss: 0.0060605998151004314, dice: 0.9973165394250859\n",
      "#Val#  epoch: 197, dice: 0.7991735753327929\n",
      "#Test#  epoch: 197, dice: 0.7704966773003767\n",
      "#Train#  epoch: 198, loss: 0.006043167319148779, dice: 0.9973363963125427\n",
      "#Val#  epoch: 198, dice: 0.7989373996621852\n",
      "#Test#  epoch: 198, dice: 0.770368167919608\n",
      "#Train#  epoch: 199, loss: 0.006025898735970259, dice: 0.9973463244613434\n",
      "#Val#  epoch: 199, dice: 0.7988349169329241\n",
      "#Test#  epoch: 199, dice: 0.770426796196078\n",
      "#Train#  epoch: 200, loss: 0.006008584052324295, dice: 0.9973264150196063\n",
      "#Val#  epoch: 200, dice: 0.7985904889372204\n",
      "#Test#  epoch: 200, dice: 0.7704082247586448\n"
     ]
    }
   ],
   "source": [
    "print('#----------Start training----------#')\n",
    "torch.cuda.empty_cache()\n",
    "info = \"%d-resizeh, %d-resizew, %f-outer_lr\"%(config.resize_h,config.resize_w,config.outer_lr)\n",
    "print(info)\n",
    "logger.info(info)\n",
    "best_dice_val = 0.0\n",
    "best_dice_test = 0.0\n",
    "train_csv = os.path.join(csv_save,\"train.csv\")\n",
    "val_csv = os.path.join(csv_save,\"val.csv\")\n",
    "test_csv = os.path.join(csv_save,\"test.csv\")\n",
    "train_columns = ['Epoch','Loss',\"Mdice\"]\n",
    "train_df = pd.DataFrame(columns=train_columns)\n",
    "val_columns = ['Epoch','Mdice']\n",
    "val_df = pd.DataFrame(columns=val_columns)\n",
    "test_columns = ['Epoch','Mdice']\n",
    "test_df = pd.DataFrame(columns=test_columns)\n",
    "for epoch in range(start_epoch, config.epoch_num+1):\n",
    "    \n",
    "    # train part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    loss_list = []    \n",
    "    base_net.train()\n",
    "    meta_optimizer.zero_grad()\n",
    "    for category_index in range(num_categories):\n",
    "        for image,mask in train_loader_list[category_index]:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)     # torch.Size([bs,out_channels=1,512,512])\n",
    "            predicted = predicted.squeeze(1)    # torch.Size([bs,512,512])\n",
    "            loss = criterion(predicted,mask)\n",
    "            loss = loss/num_categories\n",
    "            loss.backward()\n",
    "            predicted = (predicted > threshold).long()\n",
    "            temp_predicted = predicted.cpu().detach().numpy()       # threshold alternative\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "    meta_optimizer.step()\n",
    "    loss_list.append(loss.cpu().detach().numpy())\n",
    "    \n",
    "    # train_dice,train_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "    train_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "    train_mloss = np.mean(loss_list)\n",
    "    log_train = f'epoch: {epoch}, loss: {train_mloss}, dice: {train_dice}'\n",
    "    print(\"#Train# \",log_train)\n",
    "    temp_result = pd.Series([epoch,train_mloss,train_dice],index=train_columns)\n",
    "    train_df = train_df.append(temp_result, ignore_index=True)\n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    \n",
    "    # validation part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in val_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "        # val_dice,val_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        val_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_val = f'epoch: {epoch}, dice: {val_dice}'\n",
    "        print(\"#Val# \",log_val)\n",
    "        temp_result = pd.Series([epoch,val_dice],index=val_columns)\n",
    "        val_df = val_df.append(temp_result, ignore_index=True)\n",
    "        val_df.to_csv(val_csv, index=False)\n",
    "        # logger.info(log_val)\n",
    "\n",
    "    if val_dice > best_dice_val:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_val.pth'))\n",
    "        best_dice_val = val_dice\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # test part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in test_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach().numpy()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach().numpy())\n",
    "        # test_dice,test_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        test_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_test = f'epoch: {epoch}, dice: {test_dice}'\n",
    "        print(\"#Test# \",log_test)\n",
    "        temp_result = pd.Series([epoch,test_dice],index=test_columns)\n",
    "        test_df = test_df.append(temp_result, ignore_index=True)\n",
    "        test_df.to_csv(test_csv, index=False)\n",
    "        logger.info(log_test)\n",
    "\n",
    "    if test_dice > best_dice_test:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_test.pth'))\n",
    "        best_dice_test = test_dice\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best dice in testset:0.8441860068550382\n"
     ]
    }
   ],
   "source": [
    "best_result_test = \"Best dice in testset:\" + str(best_dice_test)\n",
    "print(best_result_test)\n",
    "logger.info(best_result_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
