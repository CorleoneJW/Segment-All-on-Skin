{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import *\n",
    "from models.meta import Meta\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from models.basenet import *\n",
    "from utils import *\n",
    "from configs.config_setting_classic import setting_config\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics as metrics\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.init as init\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = setting_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    support_images = batch['support_images'].squeeze(0)\n",
    "    support_masks = batch['support_masks'].squeeze(0)\n",
    "    query_images = batch['query_images'].squeeze(0)\n",
    "    query_masks = batch['query_masks'].squeeze(0)\n",
    "    return support_images, support_masks, query_images, query_masks\n",
    "\n",
    "# the function of copying the images\n",
    "def copy_file_to_folder(source_file, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    dest_path = os.path.join(dest_folder, os.path.basename(source_file))\n",
    "    shutil.copy(source_file, dest_path)\n",
    "\n",
    "# def evaluation_api(predicted_list,groudtruth_list):\n",
    "#     pre = np.array([item for sublist in predicted_list for item in sublist]).reshape(-1)\n",
    "#     gts = np.array([item for sublist in groudtruth_list for item in sublist]).reshape(-1)\n",
    "#     # confusion_matrix = metrics.confusion_matrix(gts,pre)\n",
    "#     # TN, FP, FN, TP = confusion[0,0], confusion[0,1], confusion[1,0], confusion[1,1] \n",
    "#     dice = metrics.f1_score(gts,pre)\n",
    "\n",
    "#     return dice\n",
    "\n",
    "def evaluation_api(predicted_list,groudtruth_list):\n",
    "    pre = np.array([item for sublist in predicted_list for item in sublist]).reshape(-1)\n",
    "    gts = np.array([item for sublist in groudtruth_list for item in sublist]).reshape(-1)\n",
    "    pre = torch.tensor(pre)\n",
    "    gts = torch.tensor(gts)\n",
    "    intersection = torch.sum(pre * gts)\n",
    "    union = torch.sum(pre + gts)\n",
    "    dice = (2 * intersection) / union\n",
    "    return dice\n",
    "\n",
    "def evaluation_epoch(predicted_list,groundtruth_list):\n",
    "    TP = [0]*config.num_classes\n",
    "    FP = [0]*config.num_classes\n",
    "    FN = [0]*config.num_classes\n",
    "    dice = [0.0]*config.num_classes\n",
    "    \n",
    "    for i in range(len(predicted_list)):\n",
    "        preds = np.array(predicted_list[i]).reshape(-1)\n",
    "        gts = np.array(groundtruth_list[i]).reshape(-1)\n",
    "        for j in range(len(preds)):\n",
    "            if preds[j] == gts[j]:\n",
    "                TP[gts[j]] += 1\n",
    "            else:\n",
    "                FP[preds[j]] += 1\n",
    "                FN[gts[j]] += 1        \n",
    "    \n",
    "    for i in range(config.num_classes):\n",
    "        dice[i] = (2 * TP[i])/(FP[i]+FN[i]+2*TP[i]+1)\n",
    "\n",
    "    mdice = (2*np.sum(TP))/(np.sum(FP)+np.sum(FN)+2*np.sum(TP)+1)    \n",
    "    return dice,mdice\n",
    "\n",
    "def evaluation_basenet(base_net,query_images,query_masks,criterion):\n",
    "    predicted = base_net(query_images)\n",
    "    loss = criterion(predicted,query_masks)\n",
    "    predicted = torch.argmax(predicted,dim=1).long()\n",
    "    predict_numpy = predicted.detach().cpu().numpy().reshape(-1)\n",
    "    masks_numpy = query_masks.long().detach().cpu().numpy().reshape(-1)\n",
    "    accuracy = metrics.accuracy_score(masks_numpy,predict_numpy)\n",
    "    f1_score = metrics.f1_score(masks_numpy,predict_numpy,average=None)\n",
    "    return accuracy,f1_score,loss\n",
    "\n",
    "def initialize_weights_he(model):\n",
    "    for param in model.parameters():\n",
    "        init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "def initialize_weights_xavier(model):\n",
    "    for param in model.parameters():\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "def initialize_weights_normal(model):\n",
    "    for param in model.parameters():\n",
    "        init.normal_(param, mean=0, std=1)\n",
    "\n",
    "def remove_exsits_folder(folderpath):\n",
    "    if os.path.exists(folderpath):\n",
    "        shutil.rmtree(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Creating logger----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Creating logger----------#')\n",
    "sys.path.append(config.work_dir + '/')\n",
    "log_dir = os.path.join(config.work_dir, 'log')\n",
    "checkpoint_dir = os.path.join(config.work_dir, 'checkpoints')\n",
    "resume_model = os.path.join(checkpoint_dir, 'latest.pth')\n",
    "outputs = os.path.join(config.work_dir, 'outputs')\n",
    "csv_save = os.path.join(config.work_dir, 'csv')\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "if not os.path.exists(csv_save):\n",
    "    os.makedirs(csv_save)\n",
    "\n",
    "global logger\n",
    "logger = get_logger('test', log_dir)\n",
    "global writer\n",
    "writer = SummaryWriter(config.work_dir + 'summary')\n",
    "\n",
    "log_config_info(config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Generating data----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Generating data----------#')\n",
    "images_resources_path = \"./data/HAM10000/origin/images/\"         # the resource folder of images\n",
    "masks_resources_path = \"./data/HAM10000/origin/masks/\"           # the resource folder of masks\n",
    "ratio = [0.6,0.2]     # the ratio point of train dataset and validation set and testset\n",
    "categories = config.categories\n",
    "categories_dictionary = {}\n",
    "category_id = 1\n",
    "# prepare the csv for groundtruth\n",
    "origin_groundtruth_csv = \"./data/HAM10000/origin/groundtruth/HAM10000_groundtruth.csv\"   # read the csv file\n",
    "origin_groundtruth = pd.read_csv(origin_groundtruth_csv)    # read the csv file of groundtruth\n",
    "\n",
    "# generating the folders for each category in train folder and test folder\n",
    "# create folders for each categories\n",
    "trainset_images_path = \"./data/HAM10000/train/images/\"     # the images path for train dataset\n",
    "trainset_masks_path = \"./data/HAM10000/train/masks/\"     # the masks path for train dataset\n",
    "valset_images_path = \"./data/HAM10000/val/images/\"     # the images path for validation dataset\n",
    "valset_masks_path = \"./data/HAM10000/val/masks/\"      # the masks path for validation dataset\n",
    "testset_images_path = \"./data/HAM10000/test/images/\"     # the images path for test dataset\n",
    "testset_masks_path = \"./data/HAM10000/test/masks/\"      # the masks path for test dataset\n",
    "\n",
    "for category in categories:\n",
    "    # prepare the address for folders\n",
    "    category_images_train_path = os.path.join(trainset_images_path,category)\n",
    "    category_masks_train_path = os.path.join(trainset_masks_path,category)\n",
    "    category_images_val_path = os.path.join(valset_images_path,category)\n",
    "    category_masks_val_path = os.path.join(valset_masks_path,category)\n",
    "    category_images_test_path = os.path.join(testset_images_path,category)\n",
    "    category_masks_test_path = os.path.join(testset_masks_path,category)\n",
    "    #delete the previously exsited folders\n",
    "    remove_exsits_folder(category_images_train_path)\n",
    "    remove_exsits_folder(category_masks_train_path)\n",
    "    remove_exsits_folder(category_images_val_path)\n",
    "    remove_exsits_folder(category_masks_val_path)\n",
    "    remove_exsits_folder(category_images_test_path)\n",
    "    remove_exsits_folder(category_masks_test_path)\n",
    "    # create corresponding folder for each categories\n",
    "    os.makedirs(category_images_train_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_train_path, exist_ok=True)\n",
    "    os.makedirs(category_images_val_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_val_path, exist_ok=True)\n",
    "    os.makedirs(category_images_test_path, exist_ok=True)\n",
    "    os.makedirs(category_masks_test_path, exist_ok=True)\n",
    "\n",
    "    # generate the data in trainset and testset for each categories\n",
    "    dest_folder_images = \"./data/HAM10000/train/images/\"+category    # the destination train set folder of copying the images\n",
    "    dest_folder_masks = \"./data/HAM10000/train/masks/\"+category    # the destination trian set folder of copying the masks\n",
    "    dest_folder_images_change_val = \"./data/HAM10000/val/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_val = \"./data/HAM10000/val/masks/\"+category      # the destination folder of test set masks\n",
    "    dest_folder_images_change_test = \"./data/HAM10000/test/images/\"+category     # the destination folder of test set images\n",
    "    dest_folder_masks_change_test = \"./data/HAM10000/test/masks/\"+category      # the destination folder of test set masks\n",
    "    data_categories = origin_groundtruth[origin_groundtruth['dx'] == category]      # extract each categories \n",
    "    data_categories = data_categories.sample(frac=1,random_state=config.seed)       # random sample the datagenerating\n",
    "    length_categories = len(data_categories)\n",
    "    change_folder_point_valset = math.floor(length_categories * ratio[0])     # get the point to change directory name\n",
    "    change_folder_point_testset = math.floor(length_categories * (ratio[0]+ratio[1]))     # get the point to change directory name \n",
    "    elements_count = 0\n",
    "    for image_name in data_categories['image_id']:      # each image_id in each categories\n",
    "        if elements_count == change_folder_point_valset:\n",
    "            dest_folder_images = dest_folder_images_change_val\n",
    "            dest_folder_masks = dest_folder_masks_change_val\n",
    "        elif elements_count == change_folder_point_testset:\n",
    "            dest_folder_images = dest_folder_images_change_test\n",
    "            dest_folder_masks = dest_folder_masks_change_test\n",
    "        images_file = image_name+\".jpg\"\n",
    "        masks_file = image_name+\"_segmentation.png\"\n",
    "        source_image = images_resources_path+images_file    # the full path of source of image : path + image file name\n",
    "        source_mask = masks_resources_path+masks_file       # the full path of source of mask : path + mask file name\n",
    "        copy_file_to_folder(source_image,dest_folder_images)\n",
    "        # masks should be preprocess to the form of output for network (Width*Height*Category)\n",
    "        image = Image.open(source_mask)\n",
    "        image_array = np.array(image)\n",
    "        image_array[image_array == 255] = 1\n",
    "        image = Image.fromarray(image_array)\n",
    "        image.save(os.path.join(dest_folder_masks, masks_file))\n",
    "        elements_count +=1\n",
    "    categories_dictionary[category] = category_id       # add the category id in the categories_dictionary\n",
    "    category_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------GPU init----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------GPU init----------#')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu_id\n",
    "set_seed(config.seed)\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Datasets----------#\n",
      "trian_dataset length: 1634\n",
      "val_dataset length: 546\n",
      "test_dataset length: 546\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Datasets----------#')\n",
    "# create the dataset and dataloader\n",
    "batch_size = config.batch_size\n",
    "train_dataset = HAMALL_datasets(config, train=True)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "val_dataset = HAMALL_datasets(config, train=False,val=True, num_eachcat=config.num_eachcat)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "test_dataset = HAMALL_datasets(config, train=False)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=config.num_workers)\n",
    "print(\"trian_dataset length:\",len(train_dataset))\n",
    "print(\"val_dataset length:\",len(val_dataset))\n",
    "print(\"test_dataset length:\",len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing Model----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing Model----------#')\n",
    "in_channels = config.in_channels\n",
    "out_channels = config.out_channels\n",
    "base_net = smp.Unet(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# base_net = smp.UnetPlusPlus(encoder_name='resnet34', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=config.out_channels, activation=None, aux_params=None)\n",
    "# initialize_weights_he(base_net)\n",
    "weights_dict = torch.load(config.dicts_path)\n",
    "base_net.load_state_dict(weights_dict,strict=False)\n",
    "base_net = base_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Prepareing loss, opt, sch and amp----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Prepareing loss, opt, sch and amp----------#')\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "meta_optimizer = get_optimizer(config, base_net)\n",
    "meta_scheduler = get_scheduler(config, meta_optimizer)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Set other params----------#\n"
     ]
    }
   ],
   "source": [
    "print('#----------Set other params----------#')\n",
    "min_loss = 999\n",
    "start_epoch = 1\n",
    "min_epoch = 1\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Start training----------#\n",
      "128-resizeh, 128-resizew, 0.000010-outer_lr\n",
      "#Train#  epoch: 1, loss: 0.411981999874115, dice: 0.7906271815299988\n",
      "#Val#  epoch: 1, dice: 0.8880821466445923\n",
      "#Test#  epoch: 1, dice: 0.7856839895248413\n",
      "#Train#  epoch: 2, loss: 0.40366923809051514, dice: 0.7949414849281311\n",
      "#Val#  epoch: 2, dice: 0.8866761326789856\n",
      "#Test#  epoch: 2, dice: 0.7844424843788147\n",
      "#Train#  epoch: 3, loss: 0.396961510181427, dice: 0.7986209392547607\n",
      "#Val#  epoch: 3, dice: 0.8868885636329651\n",
      "#Test#  epoch: 3, dice: 0.7864302396774292\n",
      "#Train#  epoch: 4, loss: 0.39094278216362, dice: 0.8019881248474121\n",
      "#Val#  epoch: 4, dice: 0.8877604603767395\n",
      "#Test#  epoch: 4, dice: 0.7858632802963257\n",
      "#Train#  epoch: 5, loss: 0.3858836591243744, dice: 0.8048941493034363\n",
      "#Val#  epoch: 5, dice: 0.8886486291885376\n",
      "#Test#  epoch: 5, dice: 0.7863577008247375\n",
      "#Train#  epoch: 6, loss: 0.38130709528923035, dice: 0.8075117468833923\n",
      "#Val#  epoch: 6, dice: 0.8886926174163818\n",
      "#Test#  epoch: 6, dice: 0.786076545715332\n",
      "#Train#  epoch: 7, loss: 0.37713050842285156, dice: 0.8099541664123535\n",
      "#Val#  epoch: 7, dice: 0.8895556926727295\n",
      "#Test#  epoch: 7, dice: 0.7866407036781311\n",
      "#Train#  epoch: 8, loss: 0.3733878433704376, dice: 0.8121088743209839\n",
      "#Val#  epoch: 8, dice: 0.8889098763465881\n",
      "#Test#  epoch: 8, dice: 0.7866677641868591\n",
      "#Train#  epoch: 9, loss: 0.36979395151138306, dice: 0.8141293525695801\n",
      "#Val#  epoch: 9, dice: 0.8889001607894897\n",
      "#Test#  epoch: 9, dice: 0.7867435216903687\n",
      "#Train#  epoch: 10, loss: 0.3666180372238159, dice: 0.8159752488136292\n",
      "#Val#  epoch: 10, dice: 0.8877832293510437\n",
      "#Test#  epoch: 10, dice: 0.7865341901779175\n",
      "#Train#  epoch: 11, loss: 0.3639509081840515, dice: 0.817527174949646\n",
      "#Val#  epoch: 11, dice: 0.8879201412200928\n",
      "#Test#  epoch: 11, dice: 0.786787748336792\n",
      "#Train#  epoch: 12, loss: 0.3611713647842407, dice: 0.8191105127334595\n",
      "#Val#  epoch: 12, dice: 0.8879366517066956\n",
      "#Test#  epoch: 12, dice: 0.7865762114524841\n",
      "#Train#  epoch: 13, loss: 0.35859933495521545, dice: 0.8204972147941589\n",
      "#Val#  epoch: 13, dice: 0.8889317512512207\n",
      "#Test#  epoch: 13, dice: 0.7871079444885254\n",
      "#Train#  epoch: 14, loss: 0.35566246509552, dice: 0.8223420977592468\n",
      "#Val#  epoch: 14, dice: 0.8890622854232788\n",
      "#Test#  epoch: 14, dice: 0.7868353128433228\n",
      "#Train#  epoch: 15, loss: 0.3529724180698395, dice: 0.8239341378211975\n",
      "#Val#  epoch: 15, dice: 0.8889234662055969\n",
      "#Test#  epoch: 15, dice: 0.7865795493125916\n",
      "#Train#  epoch: 16, loss: 0.35037854313850403, dice: 0.8254435658454895\n",
      "#Val#  epoch: 16, dice: 0.8880097270011902\n",
      "#Test#  epoch: 16, dice: 0.7867462635040283\n",
      "#Train#  epoch: 17, loss: 0.3482271432876587, dice: 0.8266415596008301\n",
      "#Val#  epoch: 17, dice: 0.8882450461387634\n",
      "#Test#  epoch: 17, dice: 0.7863436341285706\n",
      "#Train#  epoch: 18, loss: 0.34580573439598083, dice: 0.8280505537986755\n",
      "#Val#  epoch: 18, dice: 0.889851450920105\n",
      "#Test#  epoch: 18, dice: 0.7868055701255798\n",
      "#Train#  epoch: 19, loss: 0.3435586392879486, dice: 0.8293309807777405\n",
      "#Val#  epoch: 19, dice: 0.8901917934417725\n",
      "#Test#  epoch: 19, dice: 0.7868479490280151\n",
      "#Train#  epoch: 20, loss: 0.34153127670288086, dice: 0.830458402633667\n",
      "#Val#  epoch: 20, dice: 0.8894715309143066\n",
      "#Test#  epoch: 20, dice: 0.7862701416015625\n",
      "#Train#  epoch: 21, loss: 0.3394709825515747, dice: 0.8316499590873718\n",
      "#Val#  epoch: 21, dice: 0.8878543376922607\n",
      "#Test#  epoch: 21, dice: 0.7862361073493958\n",
      "#Train#  epoch: 22, loss: 0.3372342884540558, dice: 0.8329959511756897\n",
      "#Val#  epoch: 22, dice: 0.8867219686508179\n",
      "#Test#  epoch: 22, dice: 0.7857038974761963\n",
      "#Train#  epoch: 23, loss: 0.3352513611316681, dice: 0.8341362476348877\n",
      "#Val#  epoch: 23, dice: 0.8867807388305664\n",
      "#Test#  epoch: 23, dice: 0.7860107421875\n",
      "#Train#  epoch: 24, loss: 0.3332465589046478, dice: 0.8352974653244019\n",
      "#Val#  epoch: 24, dice: 0.886931836605072\n",
      "#Test#  epoch: 24, dice: 0.7858851552009583\n",
      "#Train#  epoch: 25, loss: 0.3315387964248657, dice: 0.8362458348274231\n",
      "#Val#  epoch: 25, dice: 0.8872798085212708\n",
      "#Test#  epoch: 25, dice: 0.7861541509628296\n",
      "#Train#  epoch: 26, loss: 0.33000877499580383, dice: 0.8370435237884521\n",
      "#Val#  epoch: 26, dice: 0.88894122838974\n",
      "#Test#  epoch: 26, dice: 0.7870532274246216\n",
      "#Train#  epoch: 27, loss: 0.3285542130470276, dice: 0.8378685116767883\n",
      "#Val#  epoch: 27, dice: 0.889025866985321\n",
      "#Test#  epoch: 27, dice: 0.7868520617485046\n",
      "#Train#  epoch: 28, loss: 0.32694703340530396, dice: 0.8388071656227112\n",
      "#Val#  epoch: 28, dice: 0.889118492603302\n",
      "#Test#  epoch: 28, dice: 0.7865604162216187\n",
      "#Train#  epoch: 29, loss: 0.3250282108783722, dice: 0.8399753570556641\n",
      "#Val#  epoch: 29, dice: 0.8887354135513306\n",
      "#Test#  epoch: 29, dice: 0.7861329913139343\n",
      "#Train#  epoch: 30, loss: 0.3232060670852661, dice: 0.8410636782646179\n",
      "#Val#  epoch: 30, dice: 0.8876117467880249\n",
      "#Test#  epoch: 30, dice: 0.7858953475952148\n",
      "#Train#  epoch: 31, loss: 0.32153043150901794, dice: 0.8421064019203186\n",
      "#Val#  epoch: 31, dice: 0.8869850039482117\n",
      "#Test#  epoch: 31, dice: 0.7861183285713196\n",
      "#Train#  epoch: 32, loss: 0.3197878897190094, dice: 0.8431947231292725\n",
      "#Val#  epoch: 32, dice: 0.8870701193809509\n",
      "#Test#  epoch: 32, dice: 0.7861073017120361\n",
      "#Train#  epoch: 33, loss: 0.317902535200119, dice: 0.8443043828010559\n",
      "#Val#  epoch: 33, dice: 0.8884624242782593\n",
      "#Test#  epoch: 33, dice: 0.786379873752594\n",
      "#Train#  epoch: 34, loss: 0.3158738613128662, dice: 0.8456150889396667\n",
      "#Val#  epoch: 34, dice: 0.8889874219894409\n",
      "#Test#  epoch: 34, dice: 0.7862030863761902\n",
      "#Train#  epoch: 35, loss: 0.31412360072135925, dice: 0.846708357334137\n",
      "#Val#  epoch: 35, dice: 0.8900509476661682\n",
      "#Test#  epoch: 35, dice: 0.7857908010482788\n",
      "#Train#  epoch: 36, loss: 0.3124501705169678, dice: 0.8477244973182678\n",
      "#Val#  epoch: 36, dice: 0.8913865089416504\n",
      "#Test#  epoch: 36, dice: 0.7856010794639587\n",
      "#Train#  epoch: 37, loss: 0.31089890003204346, dice: 0.8486184477806091\n",
      "#Val#  epoch: 37, dice: 0.8916886448860168\n",
      "#Test#  epoch: 37, dice: 0.7854798436164856\n",
      "#Train#  epoch: 38, loss: 0.30929937958717346, dice: 0.849544882774353\n",
      "#Val#  epoch: 38, dice: 0.8911759257316589\n",
      "#Test#  epoch: 38, dice: 0.7856258153915405\n",
      "#Train#  epoch: 39, loss: 0.30797162652015686, dice: 0.8502175807952881\n",
      "#Val#  epoch: 39, dice: 0.8896199464797974\n",
      "#Test#  epoch: 39, dice: 0.7853307127952576\n",
      "#Train#  epoch: 40, loss: 0.30668342113494873, dice: 0.8509970903396606\n",
      "#Val#  epoch: 40, dice: 0.888959527015686\n",
      "#Test#  epoch: 40, dice: 0.7845650911331177\n",
      "#Train#  epoch: 41, loss: 0.3050463795661926, dice: 0.8519284129142761\n",
      "#Val#  epoch: 41, dice: 0.8878284096717834\n",
      "#Test#  epoch: 41, dice: 0.7842721343040466\n",
      "#Train#  epoch: 42, loss: 0.3034008741378784, dice: 0.8530051112174988\n",
      "#Val#  epoch: 42, dice: 0.8866057991981506\n",
      "#Test#  epoch: 42, dice: 0.7839929461479187\n",
      "#Train#  epoch: 43, loss: 0.3020610511302948, dice: 0.8537375330924988\n",
      "#Val#  epoch: 43, dice: 0.8852354884147644\n",
      "#Test#  epoch: 43, dice: 0.7841851711273193\n",
      "#Train#  epoch: 44, loss: 0.30055078864097595, dice: 0.8547250032424927\n",
      "#Val#  epoch: 44, dice: 0.8845638036727905\n",
      "#Test#  epoch: 44, dice: 0.7842993140220642\n",
      "#Train#  epoch: 45, loss: 0.2990210950374603, dice: 0.8557173013687134\n",
      "#Val#  epoch: 45, dice: 0.8834580779075623\n",
      "#Test#  epoch: 45, dice: 0.7844350934028625\n",
      "#Train#  epoch: 46, loss: 0.29763853549957275, dice: 0.8565733432769775\n",
      "#Val#  epoch: 46, dice: 0.8834758400917053\n",
      "#Test#  epoch: 46, dice: 0.7843921780586243\n",
      "#Train#  epoch: 47, loss: 0.2961972951889038, dice: 0.8573889136314392\n",
      "#Val#  epoch: 47, dice: 0.8834539651870728\n",
      "#Test#  epoch: 47, dice: 0.7845401763916016\n",
      "#Train#  epoch: 48, loss: 0.2949737310409546, dice: 0.8581616878509521\n",
      "#Val#  epoch: 48, dice: 0.8852269053459167\n",
      "#Test#  epoch: 48, dice: 0.784999430179596\n",
      "#Train#  epoch: 49, loss: 0.29406818747520447, dice: 0.8586788177490234\n",
      "#Val#  epoch: 49, dice: 0.8882980942726135\n",
      "#Test#  epoch: 49, dice: 0.7849674820899963\n",
      "#Train#  epoch: 50, loss: 0.29291337728500366, dice: 0.8594511151313782\n",
      "#Val#  epoch: 50, dice: 0.8907009959220886\n",
      "#Test#  epoch: 50, dice: 0.7851160764694214\n",
      "#Train#  epoch: 51, loss: 0.2918580174446106, dice: 0.859975278377533\n",
      "#Val#  epoch: 51, dice: 0.8917245268821716\n",
      "#Test#  epoch: 51, dice: 0.7856722474098206\n",
      "#Train#  epoch: 52, loss: 0.2905225455760956, dice: 0.8608084321022034\n",
      "#Val#  epoch: 52, dice: 0.8915338516235352\n",
      "#Test#  epoch: 52, dice: 0.785775899887085\n",
      "#Train#  epoch: 53, loss: 0.28953829407691956, dice: 0.8613572716712952\n",
      "#Val#  epoch: 53, dice: 0.8904151320457458\n",
      "#Test#  epoch: 53, dice: 0.7852715849876404\n",
      "#Train#  epoch: 54, loss: 0.2883452773094177, dice: 0.8621867299079895\n",
      "#Val#  epoch: 54, dice: 0.8893884420394897\n",
      "#Test#  epoch: 54, dice: 0.7853421568870544\n",
      "#Train#  epoch: 55, loss: 0.28699493408203125, dice: 0.8630331158638\n",
      "#Val#  epoch: 55, dice: 0.888069748878479\n",
      "#Test#  epoch: 55, dice: 0.7852020263671875\n",
      "#Train#  epoch: 56, loss: 0.2856276035308838, dice: 0.8639959096908569\n",
      "#Val#  epoch: 56, dice: 0.8872044086456299\n",
      "#Test#  epoch: 56, dice: 0.7850540280342102\n",
      "#Train#  epoch: 57, loss: 0.2841504216194153, dice: 0.8650193810462952\n",
      "#Val#  epoch: 57, dice: 0.8869616389274597\n",
      "#Test#  epoch: 57, dice: 0.7851979732513428\n",
      "#Train#  epoch: 58, loss: 0.28263139724731445, dice: 0.8660809993743896\n",
      "#Val#  epoch: 58, dice: 0.8869460821151733\n",
      "#Test#  epoch: 58, dice: 0.785024881362915\n",
      "#Train#  epoch: 59, loss: 0.2812483012676239, dice: 0.8670042157173157\n",
      "#Val#  epoch: 59, dice: 0.8874160051345825\n",
      "#Test#  epoch: 59, dice: 0.7853702902793884\n",
      "#Train#  epoch: 60, loss: 0.2796907126903534, dice: 0.8679949641227722\n",
      "#Val#  epoch: 60, dice: 0.8883856534957886\n",
      "#Test#  epoch: 60, dice: 0.7851752042770386\n",
      "#Train#  epoch: 61, loss: 0.2782844305038452, dice: 0.8689818382263184\n",
      "#Val#  epoch: 61, dice: 0.8886459469795227\n",
      "#Test#  epoch: 61, dice: 0.784933865070343\n",
      "#Train#  epoch: 62, loss: 0.2769894301891327, dice: 0.8698362708091736\n",
      "#Val#  epoch: 62, dice: 0.8885979652404785\n",
      "#Test#  epoch: 62, dice: 0.7848708033561707\n",
      "#Train#  epoch: 63, loss: 0.2759041488170624, dice: 0.8705002069473267\n",
      "#Val#  epoch: 63, dice: 0.889117419719696\n",
      "#Test#  epoch: 63, dice: 0.7845152616500854\n",
      "#Train#  epoch: 64, loss: 0.2746729552745819, dice: 0.8712800145149231\n",
      "#Val#  epoch: 64, dice: 0.8900132775306702\n",
      "#Test#  epoch: 64, dice: 0.7843078970909119\n",
      "#Train#  epoch: 65, loss: 0.27369654178619385, dice: 0.8718132376670837\n",
      "#Val#  epoch: 65, dice: 0.8908272385597229\n",
      "#Test#  epoch: 65, dice: 0.7839282751083374\n",
      "#Train#  epoch: 66, loss: 0.2727832794189453, dice: 0.8722891807556152\n",
      "#Val#  epoch: 66, dice: 0.8917415738105774\n",
      "#Test#  epoch: 66, dice: 0.7835894823074341\n",
      "#Train#  epoch: 67, loss: 0.2717266082763672, dice: 0.8728392720222473\n",
      "#Val#  epoch: 67, dice: 0.892034113407135\n",
      "#Test#  epoch: 67, dice: 0.7836335301399231\n",
      "#Train#  epoch: 68, loss: 0.27053412795066833, dice: 0.8735480308532715\n",
      "#Val#  epoch: 68, dice: 0.8913880586624146\n",
      "#Test#  epoch: 68, dice: 0.7827050089836121\n",
      "#Train#  epoch: 69, loss: 0.26930487155914307, dice: 0.8743173480033875\n",
      "#Val#  epoch: 69, dice: 0.8911408185958862\n",
      "#Test#  epoch: 69, dice: 0.782942533493042\n",
      "#Train#  epoch: 70, loss: 0.26834598183631897, dice: 0.8748778104782104\n",
      "#Val#  epoch: 70, dice: 0.8909231424331665\n",
      "#Test#  epoch: 70, dice: 0.7827414870262146\n",
      "#Train#  epoch: 71, loss: 0.26716622710227966, dice: 0.8756647706031799\n",
      "#Val#  epoch: 71, dice: 0.8894221782684326\n",
      "#Test#  epoch: 71, dice: 0.7823905348777771\n",
      "#Train#  epoch: 72, loss: 0.266207218170166, dice: 0.8761860132217407\n",
      "#Val#  epoch: 72, dice: 0.8886405825614929\n",
      "#Test#  epoch: 72, dice: 0.7823528051376343\n",
      "#Train#  epoch: 73, loss: 0.26510417461395264, dice: 0.8768867254257202\n",
      "#Val#  epoch: 73, dice: 0.8877202272415161\n",
      "#Test#  epoch: 73, dice: 0.7825519442558289\n",
      "#Train#  epoch: 74, loss: 0.2641075551509857, dice: 0.877416729927063\n",
      "#Val#  epoch: 74, dice: 0.8871779441833496\n",
      "#Test#  epoch: 74, dice: 0.7827774882316589\n",
      "#Train#  epoch: 75, loss: 0.26296499371528625, dice: 0.8781059384346008\n",
      "#Val#  epoch: 75, dice: 0.886993408203125\n",
      "#Test#  epoch: 75, dice: 0.7827197313308716\n",
      "#Train#  epoch: 76, loss: 0.26177844405174255, dice: 0.8788666129112244\n",
      "#Val#  epoch: 76, dice: 0.8870306611061096\n",
      "#Test#  epoch: 76, dice: 0.7825711965560913\n",
      "#Train#  epoch: 77, loss: 0.26072242856025696, dice: 0.8795070648193359\n",
      "#Val#  epoch: 77, dice: 0.8876391053199768\n",
      "#Test#  epoch: 77, dice: 0.7824457287788391\n",
      "#Train#  epoch: 78, loss: 0.2596341073513031, dice: 0.8802483081817627\n",
      "#Val#  epoch: 78, dice: 0.8886670470237732\n",
      "#Test#  epoch: 78, dice: 0.7827025055885315\n",
      "#Train#  epoch: 79, loss: 0.2586698830127716, dice: 0.8808502554893494\n",
      "#Val#  epoch: 79, dice: 0.8883303999900818\n",
      "#Test#  epoch: 79, dice: 0.783227801322937\n",
      "#Train#  epoch: 80, loss: 0.2576800286769867, dice: 0.8814273476600647\n",
      "#Val#  epoch: 80, dice: 0.8883963227272034\n",
      "#Test#  epoch: 80, dice: 0.7831975817680359\n",
      "#Train#  epoch: 81, loss: 0.25672653317451477, dice: 0.8819979429244995\n",
      "#Val#  epoch: 81, dice: 0.888874888420105\n",
      "#Test#  epoch: 81, dice: 0.783159613609314\n",
      "#Train#  epoch: 82, loss: 0.25570976734161377, dice: 0.8825463056564331\n",
      "#Val#  epoch: 82, dice: 0.8897790908813477\n",
      "#Test#  epoch: 82, dice: 0.7833752036094666\n",
      "#Train#  epoch: 83, loss: 0.2547615170478821, dice: 0.8830745816230774\n",
      "#Val#  epoch: 83, dice: 0.8903703093528748\n",
      "#Test#  epoch: 83, dice: 0.7832497358322144\n",
      "#Train#  epoch: 84, loss: 0.25413978099823, dice: 0.883290708065033\n",
      "#Val#  epoch: 84, dice: 0.8913739323616028\n",
      "#Test#  epoch: 84, dice: 0.7834427356719971\n",
      "#Train#  epoch: 85, loss: 0.25369536876678467, dice: 0.8833804130554199\n",
      "#Val#  epoch: 85, dice: 0.8920748829841614\n",
      "#Test#  epoch: 85, dice: 0.7840263843536377\n",
      "#Train#  epoch: 86, loss: 0.2532535791397095, dice: 0.8835456967353821\n",
      "#Val#  epoch: 86, dice: 0.8915138244628906\n",
      "#Test#  epoch: 86, dice: 0.7844619750976562\n",
      "#Train#  epoch: 87, loss: 0.25305140018463135, dice: 0.8834426403045654\n",
      "#Val#  epoch: 87, dice: 0.8898955583572388\n",
      "#Test#  epoch: 87, dice: 0.7839455604553223\n",
      "#Train#  epoch: 88, loss: 0.252441942691803, dice: 0.8837092518806458\n",
      "#Val#  epoch: 88, dice: 0.8891798853874207\n",
      "#Test#  epoch: 88, dice: 0.7839490175247192\n",
      "#Train#  epoch: 89, loss: 0.2512800991535187, dice: 0.8844926357269287\n",
      "#Val#  epoch: 89, dice: 0.8886975646018982\n",
      "#Test#  epoch: 89, dice: 0.78364098072052\n",
      "#Train#  epoch: 90, loss: 0.2500940263271332, dice: 0.8853038549423218\n",
      "#Val#  epoch: 90, dice: 0.8888761401176453\n",
      "#Test#  epoch: 90, dice: 0.7835215926170349\n",
      "#Train#  epoch: 91, loss: 0.24883688986301422, dice: 0.8861567974090576\n",
      "#Val#  epoch: 91, dice: 0.8881760835647583\n",
      "#Test#  epoch: 91, dice: 0.7832875847816467\n",
      "#Train#  epoch: 92, loss: 0.2478310763835907, dice: 0.8867442011833191\n",
      "#Val#  epoch: 92, dice: 0.8869447112083435\n",
      "#Test#  epoch: 92, dice: 0.7831386923789978\n",
      "#Train#  epoch: 93, loss: 0.24666298925876617, dice: 0.8874764442443848\n",
      "#Val#  epoch: 93, dice: 0.8863701820373535\n",
      "#Test#  epoch: 93, dice: 0.782991886138916\n",
      "#Train#  epoch: 94, loss: 0.24531473219394684, dice: 0.8884246349334717\n",
      "#Val#  epoch: 94, dice: 0.8864072561264038\n",
      "#Test#  epoch: 94, dice: 0.7832353115081787\n",
      "#Train#  epoch: 95, loss: 0.24405628442764282, dice: 0.8892574310302734\n",
      "#Val#  epoch: 95, dice: 0.8863913416862488\n",
      "#Test#  epoch: 95, dice: 0.783395528793335\n",
      "#Train#  epoch: 96, loss: 0.24288718402385712, dice: 0.8900807499885559\n",
      "#Val#  epoch: 96, dice: 0.8866007924079895\n",
      "#Test#  epoch: 96, dice: 0.7834975719451904\n",
      "#Train#  epoch: 97, loss: 0.24175360798835754, dice: 0.8908753395080566\n",
      "#Val#  epoch: 97, dice: 0.8872787356376648\n",
      "#Test#  epoch: 97, dice: 0.7835600972175598\n",
      "#Train#  epoch: 98, loss: 0.24078400433063507, dice: 0.8915112614631653\n",
      "#Val#  epoch: 98, dice: 0.8887945413589478\n",
      "#Test#  epoch: 98, dice: 0.7834265232086182\n",
      "#Train#  epoch: 99, loss: 0.23967106640338898, dice: 0.8922375440597534\n",
      "#Val#  epoch: 99, dice: 0.8904294967651367\n",
      "#Test#  epoch: 99, dice: 0.7831690907478333\n",
      "#Train#  epoch: 100, loss: 0.2386087328195572, dice: 0.8930177092552185\n",
      "#Val#  epoch: 100, dice: 0.891379714012146\n",
      "#Test#  epoch: 100, dice: 0.7826111912727356\n",
      "#Train#  epoch: 101, loss: 0.23762546479701996, dice: 0.8936482071876526\n",
      "#Val#  epoch: 101, dice: 0.8919155597686768\n",
      "#Test#  epoch: 101, dice: 0.7820241451263428\n",
      "#Train#  epoch: 102, loss: 0.2368066906929016, dice: 0.8941308856010437\n",
      "#Val#  epoch: 102, dice: 0.8925300240516663\n",
      "#Test#  epoch: 102, dice: 0.7814925312995911\n",
      "#Train#  epoch: 103, loss: 0.23588316142559052, dice: 0.8947214484214783\n",
      "#Val#  epoch: 103, dice: 0.8930007219314575\n",
      "#Test#  epoch: 103, dice: 0.7814182639122009\n",
      "#Train#  epoch: 104, loss: 0.23500970005989075, dice: 0.895283579826355\n",
      "#Val#  epoch: 104, dice: 0.8931882381439209\n",
      "#Test#  epoch: 104, dice: 0.781853973865509\n",
      "#Train#  epoch: 105, loss: 0.23410844802856445, dice: 0.8958613276481628\n",
      "#Val#  epoch: 105, dice: 0.8930164575576782\n",
      "#Test#  epoch: 105, dice: 0.7815262079238892\n",
      "#Train#  epoch: 106, loss: 0.2331487536430359, dice: 0.8965345025062561\n",
      "#Val#  epoch: 106, dice: 0.8926928043365479\n",
      "#Test#  epoch: 106, dice: 0.7811301350593567\n",
      "#Train#  epoch: 107, loss: 0.23240187764167786, dice: 0.8969524502754211\n",
      "#Val#  epoch: 107, dice: 0.892265260219574\n",
      "#Test#  epoch: 107, dice: 0.7809349298477173\n",
      "#Train#  epoch: 108, loss: 0.2316480427980423, dice: 0.8973777294158936\n",
      "#Val#  epoch: 108, dice: 0.8920277953147888\n",
      "#Test#  epoch: 108, dice: 0.7806866765022278\n",
      "#Train#  epoch: 109, loss: 0.23089854419231415, dice: 0.8977952003479004\n",
      "#Val#  epoch: 109, dice: 0.8916288018226624\n",
      "#Test#  epoch: 109, dice: 0.7803496718406677\n",
      "#Train#  epoch: 110, loss: 0.23008401691913605, dice: 0.898250162601471\n",
      "#Val#  epoch: 110, dice: 0.8909231424331665\n",
      "#Test#  epoch: 110, dice: 0.7799345850944519\n",
      "#Train#  epoch: 111, loss: 0.22939999401569366, dice: 0.89859539270401\n",
      "#Val#  epoch: 111, dice: 0.8904907703399658\n",
      "#Test#  epoch: 111, dice: 0.7795921564102173\n",
      "#Train#  epoch: 112, loss: 0.22866283357143402, dice: 0.8990028500556946\n",
      "#Val#  epoch: 112, dice: 0.8897539377212524\n",
      "#Test#  epoch: 112, dice: 0.7795958518981934\n",
      "#Train#  epoch: 113, loss: 0.22796829044818878, dice: 0.8993960618972778\n",
      "#Val#  epoch: 113, dice: 0.8888950347900391\n",
      "#Test#  epoch: 113, dice: 0.7792562246322632\n",
      "#Train#  epoch: 114, loss: 0.2272367775440216, dice: 0.8997792601585388\n",
      "#Val#  epoch: 114, dice: 0.8881969451904297\n",
      "#Test#  epoch: 114, dice: 0.7794051766395569\n",
      "#Train#  epoch: 115, loss: 0.226470947265625, dice: 0.9002578854560852\n",
      "#Val#  epoch: 115, dice: 0.8876008987426758\n",
      "#Test#  epoch: 115, dice: 0.779262125492096\n",
      "#Train#  epoch: 116, loss: 0.2256668359041214, dice: 0.9007483124732971\n",
      "#Val#  epoch: 116, dice: 0.8880020976066589\n",
      "#Test#  epoch: 116, dice: 0.7794787883758545\n",
      "#Train#  epoch: 117, loss: 0.2247472107410431, dice: 0.901393711566925\n",
      "#Val#  epoch: 117, dice: 0.8885515332221985\n",
      "#Test#  epoch: 117, dice: 0.7797269821166992\n",
      "#Train#  epoch: 118, loss: 0.22399619221687317, dice: 0.901870608329773\n",
      "#Val#  epoch: 118, dice: 0.8890954256057739\n",
      "#Test#  epoch: 118, dice: 0.7795115113258362\n",
      "#Train#  epoch: 119, loss: 0.22323264181613922, dice: 0.9023380875587463\n",
      "#Val#  epoch: 119, dice: 0.889649510383606\n",
      "#Test#  epoch: 119, dice: 0.779974102973938\n",
      "#Train#  epoch: 120, loss: 0.222410649061203, dice: 0.9028418660163879\n",
      "#Val#  epoch: 120, dice: 0.8901854753494263\n",
      "#Test#  epoch: 120, dice: 0.7804952263832092\n",
      "#Train#  epoch: 121, loss: 0.2216716706752777, dice: 0.903336226940155\n",
      "#Val#  epoch: 121, dice: 0.8904024958610535\n",
      "#Test#  epoch: 121, dice: 0.7809444665908813\n",
      "#Train#  epoch: 122, loss: 0.22094276547431946, dice: 0.9038165211677551\n",
      "#Val#  epoch: 122, dice: 0.8908283710479736\n",
      "#Test#  epoch: 122, dice: 0.7811173796653748\n",
      "#Train#  epoch: 123, loss: 0.2202419638633728, dice: 0.9042473435401917\n",
      "#Val#  epoch: 123, dice: 0.8912761211395264\n",
      "#Test#  epoch: 123, dice: 0.7810595631599426\n",
      "#Train#  epoch: 124, loss: 0.21958938241004944, dice: 0.9046522378921509\n",
      "#Val#  epoch: 124, dice: 0.8916225433349609\n",
      "#Test#  epoch: 124, dice: 0.7813760042190552\n",
      "#Train#  epoch: 125, loss: 0.21891647577285767, dice: 0.9050487875938416\n",
      "#Val#  epoch: 125, dice: 0.8920115232467651\n",
      "#Test#  epoch: 125, dice: 0.7812323570251465\n",
      "#Train#  epoch: 126, loss: 0.21825474500656128, dice: 0.9054598808288574\n",
      "#Val#  epoch: 126, dice: 0.8923664689064026\n",
      "#Test#  epoch: 126, dice: 0.7815206050872803\n",
      "#Train#  epoch: 127, loss: 0.21765202283859253, dice: 0.9058166742324829\n",
      "#Val#  epoch: 127, dice: 0.8924350738525391\n",
      "#Test#  epoch: 127, dice: 0.7817888855934143\n",
      "#Train#  epoch: 128, loss: 0.21707981824874878, dice: 0.9061274528503418\n",
      "#Val#  epoch: 128, dice: 0.8923840522766113\n",
      "#Test#  epoch: 128, dice: 0.7819138765335083\n",
      "#Train#  epoch: 129, loss: 0.21648389101028442, dice: 0.906481921672821\n",
      "#Val#  epoch: 129, dice: 0.8921536207199097\n",
      "#Test#  epoch: 129, dice: 0.7819372415542603\n",
      "#Train#  epoch: 130, loss: 0.21583476662635803, dice: 0.9068728685379028\n",
      "#Val#  epoch: 130, dice: 0.8922666907310486\n",
      "#Test#  epoch: 130, dice: 0.7817522883415222\n",
      "#Train#  epoch: 131, loss: 0.21518781781196594, dice: 0.9072659015655518\n",
      "#Val#  epoch: 131, dice: 0.8921916484832764\n",
      "#Test#  epoch: 131, dice: 0.7817184329032898\n",
      "#Train#  epoch: 132, loss: 0.21460285782814026, dice: 0.9076132774353027\n",
      "#Val#  epoch: 132, dice: 0.8919183611869812\n",
      "#Test#  epoch: 132, dice: 0.7819964289665222\n",
      "#Train#  epoch: 133, loss: 0.2140505611896515, dice: 0.9079464673995972\n",
      "#Val#  epoch: 133, dice: 0.8919401168823242\n",
      "#Test#  epoch: 133, dice: 0.781809389591217\n",
      "#Train#  epoch: 134, loss: 0.2134293168783188, dice: 0.9083457589149475\n",
      "#Val#  epoch: 134, dice: 0.8915557265281677\n",
      "#Test#  epoch: 134, dice: 0.7817773818969727\n",
      "#Train#  epoch: 135, loss: 0.21291397511959076, dice: 0.9086412787437439\n",
      "#Val#  epoch: 135, dice: 0.8915168642997742\n",
      "#Test#  epoch: 135, dice: 0.7815591096878052\n",
      "#Train#  epoch: 136, loss: 0.2122626006603241, dice: 0.9090457558631897\n",
      "#Val#  epoch: 136, dice: 0.8914172053337097\n",
      "#Test#  epoch: 136, dice: 0.7814092636108398\n",
      "#Train#  epoch: 137, loss: 0.21173541247844696, dice: 0.9093546867370605\n",
      "#Val#  epoch: 137, dice: 0.8912839293479919\n",
      "#Test#  epoch: 137, dice: 0.7810169458389282\n",
      "#Train#  epoch: 138, loss: 0.21124519407749176, dice: 0.9096093773841858\n",
      "#Val#  epoch: 138, dice: 0.8912211656570435\n",
      "#Test#  epoch: 138, dice: 0.7807350158691406\n",
      "#Train#  epoch: 139, loss: 0.2106848955154419, dice: 0.909980297088623\n",
      "#Val#  epoch: 139, dice: 0.8912593722343445\n",
      "#Test#  epoch: 139, dice: 0.7805375456809998\n",
      "#Train#  epoch: 140, loss: 0.21013030409812927, dice: 0.9102888107299805\n",
      "#Val#  epoch: 140, dice: 0.8911405801773071\n",
      "#Test#  epoch: 140, dice: 0.7802954316139221\n",
      "#Train#  epoch: 141, loss: 0.20956891775131226, dice: 0.9106521010398865\n",
      "#Val#  epoch: 141, dice: 0.8912360668182373\n",
      "#Test#  epoch: 141, dice: 0.7803798913955688\n",
      "#Train#  epoch: 142, loss: 0.20903033018112183, dice: 0.9109655618667603\n",
      "#Val#  epoch: 142, dice: 0.8914543986320496\n",
      "#Test#  epoch: 142, dice: 0.7803130745887756\n",
      "#Train#  epoch: 143, loss: 0.20845352113246918, dice: 0.9113544821739197\n",
      "#Val#  epoch: 143, dice: 0.8913803696632385\n",
      "#Test#  epoch: 143, dice: 0.7801127433776855\n",
      "#Train#  epoch: 144, loss: 0.2079509198665619, dice: 0.911665141582489\n",
      "#Val#  epoch: 144, dice: 0.8914505839347839\n",
      "#Test#  epoch: 144, dice: 0.7800101041793823\n",
      "#Train#  epoch: 145, loss: 0.20741596817970276, dice: 0.9119941592216492\n",
      "#Val#  epoch: 145, dice: 0.8918735384941101\n",
      "#Test#  epoch: 145, dice: 0.7798449397087097\n",
      "#Train#  epoch: 146, loss: 0.20685458183288574, dice: 0.912327766418457\n",
      "#Val#  epoch: 146, dice: 0.8923822641372681\n",
      "#Test#  epoch: 146, dice: 0.7797566652297974\n",
      "#Train#  epoch: 147, loss: 0.2062329798936844, dice: 0.9126920700073242\n",
      "#Val#  epoch: 147, dice: 0.8925758004188538\n",
      "#Test#  epoch: 147, dice: 0.7794243693351746\n",
      "#Train#  epoch: 148, loss: 0.20574107766151428, dice: 0.9129796624183655\n",
      "#Val#  epoch: 148, dice: 0.892742395401001\n",
      "#Test#  epoch: 148, dice: 0.7792637348175049\n",
      "#Train#  epoch: 149, loss: 0.2052992731332779, dice: 0.9132313132286072\n",
      "#Val#  epoch: 149, dice: 0.8926228880882263\n",
      "#Test#  epoch: 149, dice: 0.7792450189590454\n",
      "#Train#  epoch: 150, loss: 0.20478907227516174, dice: 0.9135293960571289\n",
      "#Val#  epoch: 150, dice: 0.8925818204879761\n",
      "#Test#  epoch: 150, dice: 0.7790751457214355\n",
      "#Train#  epoch: 151, loss: 0.20430287718772888, dice: 0.9137861132621765\n",
      "#Val#  epoch: 151, dice: 0.892347514629364\n",
      "#Test#  epoch: 151, dice: 0.7790267467498779\n",
      "#Train#  epoch: 152, loss: 0.2038138061761856, dice: 0.9140791296958923\n",
      "#Val#  epoch: 152, dice: 0.8922069668769836\n",
      "#Test#  epoch: 152, dice: 0.7788844108581543\n",
      "#Train#  epoch: 153, loss: 0.20331880450248718, dice: 0.914371132850647\n",
      "#Val#  epoch: 153, dice: 0.8920326828956604\n",
      "#Test#  epoch: 153, dice: 0.778634786605835\n",
      "#Train#  epoch: 154, loss: 0.20283548533916473, dice: 0.9146226644515991\n",
      "#Val#  epoch: 154, dice: 0.8917800188064575\n",
      "#Test#  epoch: 154, dice: 0.7784727811813354\n",
      "#Train#  epoch: 155, loss: 0.20233389735221863, dice: 0.9149019718170166\n",
      "#Val#  epoch: 155, dice: 0.8916799426078796\n",
      "#Test#  epoch: 155, dice: 0.7785205841064453\n",
      "#Train#  epoch: 156, loss: 0.2018522471189499, dice: 0.9151915311813354\n",
      "#Val#  epoch: 156, dice: 0.8917622566223145\n",
      "#Test#  epoch: 156, dice: 0.7785599827766418\n",
      "#Train#  epoch: 157, loss: 0.20139479637145996, dice: 0.9154260754585266\n",
      "#Val#  epoch: 157, dice: 0.8918543457984924\n",
      "#Test#  epoch: 157, dice: 0.7785027027130127\n",
      "#Train#  epoch: 158, loss: 0.20098291337490082, dice: 0.915616512298584\n",
      "#Val#  epoch: 158, dice: 0.8916828632354736\n",
      "#Test#  epoch: 158, dice: 0.7786002159118652\n",
      "#Train#  epoch: 159, loss: 0.200501948595047, dice: 0.9158633351325989\n",
      "#Val#  epoch: 159, dice: 0.8916942477226257\n",
      "#Test#  epoch: 159, dice: 0.7787826061248779\n",
      "#Train#  epoch: 160, loss: 0.20004603266716003, dice: 0.916110634803772\n",
      "#Val#  epoch: 160, dice: 0.8916851282119751\n",
      "#Test#  epoch: 160, dice: 0.7791210412979126\n",
      "#Train#  epoch: 161, loss: 0.19959034025669098, dice: 0.9163314700126648\n",
      "#Val#  epoch: 161, dice: 0.8916472792625427\n",
      "#Test#  epoch: 161, dice: 0.7791550755500793\n",
      "#Train#  epoch: 162, loss: 0.19915111362934113, dice: 0.9165579676628113\n",
      "#Val#  epoch: 162, dice: 0.8916696906089783\n",
      "#Test#  epoch: 162, dice: 0.7792309522628784\n",
      "#Train#  epoch: 163, loss: 0.19868312776088715, dice: 0.916796088218689\n",
      "#Val#  epoch: 163, dice: 0.8917154669761658\n",
      "#Test#  epoch: 163, dice: 0.7794396281242371\n",
      "#Train#  epoch: 164, loss: 0.198211669921875, dice: 0.9170323610305786\n",
      "#Val#  epoch: 164, dice: 0.8918082118034363\n",
      "#Test#  epoch: 164, dice: 0.7796503305435181\n",
      "#Train#  epoch: 165, loss: 0.1977124661207199, dice: 0.9172897934913635\n",
      "#Val#  epoch: 165, dice: 0.8917636275291443\n",
      "#Test#  epoch: 165, dice: 0.7795180678367615\n",
      "#Train#  epoch: 166, loss: 0.19723516702651978, dice: 0.9175139665603638\n",
      "#Val#  epoch: 166, dice: 0.8918520212173462\n",
      "#Test#  epoch: 166, dice: 0.7797706723213196\n",
      "#Train#  epoch: 167, loss: 0.1967395842075348, dice: 0.9178141951560974\n",
      "#Val#  epoch: 167, dice: 0.8918196558952332\n",
      "#Test#  epoch: 167, dice: 0.7799615859985352\n",
      "#Train#  epoch: 168, loss: 0.1962963193655014, dice: 0.917982280254364\n",
      "#Val#  epoch: 168, dice: 0.8918154239654541\n",
      "#Test#  epoch: 168, dice: 0.7799425721168518\n",
      "#Train#  epoch: 169, loss: 0.19586607813835144, dice: 0.9181864857673645\n",
      "#Val#  epoch: 169, dice: 0.8915632963180542\n",
      "#Test#  epoch: 169, dice: 0.7799299955368042\n",
      "#Train#  epoch: 170, loss: 0.19541656970977783, dice: 0.9184238910675049\n",
      "#Val#  epoch: 170, dice: 0.8913975358009338\n",
      "#Test#  epoch: 170, dice: 0.7800970077514648\n",
      "#Train#  epoch: 171, loss: 0.19496700167655945, dice: 0.9186599850654602\n",
      "#Val#  epoch: 171, dice: 0.8912520408630371\n",
      "#Test#  epoch: 171, dice: 0.7800999283790588\n",
      "#Train#  epoch: 172, loss: 0.19452530145645142, dice: 0.9188850522041321\n",
      "#Val#  epoch: 172, dice: 0.8913671970367432\n",
      "#Test#  epoch: 172, dice: 0.7801651358604431\n",
      "#Train#  epoch: 173, loss: 0.19408848881721497, dice: 0.9191206693649292\n",
      "#Val#  epoch: 173, dice: 0.8912867903709412\n",
      "#Test#  epoch: 173, dice: 0.7803103923797607\n",
      "#Train#  epoch: 174, loss: 0.19366389513015747, dice: 0.9193737506866455\n",
      "#Val#  epoch: 174, dice: 0.8913435935974121\n",
      "#Test#  epoch: 174, dice: 0.7806151509284973\n",
      "#Train#  epoch: 175, loss: 0.1932554394006729, dice: 0.9195759892463684\n",
      "#Val#  epoch: 175, dice: 0.8915323615074158\n",
      "#Test#  epoch: 175, dice: 0.780498206615448\n",
      "#Train#  epoch: 176, loss: 0.1928248256444931, dice: 0.9197966456413269\n",
      "#Val#  epoch: 176, dice: 0.8915863633155823\n",
      "#Test#  epoch: 176, dice: 0.7806280851364136\n",
      "#Train#  epoch: 177, loss: 0.1923934817314148, dice: 0.9200380444526672\n",
      "#Val#  epoch: 177, dice: 0.8916637897491455\n",
      "#Test#  epoch: 177, dice: 0.7804057598114014\n",
      "#Train#  epoch: 178, loss: 0.19197942316532135, dice: 0.9202621579170227\n",
      "#Val#  epoch: 178, dice: 0.8916966915130615\n",
      "#Test#  epoch: 178, dice: 0.7804052829742432\n",
      "#Train#  epoch: 179, loss: 0.1916099488735199, dice: 0.9204274415969849\n",
      "#Val#  epoch: 179, dice: 0.8916296362876892\n",
      "#Test#  epoch: 179, dice: 0.780318558216095\n",
      "#Train#  epoch: 180, loss: 0.19122366607189178, dice: 0.9206136465072632\n",
      "#Val#  epoch: 180, dice: 0.8916031122207642\n",
      "#Test#  epoch: 180, dice: 0.7802173495292664\n",
      "#Train#  epoch: 181, loss: 0.19081971049308777, dice: 0.9208140969276428\n",
      "#Val#  epoch: 181, dice: 0.8915380239486694\n",
      "#Test#  epoch: 181, dice: 0.7801538109779358\n",
      "#Train#  epoch: 182, loss: 0.1904619336128235, dice: 0.9209694862365723\n",
      "#Val#  epoch: 182, dice: 0.8914409875869751\n",
      "#Test#  epoch: 182, dice: 0.779965877532959\n",
      "#Train#  epoch: 183, loss: 0.1901005059480667, dice: 0.9211437106132507\n",
      "#Val#  epoch: 183, dice: 0.8915585875511169\n",
      "#Test#  epoch: 183, dice: 0.7798378467559814\n",
      "#Train#  epoch: 184, loss: 0.18972566723823547, dice: 0.9213311076164246\n",
      "#Val#  epoch: 184, dice: 0.8914570808410645\n",
      "#Test#  epoch: 184, dice: 0.7798087000846863\n",
      "#Train#  epoch: 185, loss: 0.18938010931015015, dice: 0.9214490056037903\n",
      "#Val#  epoch: 185, dice: 0.8915203809738159\n",
      "#Test#  epoch: 185, dice: 0.779735267162323\n",
      "#Train#  epoch: 186, loss: 0.1890362799167633, dice: 0.921609103679657\n",
      "#Val#  epoch: 186, dice: 0.8915688395500183\n",
      "#Test#  epoch: 186, dice: 0.7795781493186951\n",
      "#Train#  epoch: 187, loss: 0.18869012594223022, dice: 0.9217745661735535\n",
      "#Val#  epoch: 187, dice: 0.8916082978248596\n",
      "#Test#  epoch: 187, dice: 0.7795335054397583\n",
      "#Train#  epoch: 188, loss: 0.18838177621364594, dice: 0.9218860268592834\n",
      "#Val#  epoch: 188, dice: 0.8916246891021729\n",
      "#Test#  epoch: 188, dice: 0.779352068901062\n",
      "#Train#  epoch: 189, loss: 0.1880432814359665, dice: 0.9220494627952576\n",
      "#Val#  epoch: 189, dice: 0.8914597630500793\n",
      "#Test#  epoch: 189, dice: 0.7791907787322998\n",
      "#Train#  epoch: 190, loss: 0.1877407431602478, dice: 0.92215496301651\n",
      "#Val#  epoch: 190, dice: 0.8914417624473572\n",
      "#Test#  epoch: 190, dice: 0.7790738344192505\n",
      "#Train#  epoch: 191, loss: 0.1873776912689209, dice: 0.9223371744155884\n",
      "#Val#  epoch: 191, dice: 0.8912755846977234\n",
      "#Test#  epoch: 191, dice: 0.7788971066474915\n",
      "#Train#  epoch: 192, loss: 0.18708541989326477, dice: 0.9224318861961365\n",
      "#Val#  epoch: 192, dice: 0.8911243677139282\n",
      "#Test#  epoch: 192, dice: 0.7789194583892822\n",
      "#Train#  epoch: 193, loss: 0.1867426186800003, dice: 0.9226117134094238\n",
      "#Val#  epoch: 193, dice: 0.8909862041473389\n",
      "#Test#  epoch: 193, dice: 0.7787732481956482\n",
      "#Train#  epoch: 194, loss: 0.18638424575328827, dice: 0.9227730631828308\n",
      "#Val#  epoch: 194, dice: 0.8907182812690735\n",
      "#Test#  epoch: 194, dice: 0.7787917256355286\n",
      "#Train#  epoch: 195, loss: 0.1860577017068863, dice: 0.9229152202606201\n",
      "#Val#  epoch: 195, dice: 0.8905174732208252\n",
      "#Test#  epoch: 195, dice: 0.7787526845932007\n",
      "#Train#  epoch: 196, loss: 0.18574315309524536, dice: 0.9230374097824097\n",
      "#Val#  epoch: 196, dice: 0.8902881741523743\n",
      "#Test#  epoch: 196, dice: 0.778583288192749\n",
      "#Train#  epoch: 197, loss: 0.18541564047336578, dice: 0.9231712818145752\n",
      "#Val#  epoch: 197, dice: 0.8901091814041138\n",
      "#Test#  epoch: 197, dice: 0.7785849571228027\n",
      "#Train#  epoch: 198, loss: 0.18507404625415802, dice: 0.9233763813972473\n",
      "#Val#  epoch: 198, dice: 0.8897002935409546\n",
      "#Test#  epoch: 198, dice: 0.7787731885910034\n",
      "#Train#  epoch: 199, loss: 0.18481118977069855, dice: 0.9234112501144409\n",
      "#Val#  epoch: 199, dice: 0.8896065950393677\n",
      "#Test#  epoch: 199, dice: 0.7788622975349426\n",
      "#Train#  epoch: 200, loss: 0.18445315957069397, dice: 0.923587441444397\n",
      "#Val#  epoch: 200, dice: 0.8895596861839294\n",
      "#Test#  epoch: 200, dice: 0.7788782119750977\n"
     ]
    }
   ],
   "source": [
    "print('#----------Start training----------#')\n",
    "torch.cuda.empty_cache()\n",
    "info = \"%d-resizeh, %d-resizew, %f-outer_lr\"%(config.resize_h,config.resize_w,config.outer_lr)\n",
    "print(info)\n",
    "logger.info(info)\n",
    "best_dice_val = 0.0\n",
    "best_dice_test = 0.0\n",
    "train_csv = os.path.join(csv_save,\"train.csv\")\n",
    "val_csv = os.path.join(csv_save,\"val.csv\")\n",
    "test_csv = os.path.join(csv_save,\"test.csv\")\n",
    "train_columns = ['Epoch','Loss',\"Mdice\"]\n",
    "train_df = pd.DataFrame(columns=train_columns)\n",
    "val_columns = ['Epoch','Mdice']\n",
    "val_df = pd.DataFrame(columns=val_columns)\n",
    "test_columns = ['Epoch','Mdice']\n",
    "test_df = pd.DataFrame(columns=test_columns)\n",
    "for epoch in range(start_epoch, config.epoch_num+1):\n",
    "    # train part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    loss_list = []    \n",
    "    base_net.train()\n",
    "    for image,mask in val_loader:\n",
    "        # claer the meta_optimizer, setting zero\n",
    "        meta_optimizer.zero_grad()\n",
    "        image = image.to(device)\n",
    "        mask = mask.to(device)\n",
    "        image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "        mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "        mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "        predicted = base_net(image)     # torch.Size([bs,out_channels=1,512,512])\n",
    "        predicted = predicted.squeeze(1)    # torch.Size([bs,512,512])\n",
    "        loss = criterion(predicted,mask)\n",
    "        loss.backward()\n",
    "        meta_optimizer.step()\n",
    "        loss_list.append(loss.cpu().detach().numpy())\n",
    "        predicted = (predicted > threshold).long()\n",
    "        temp_predicted = predicted.cpu().detach()       # threshold alternative\n",
    "        predicted_list.append(temp_predicted)\n",
    "        groundtruth_list.append(mask.long().cpu().detach())\n",
    "    # train_dice,train_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "    train_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "    train_mloss = np.mean(loss_list)\n",
    "    log_train = f'epoch: {epoch}, loss: {train_mloss}, dice: {train_dice}'\n",
    "    print(\"#Train# \",log_train)\n",
    "    temp_result = pd.Series([epoch,train_mloss,train_dice.item()],index=train_columns)\n",
    "    train_df = train_df.append(temp_result, ignore_index=True)\n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    \n",
    "    # validation part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in train_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach())\n",
    "        # val_dice,val_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        val_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_val = f'epoch: {epoch}, dice: {val_dice}'\n",
    "        print(\"#Val# \",log_val)\n",
    "        temp_result = pd.Series([epoch,val_dice.item()],index=val_columns)\n",
    "        val_df = val_df.append(temp_result, ignore_index=True)\n",
    "        val_df.to_csv(val_csv, index=False)\n",
    "        # logger.info(log_val)\n",
    "\n",
    "    if val_dice > best_dice_val:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_val.pth'))\n",
    "        best_dice_val = val_dice\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # test part\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    base_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for image,mask in test_loader:\n",
    "            # claer the meta_optimizer, setting zero\n",
    "            meta_optimizer.zero_grad()\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            image = torch.squeeze(image,dim=1)      # torch.Size([bs, 3, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1)     # torch.Size([bs, 1, 512, 512])\n",
    "            mask = torch.squeeze(mask,dim=1).float()     # torch.Size([bs, 512, 512])\n",
    "            predicted = base_net(image)\n",
    "            temp_predicted = (predicted > threshold).long().cpu().detach()        # (20, 128, 128)\n",
    "            predicted_list.append(temp_predicted)\n",
    "            groundtruth_list.append(mask.long().cpu().detach())\n",
    "        # test_dice,test_mdice = evaluation_epoch(predicted_list,groundtruth_list)\n",
    "        test_dice = evaluation_api(predicted_list,groundtruth_list)\n",
    "        log_test = f'epoch: {epoch}, dice: {test_dice}'\n",
    "        print(\"#Test# \",log_test)\n",
    "        temp_result = pd.Series([epoch,test_dice.item()],index=test_columns)\n",
    "        test_df = test_df.append(temp_result, ignore_index=True)\n",
    "        test_df.to_csv(test_csv, index=False)\n",
    "        logger.info(log_test)\n",
    "\n",
    "    if test_dice > best_dice_test:\n",
    "        torch.save(base_net.state_dict(), os.path.join(checkpoint_dir, 'best_test.pth'))\n",
    "        best_dice_test = test_dice\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best dice in testset:tensor(0.7871)\n"
     ]
    }
   ],
   "source": [
    "best_result_test = \"Best dice in testset:\" + str(best_dice_test)\n",
    "print(best_result_test)\n",
    "logger.info(best_result_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEngineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
